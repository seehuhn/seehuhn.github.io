<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Section 15 Multicollinearity | MATH3714 Linear Regression and Robustness</title>
  <meta name="description" content="Lecture notes for the course MATH3714 Linear Regression and Robustness at the University of Leeds, 2024/25" />
  <meta name="generator" content="bookdown 0.40 and GitBook 2.6.7" />

  <meta property="og:title" content="Section 15 Multicollinearity | MATH3714 Linear Regression and Robustness" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="Lecture notes for the course MATH3714 Linear Regression and Robustness at the University of Leeds, 2024/25" />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Section 15 Multicollinearity | MATH3714 Linear Regression and Robustness" />
  
  <meta name="twitter:description" content="Lecture notes for the course MATH3714 Linear Regression and Robustness at the University of Leeds, 2024/25" />
  

<meta name="author" content="Jochen Voss" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="S14-examples.html"/>
<link rel="next" href="P04.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>

<link rel="stylesheet" href="jvstyle.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./index.html">MATH3714 Notes</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="chapter" data-level="1" data-path="S01-simple.html"><a href="S01-simple.html"><i class="fa fa-check"></i><b>1</b> Simple Linear Regression</a>
<ul>
<li class="chapter" data-level="1.1" data-path="S01-simple.html"><a href="S01-simple.html#residual-sum-of-squares"><i class="fa fa-check"></i><b>1.1</b> Residual Sum of Squares</a></li>
<li class="chapter" data-level="1.2" data-path="S01-simple.html"><a href="S01-simple.html#linear-regression-as-a-parameter-estimation-problem"><i class="fa fa-check"></i><b>1.2</b> Linear Regression as a Parameter Estimation Problem</a></li>
<li class="chapter" data-level="1.3" data-path="S01-simple.html"><a href="S01-simple.html#sec:simple-mat"><i class="fa fa-check"></i><b>1.3</b> Matrix Notation</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="S02-multiple.html"><a href="S02-multiple.html"><i class="fa fa-check"></i><b>2</b> Least Squares Estimates</a>
<ul>
<li class="chapter" data-level="2.1" data-path="S02-multiple.html"><a href="S02-multiple.html#data-and-models"><i class="fa fa-check"></i><b>2.1</b> Data and Models</a></li>
<li class="chapter" data-level="2.2" data-path="S02-multiple.html"><a href="S02-multiple.html#the-normal-equations"><i class="fa fa-check"></i><b>2.2</b> The Normal Equations</a></li>
<li class="chapter" data-level="2.3" data-path="S02-multiple.html"><a href="S02-multiple.html#fitted-values"><i class="fa fa-check"></i><b>2.3</b> Fitted Values</a></li>
<li class="chapter" data-level="2.4" data-path="S02-multiple.html"><a href="S02-multiple.html#models-without-intercept"><i class="fa fa-check"></i><b>2.4</b> Models Without Intercept</a></li>
<li class="chapter" data-level="2.5" data-path="S02-multiple.html"><a href="S02-multiple.html#example"><i class="fa fa-check"></i><b>2.5</b> Example</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="I01-lm.html"><a href="I01-lm.html"><i class="fa fa-check"></i>Interlude: Linear Regression in R</a>
<ul>
<li class="chapter" data-level="" data-path="I01-lm.html"><a href="I01-lm.html#lm-fitting"><i class="fa fa-check"></i>Fitting a Model</a></li>
<li class="chapter" data-level="" data-path="I01-lm.html"><a href="I01-lm.html#lm-model"><i class="fa fa-check"></i>Understanding the Model</a></li>
<li class="chapter" data-level="" data-path="I01-lm.html"><a href="I01-lm.html#lm-predict"><i class="fa fa-check"></i>Making Predictions</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="S03-cov.html"><a href="S03-cov.html"><i class="fa fa-check"></i><b>3</b> Random Vectors and Covariance</a>
<ul>
<li class="chapter" data-level="3.1" data-path="S03-cov.html"><a href="S03-cov.html#expectation"><i class="fa fa-check"></i><b>3.1</b> Expectation</a></li>
<li class="chapter" data-level="3.2" data-path="S03-cov.html"><a href="S03-cov.html#sec:covariance"><i class="fa fa-check"></i><b>3.2</b> Covariance Matrix</a></li>
<li class="chapter" data-level="3.3" data-path="S03-cov.html"><a href="S03-cov.html#the-multivariate-normal-distribution"><i class="fa fa-check"></i><b>3.3</b> The Multivariate Normal Distribution</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="P01.html"><a href="P01.html"><i class="fa fa-check"></i>Problem Sheet 1</a></li>
<li class="chapter" data-level="4" data-path="S04-model.html"><a href="S04-model.html"><i class="fa fa-check"></i><b>4</b> Properties of the Least Squares Estimate</a>
<ul>
<li class="chapter" data-level="4.1" data-path="S04-model.html"><a href="S04-model.html#mean-and-covariance"><i class="fa fa-check"></i><b>4.1</b> Mean and Covariance</a></li>
<li class="chapter" data-level="4.2" data-path="S04-model.html"><a href="S04-model.html#hat-matrix"><i class="fa fa-check"></i><b>4.2</b> Properties of the Hat Matrix</a></li>
<li class="chapter" data-level="4.3" data-path="S04-model.html"><a href="S04-model.html#Cochran"><i class="fa fa-check"></i><b>4.3</b> Cochran’s theorem</a></li>
<li class="chapter" data-level="4.4" data-path="S04-model.html"><a href="S04-model.html#var-est-bias"><i class="fa fa-check"></i><b>4.4</b> Estimating the Error Variance</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="S05-single.html"><a href="S05-single.html"><i class="fa fa-check"></i><b>5</b> Uncertainty for Individual Regression Coefficients</a>
<ul>
<li class="chapter" data-level="5.1" data-path="S05-single.html"><a href="S05-single.html#measuring-the-estimation-error"><i class="fa fa-check"></i><b>5.1</b> Measuring the Estimation Error</a></li>
<li class="chapter" data-level="5.2" data-path="S05-single.html"><a href="S05-single.html#confidence-intervals"><i class="fa fa-check"></i><b>5.2</b> Confidence Intervals</a></li>
<li class="chapter" data-level="5.3" data-path="S05-single.html"><a href="S05-single.html#hypthesis-tests"><i class="fa fa-check"></i><b>5.3</b> Hypthesis Tests</a></li>
<li class="chapter" data-level="5.4" data-path="S05-single.html"><a href="S05-single.html#r-experiments"><i class="fa fa-check"></i><b>5.4</b> R Experiments</a>
<ul>
<li class="chapter" data-level="5.4.1" data-path="S05-single.html"><a href="S05-single.html#fitting-the-model"><i class="fa fa-check"></i><b>5.4.1</b> Fitting the model</a></li>
<li class="chapter" data-level="5.4.2" data-path="S05-single.html"><a href="S05-single.html#estimating-the-variance-of-the-error"><i class="fa fa-check"></i><b>5.4.2</b> Estimating the Variance of the Error</a></li>
<li class="chapter" data-level="5.4.3" data-path="S05-single.html"><a href="S05-single.html#estimating-the-standard-errors"><i class="fa fa-check"></i><b>5.4.3</b> Estimating the Standard Errors</a></li>
<li class="chapter" data-level="5.4.4" data-path="S05-single.html"><a href="S05-single.html#hypothesis-tests"><i class="fa fa-check"></i><b>5.4.4</b> Hypothesis tests</a></li>
<li class="chapter" data-level="5.4.5" data-path="S05-single.html"><a href="S05-single.html#confidence-intervals-1"><i class="fa fa-check"></i><b>5.4.5</b> Confidence Intervals</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="S06-simultaneous.html"><a href="S06-simultaneous.html"><i class="fa fa-check"></i><b>6</b> Estimating Coefficients Simultaneously</a>
<ul>
<li class="chapter" data-level="6.1" data-path="S06-simultaneous.html"><a href="S06-simultaneous.html#sec:simult-dist"><i class="fa fa-check"></i><b>6.1</b> Linear Combinations of Coefficients</a></li>
<li class="chapter" data-level="6.2" data-path="S06-simultaneous.html"><a href="S06-simultaneous.html#sec:simult-CI"><i class="fa fa-check"></i><b>6.2</b> Confidence Regions</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="S06-simultaneous.html"><a href="S06-simultaneous.html#result"><i class="fa fa-check"></i><b>6.2.1</b> Result</a></li>
<li class="chapter" data-level="6.2.2" data-path="S06-simultaneous.html"><a href="S06-simultaneous.html#numerical-experiments"><i class="fa fa-check"></i><b>6.2.2</b> Numerical Experiments</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="S06-simultaneous.html"><a href="S06-simultaneous.html#sec:simult-test"><i class="fa fa-check"></i><b>6.3</b> Hypothesis Tests</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="I02-read.html"><a href="I02-read.html"><i class="fa fa-check"></i>Interlude: Loading Data into R</a>
<ul>
<li class="chapter" data-level="" data-path="I02-read.html"><a href="I02-read.html#importing-csv-files"><i class="fa fa-check"></i>Importing CSV Files</a></li>
<li class="chapter" data-level="" data-path="I02-read.html"><a href="I02-read.html#importing-microsoft-excel-files"><i class="fa fa-check"></i>Importing Microsoft Excel Files</a></li>
<li class="chapter" data-level="" data-path="I02-read.html"><a href="I02-read.html#checking-the-imported-data"><i class="fa fa-check"></i>Checking the Imported Data</a></li>
<li class="chapter" data-level="" data-path="I02-read.html"><a href="I02-read.html#common-problems"><i class="fa fa-check"></i>Common Problems</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="S07-examples.html"><a href="S07-examples.html"><i class="fa fa-check"></i><b>7</b> Examples</a>
<ul>
<li class="chapter" data-level="7.1" data-path="S07-examples.html"><a href="S07-examples.html#simple-confidence-interval"><i class="fa fa-check"></i><b>7.1</b> Simple Confidence Interval</a>
<ul>
<li class="chapter" data-level="7.1.1" data-path="S07-examples.html"><a href="S07-examples.html#from-first-principles"><i class="fa fa-check"></i><b>7.1.1</b> From First Principles</a></li>
<li class="chapter" data-level="7.1.2" data-path="S07-examples.html"><a href="S07-examples.html#from-the-lm-output"><i class="fa fa-check"></i><b>7.1.2</b> From the <code>lm()</code> Output</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="S07-examples.html"><a href="S07-examples.html#confidence-intervals-for-the-mean"><i class="fa fa-check"></i><b>7.2</b> Confidence Intervals for the Mean</a></li>
<li class="chapter" data-level="7.3" data-path="S07-examples.html"><a href="S07-examples.html#testing-a-single-coefficient"><i class="fa fa-check"></i><b>7.3</b> Testing a Single Coefficient</a>
<ul>
<li class="chapter" data-level="7.3.1" data-path="S07-examples.html"><a href="S07-examples.html#from-first-principles-1"><i class="fa fa-check"></i><b>7.3.1</b> From First Principles</a></li>
<li class="chapter" data-level="7.3.2" data-path="S07-examples.html"><a href="S07-examples.html#using-the-lm-output-i"><i class="fa fa-check"></i><b>7.3.2</b> Using the <code>lm()</code> Output, I</a></li>
<li class="chapter" data-level="7.3.3" data-path="S07-examples.html"><a href="S07-examples.html#using-the-lm-output-ii"><i class="fa fa-check"></i><b>7.3.3</b> Using the <code>lm()</code> Output, II</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="S07-examples.html"><a href="S07-examples.html#testing-multiple-coefficents"><i class="fa fa-check"></i><b>7.4</b> Testing Multiple Coefficents</a>
<ul>
<li class="chapter" data-level="7.4.1" data-path="S07-examples.html"><a href="S07-examples.html#from-first-principles-2"><i class="fa fa-check"></i><b>7.4.1</b> From First Principles</a></li>
<li class="chapter" data-level="7.4.2" data-path="S07-examples.html"><a href="S07-examples.html#using-the-lm-output"><i class="fa fa-check"></i><b>7.4.2</b> Using the <code>lm()</code> output</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="P02.html"><a href="P02.html"><i class="fa fa-check"></i>Problem Sheet 2</a></li>
<li class="chapter" data-level="8" data-path="S08-influence.html"><a href="S08-influence.html"><i class="fa fa-check"></i><b>8</b> The Influence of Observations</a>
<ul>
<li class="chapter" data-level="8.1" data-path="S08-influence.html"><a href="S08-influence.html#deleting"><i class="fa fa-check"></i><b>8.1</b> Deleting Observations</a></li>
<li class="chapter" data-level="8.2" data-path="S08-influence.html"><a href="S08-influence.html#influence"><i class="fa fa-check"></i><b>8.2</b> Cook’s Distance</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="S09-plots.html"><a href="S09-plots.html"><i class="fa fa-check"></i><b>9</b> Diagnostic Plots</a>
<ul>
<li class="chapter" data-level="9.1" data-path="S09-plots.html"><a href="S09-plots.html#residual-plots"><i class="fa fa-check"></i><b>9.1</b> Residual Plots</a></li>
<li class="chapter" data-level="9.2" data-path="S09-plots.html"><a href="S09-plots.html#q-q-plots"><i class="fa fa-check"></i><b>9.2</b> Q-Q Plots</a></li>
<li class="chapter" data-level="9.3" data-path="S09-plots.html"><a href="S09-plots.html#other-plot-types"><i class="fa fa-check"></i><b>9.3</b> Other Plot Types</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="S10-improving.html"><a href="S10-improving.html"><i class="fa fa-check"></i><b>10</b> Improving the Model Fit</a>
<ul>
<li class="chapter" data-level="10.1" data-path="S10-improving.html"><a href="S10-improving.html#linearising-the-mean"><i class="fa fa-check"></i><b>10.1</b> Linearising the Mean</a></li>
<li class="chapter" data-level="10.2" data-path="S10-improving.html"><a href="S10-improving.html#stabilising-the-variance"><i class="fa fa-check"></i><b>10.2</b> Stabilising the Variance</a></li>
<li class="chapter" data-level="10.3" data-path="S10-improving.html"><a href="S10-improving.html#power-transform"><i class="fa fa-check"></i><b>10.3</b> The Power Transform</a></li>
<li class="chapter" data-level="10.4" data-path="S10-improving.html"><a href="S10-improving.html#candidate-models"><i class="fa fa-check"></i><b>10.4</b> Candidate Models</a></li>
<li class="chapter" data-level="10.5" data-path="S10-improving.html"><a href="S10-improving.html#misspecified-models"><i class="fa fa-check"></i><b>10.5</b> Misspecified Models</a>
<ul>
<li class="chapter" data-level="10.5.1" data-path="S10-improving.html"><a href="S10-improving.html#missing-variables"><i class="fa fa-check"></i><b>10.5.1</b> Missing Variables</a></li>
<li class="chapter" data-level="10.5.2" data-path="S10-improving.html"><a href="S10-improving.html#unnecessary-variables"><i class="fa fa-check"></i><b>10.5.2</b> Unnecessary Variables</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="11" data-path="S11-diagnostics.html"><a href="S11-diagnostics.html"><i class="fa fa-check"></i><b>11</b> Measures for Model Fit</a>
<ul>
<li class="chapter" data-level="11.1" data-path="S11-diagnostics.html"><a href="S11-diagnostics.html#R-squared"><i class="fa fa-check"></i><b>11.1</b> The Coefficient of Multiple Determination</a></li>
<li class="chapter" data-level="11.2" data-path="S11-diagnostics.html"><a href="S11-diagnostics.html#error-var"><i class="fa fa-check"></i><b>11.2</b> Error Variance</a></li>
<li class="chapter" data-level="11.3" data-path="S11-diagnostics.html"><a href="S11-diagnostics.html#PRESS"><i class="fa fa-check"></i><b>11.3</b> Prediction Error Sum of Squares</a></li>
<li class="chapter" data-level="11.4" data-path="S11-diagnostics.html"><a href="S11-diagnostics.html#AIC"><i class="fa fa-check"></i><b>11.4</b> Akaike’s Information Criterion</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="I03-lm-output.html"><a href="I03-lm-output.html"><i class="fa fa-check"></i>Interlude: Understanding the <code>lm()</code> Output</a></li>
<li class="chapter" data-level="" data-path="P03.html"><a href="P03.html"><i class="fa fa-check"></i>Problem Sheet 3</a></li>
<li class="chapter" data-level="12" data-path="S12-automatic.html"><a href="S12-automatic.html"><i class="fa fa-check"></i><b>12</b> Automatic Model Selection</a>
<ul>
<li class="chapter" data-level="12.1" data-path="S12-automatic.html"><a href="S12-automatic.html#exhaustive-search"><i class="fa fa-check"></i><b>12.1</b> Exhaustive Search</a></li>
<li class="chapter" data-level="12.2" data-path="S12-automatic.html"><a href="S12-automatic.html#search-algorithm"><i class="fa fa-check"></i><b>12.2</b> Search Algorithm</a></li>
<li class="chapter" data-level="12.3" data-path="S12-automatic.html"><a href="S12-automatic.html#other-methods"><i class="fa fa-check"></i><b>12.3</b> Other Methods</a>
<ul>
<li class="chapter" data-level="12.3.1" data-path="S12-automatic.html"><a href="S12-automatic.html#stepwise-forward-selection"><i class="fa fa-check"></i><b>12.3.1</b> Stepwise Forward Selection</a></li>
<li class="chapter" data-level="12.3.2" data-path="S12-automatic.html"><a href="S12-automatic.html#stepwise-backward-selection"><i class="fa fa-check"></i><b>12.3.2</b> Stepwise Backward Selection</a></li>
<li class="chapter" data-level="12.3.3" data-path="S12-automatic.html"><a href="S12-automatic.html#hybrid-methods"><i class="fa fa-check"></i><b>12.3.3</b> Hybrid Methods</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="13" data-path="S13-factors.html"><a href="S13-factors.html"><i class="fa fa-check"></i><b>13</b> Factors</a>
<ul>
<li class="chapter" data-level="13.1" data-path="S13-factors.html"><a href="S13-factors.html#indicator-variables"><i class="fa fa-check"></i><b>13.1</b> Indicator Variables</a></li>
<li class="chapter" data-level="13.2" data-path="S13-factors.html"><a href="S13-factors.html#interactions"><i class="fa fa-check"></i><b>13.2</b> Interactions</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="S14-examples.html"><a href="S14-examples.html"><i class="fa fa-check"></i><b>14</b> Examples</a>
<ul>
<li class="chapter" data-level="14.1" data-path="S14-examples.html"><a href="S14-examples.html#interactions-example"><i class="fa fa-check"></i><b>14.1</b> Use of Interaction Terms in Modelling</a></li>
<li class="chapter" data-level="14.2" data-path="S14-examples.html"><a href="S14-examples.html#codings"><i class="fa fa-check"></i><b>14.2</b> Alternative Factor Codings</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="S15-multicoll.html"><a href="S15-multicoll.html"><i class="fa fa-check"></i><b>15</b> Multicollinearity</a>
<ul>
<li class="chapter" data-level="15.1" data-path="S15-multicoll.html"><a href="S15-multicoll.html#consequences-of-multicollinearity"><i class="fa fa-check"></i><b>15.1</b> Consequences of Multicollinearity</a></li>
<li class="chapter" data-level="15.2" data-path="S15-multicoll.html"><a href="S15-multicoll.html#detecting-multicollinearity"><i class="fa fa-check"></i><b>15.2</b> Detecting Multicollinearity</a></li>
<li class="chapter" data-level="15.3" data-path="S15-multicoll.html"><a href="S15-multicoll.html#mitigations"><i class="fa fa-check"></i><b>15.3</b> Mitigations</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="P04.html"><a href="P04.html"><i class="fa fa-check"></i>Problem Sheet 4</a></li>
<li class="chapter" data-level="16" data-path="S16-ridge.html"><a href="S16-ridge.html"><i class="fa fa-check"></i><b>16</b> Ridge Regression</a>
<ul>
<li class="chapter" data-level="16.1" data-path="S16-ridge.html"><a href="S16-ridge.html#definition-the-estimator"><i class="fa fa-check"></i><b>16.1</b> Definition the Estimator</a></li>
<li class="chapter" data-level="16.2" data-path="S16-ridge.html"><a href="S16-ridge.html#properties-of-the-estimate"><i class="fa fa-check"></i><b>16.2</b> Properties of the Estimate</a>
<ul>
<li class="chapter" data-level="16.2.1" data-path="S16-ridge.html"><a href="S16-ridge.html#bias"><i class="fa fa-check"></i><b>16.2.1</b> Bias</a></li>
<li class="chapter" data-level="16.2.2" data-path="S16-ridge.html"><a href="S16-ridge.html#variance"><i class="fa fa-check"></i><b>16.2.2</b> Variance</a></li>
<li class="chapter" data-level="16.2.3" data-path="S16-ridge.html"><a href="S16-ridge.html#mean-squared-error"><i class="fa fa-check"></i><b>16.2.3</b> Mean Squared Error</a></li>
</ul></li>
<li class="chapter" data-level="16.3" data-path="S16-ridge.html"><a href="S16-ridge.html#standardisation"><i class="fa fa-check"></i><b>16.3</b> Standardisation</a></li>
</ul></li>
<li class="chapter" data-level="17" data-path="S17-robust.html"><a href="S17-robust.html"><i class="fa fa-check"></i><b>17</b> Robust Regression</a>
<ul>
<li class="chapter" data-level="17.1" data-path="S17-robust.html"><a href="S17-robust.html#outliers"><i class="fa fa-check"></i><b>17.1</b> Outliers</a>
<ul>
<li class="chapter" data-level="17.1.1" data-path="S17-robust.html"><a href="S17-robust.html#leverage"><i class="fa fa-check"></i><b>17.1.1</b> Leverage</a></li>
<li class="chapter" data-level="17.1.2" data-path="S17-robust.html"><a href="S17-robust.html#studentised-residuals"><i class="fa fa-check"></i><b>17.1.2</b> Studentised Residuals</a></li>
</ul></li>
<li class="chapter" data-level="17.2" data-path="S17-robust.html"><a href="S17-robust.html#breakdown-points"><i class="fa fa-check"></i><b>17.2</b> Breakdown Points</a></li>
</ul></li>
<li class="chapter" data-level="18" data-path="S18-m-est.html"><a href="S18-m-est.html"><i class="fa fa-check"></i><b>18</b> M-Estimators</a>
<ul>
<li class="chapter" data-level="18.1" data-path="S18-m-est.html"><a href="S18-m-est.html#definition"><i class="fa fa-check"></i><b>18.1</b> Definition</a></li>
<li class="chapter" data-level="18.2" data-path="S18-m-est.html"><a href="S18-m-est.html#iterative-methods"><i class="fa fa-check"></i><b>18.2</b> Iterative Methods</a></li>
<li class="chapter" data-level="18.3" data-path="S18-m-est.html"><a href="S18-m-est.html#objective-functions"><i class="fa fa-check"></i><b>18.3</b> Objective Functions</a>
<ul>
<li class="chapter" data-level="18.3.1" data-path="S18-m-est.html"><a href="S18-m-est.html#least-squares-method"><i class="fa fa-check"></i><b>18.3.1</b> Least Squares Method</a></li>
<li class="chapter" data-level="18.3.2" data-path="S18-m-est.html"><a href="S18-m-est.html#least-absolute-values"><i class="fa fa-check"></i><b>18.3.2</b> Least Absolute Values</a></li>
<li class="chapter" data-level="18.3.3" data-path="S18-m-est.html"><a href="S18-m-est.html#Huber"><i class="fa fa-check"></i><b>18.3.3</b> Huber’s <span class="math inline">\(t\)</span>-function</a></li>
<li class="chapter" data-level="18.3.4" data-path="S18-m-est.html"><a href="S18-m-est.html#hampels-method"><i class="fa fa-check"></i><b>18.3.4</b> Hampel’s Method</a></li>
<li class="chapter" data-level="18.3.5" data-path="S18-m-est.html"><a href="S18-m-est.html#tukeys-bisquare-method"><i class="fa fa-check"></i><b>18.3.5</b> Tukey’s Bisquare Method</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="P05.html"><a href="P05.html"><i class="fa fa-check"></i>Problem Sheet 5</a></li>
<li class="chapter" data-level="19" data-path="S19-efficiency.html"><a href="S19-efficiency.html"><i class="fa fa-check"></i><b>19</b> Efficiency of Robust Estimators</a>
<ul>
<li class="chapter" data-level="19.1" data-path="S19-efficiency.html"><a href="S19-efficiency.html#efficiency"><i class="fa fa-check"></i><b>19.1</b> Efficiency</a></li>
<li class="chapter" data-level="19.2" data-path="S19-efficiency.html"><a href="S19-efficiency.html#robust-estimators"><i class="fa fa-check"></i><b>19.2</b> Robust estimators</a>
<ul>
<li class="chapter" data-level="19.2.1" data-path="S19-efficiency.html"><a href="S19-efficiency.html#least-median-of-squares"><i class="fa fa-check"></i><b>19.2.1</b> Least Median of Squares</a></li>
<li class="chapter" data-level="19.2.2" data-path="S19-efficiency.html"><a href="S19-efficiency.html#least-trimmed-squares"><i class="fa fa-check"></i><b>19.2.2</b> Least Trimmed Squares</a></li>
</ul></li>
</ul></li>
<li class="appendix"><span><b>Appendices</b></span></li>
<li class="chapter" data-level="A" data-path="Sx1-matrices.html"><a href="Sx1-matrices.html"><i class="fa fa-check"></i><b>A</b> Linear Algebra Reminders</a>
<ul>
<li class="chapter" data-level="A.1" data-path="Sx1-matrices.html"><a href="Sx1-matrices.html#vectors"><i class="fa fa-check"></i><b>A.1</b> Vectors</a></li>
<li class="chapter" data-level="A.2" data-path="Sx1-matrices.html"><a href="Sx1-matrices.html#matrix-rules"><i class="fa fa-check"></i><b>A.2</b> Matrices</a>
<ul>
<li class="chapter" data-level="A.2.1" data-path="Sx1-matrices.html"><a href="Sx1-matrices.html#transpose"><i class="fa fa-check"></i><b>A.2.1</b> Transpose</a></li>
<li class="chapter" data-level="A.2.2" data-path="Sx1-matrices.html"><a href="Sx1-matrices.html#matrix-vector-product"><i class="fa fa-check"></i><b>A.2.2</b> Matrix-vector Product</a></li>
<li class="chapter" data-level="A.2.3" data-path="Sx1-matrices.html"><a href="Sx1-matrices.html#matrix-matrix-product"><i class="fa fa-check"></i><b>A.2.3</b> Matrix-matrix Product</a></li>
<li class="chapter" data-level="A.2.4" data-path="Sx1-matrices.html"><a href="Sx1-matrices.html#rank"><i class="fa fa-check"></i><b>A.2.4</b> Rank</a></li>
<li class="chapter" data-level="A.2.5" data-path="Sx1-matrices.html"><a href="Sx1-matrices.html#trace"><i class="fa fa-check"></i><b>A.2.5</b> Trace</a></li>
<li class="chapter" data-level="A.2.6" data-path="Sx1-matrices.html"><a href="Sx1-matrices.html#matrix-inverse"><i class="fa fa-check"></i><b>A.2.6</b> Matrix Inverse</a></li>
<li class="chapter" data-level="A.2.7" data-path="Sx1-matrices.html"><a href="Sx1-matrices.html#orthogonal-matrices"><i class="fa fa-check"></i><b>A.2.7</b> Orthogonal Matrices</a></li>
<li class="chapter" data-level="A.2.8" data-path="Sx1-matrices.html"><a href="Sx1-matrices.html#positive-definite"><i class="fa fa-check"></i><b>A.2.8</b> Positive Definite Matrices</a></li>
<li class="chapter" data-level="A.2.9" data-path="Sx1-matrices.html"><a href="Sx1-matrices.html#idempotent"><i class="fa fa-check"></i><b>A.2.9</b> Idempotent Matrices</a></li>
</ul></li>
<li class="chapter" data-level="A.3" data-path="Sx1-matrices.html"><a href="Sx1-matrices.html#eigenvalues"><i class="fa fa-check"></i><b>A.3</b> Eigenvalues</a></li>
</ul></li>
<li class="chapter" data-level="B" data-path="Sx2-probability.html"><a href="Sx2-probability.html"><i class="fa fa-check"></i><b>B</b> Probability Reminders</a>
<ul>
<li class="chapter" data-level="B.1" data-path="Sx2-probability.html"><a href="Sx2-probability.html#independence"><i class="fa fa-check"></i><b>B.1</b> Independence</a></li>
<li class="chapter" data-level="B.2" data-path="Sx2-probability.html"><a href="Sx2-probability.html#chi-square"><i class="fa fa-check"></i><b>B.2</b> The Chi-Squared Distribution</a></li>
<li class="chapter" data-level="B.3" data-path="Sx2-probability.html"><a href="Sx2-probability.html#t"><i class="fa fa-check"></i><b>B.3</b> The t-distribution</a></li>
</ul></li>
<li class="divider"></li>
<li class="chapter"><span><b>THE END</b></span></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">MATH3714 Linear Regression and Robustness</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="S15-multicoll" class="section level1 hasAnchor" number="15">
<h1><span class="header-section-number">Section 15</span> Multicollinearity<a href="S15-multicoll.html#S15-multicoll" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<!--
TODO (voss):
* Move this before section 13 (Factors)
* Add variance inflation factors?
-->
<div class="definition">
<p><span id="def:unlabeled-div-49" class="definition"><strong>Definition 15.1  </strong></span>In linear regression, <strong>Multicollinearity</strong> denotes the situation
when the columns of the design matrix <span class="math inline">\(X\)</span> are (approximately) linearly
dependent.</p>
</div>
<p>The columns of <span class="math inline">\(X\)</span> are linearly dependent, if and only if
there is a <span class="math inline">\(v \in \mathbb{R}^{p+1}\)</span> such that <span class="math inline">\(X v = 0\)</span>. The columns
are approximately linearly dependent, if there is a vector <span class="math inline">\(v\)</span>
such that <span class="math inline">\(X v \approx 0\)</span>.</p>
<div id="consequences-of-multicollinearity" class="section level2 hasAnchor" number="15.1">
<h2><span class="header-section-number">15.1</span> Consequences of Multicollinearity<a href="S15-multicoll.html#consequences-of-multicollinearity" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div class="videowrap">
<div class="videowrapper">
<iframe width="560" height="315" src="https://www.youtube.com/embed/DBdeSoPbjb4" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen>
</iframe>
</div>
</div>
<p>In the derivation of the least squares estimator <span class="math inline">\(\hat\beta =
(X^\top X)^{-1} X^\top y\)</span> we had to assume that the matrix <span class="math inline">\(X^\top X\)</span> is
invertible. If the columns of <span class="math inline">\(X\)</span> are linearly dependent, <span class="math inline">\(X^\top X\)</span> is no
longer invertible and the least squares estimate is no longer uniquely
defined.</p>
<div class="example">
<p><span id="exm:unlabeled-div-50" class="example"><strong>Example 15.1  </strong></span>Consider the following data:</p>
<table>
<thead>
<tr>
<th align="right"><span class="math inline">\(y\)</span></th>
<th align="center"><span class="math inline">\(x_1\)</span></th>
<th align="left"><span class="math inline">\(x_2\)</span></th>
</tr>
</thead>
<tbody>
<tr>
<td align="right">2</td>
<td align="center">1</td>
<td align="left">1</td>
</tr>
<tr>
<td align="right">4</td>
<td align="center">2</td>
<td align="left">2</td>
</tr>
<tr>
<td align="right">6</td>
<td align="center">3</td>
<td align="left">3</td>
</tr>
</tbody>
</table>
<p>In this case, an exact match with no residuals can be achieved
as <span class="math inline">\(y = x_1 + x_2\)</span>, <em>i.e.</em> for <span class="math inline">\(\beta_1 = \beta_2 = 1\)</span>. But this solution
is not unique: we could just as well write <span class="math inline">\(y = 2 x_1\)</span> or <span class="math inline">\(y = 2 x_2\)</span>.
Any choice of <span class="math inline">\(\beta_1\)</span> and <span class="math inline">\(\beta_2\)</span> with <span class="math inline">\(\beta_1 + \beta_2 = 2\)</span> will
lead to zero residuals.</p>
</div>
<p>The problem in the example above occurs, since the two input columns in the
data are identical. The same problem, in a less obvious way, would occur in
datasets with more inputs when one column of <span class="math inline">\(X\)</span> can be written as a linear
combination of other columns. This is a problem of the given
input data, not of the responsees or of the statistical model.</p>
<p>In the case where there is only approximate linear dependency between the
columns of <span class="math inline">\(X\)</span>, the inverse <span class="math inline">\((X^\top X)^{-1}\)</span> exists and an estimate <span class="math inline">\(\hat\beta\)</span>
can be computed, but there will be huge uncertainties in some of the stimated
coefficients. We illustrate this effect using a numerical example.</p>
<div class="example">
<p><span id="exm:mulcollell" class="example"><strong>Example 15.2  </strong></span>Here we simulate data which has similar characteristics to the toy example
above: we have very similar two inputs, the sum of which nearly equals the
output. We fit a model without the intercept, so that there are only two
coefficients to estimate and plotting these is no problem.</p>
<div class="sourceCode" id="cb242"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb242-1"><a href="S15-multicoll.html#cb242-1" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">20211101</span>)</span>
<span id="cb242-2"><a href="S15-multicoll.html#cb242-2" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">10</span></span>
<span id="cb242-3"><a href="S15-multicoll.html#cb242-3" tabindex="-1"></a>y <span class="ot">&lt;-</span> <span class="dv">2</span> <span class="sc">*</span> (<span class="dv">1</span><span class="sc">:</span>n)</span>
<span id="cb242-4"><a href="S15-multicoll.html#cb242-4" tabindex="-1"></a>x1 <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="dv">10</span>, <span class="dv">1</span><span class="sc">:</span>n, <span class="fl">0.15</span>)</span>
<span id="cb242-5"><a href="S15-multicoll.html#cb242-5" tabindex="-1"></a>x2 <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="dv">10</span>, <span class="dv">1</span><span class="sc">:</span>n, <span class="fl">0.15</span>)</span>
<span id="cb242-6"><a href="S15-multicoll.html#cb242-6" tabindex="-1"></a>m <span class="ot">&lt;-</span> <span class="fu">lm</span>(y <span class="sc">~</span> <span class="dv">0</span> <span class="sc">+</span> x1 <span class="sc">+</span> x2)</span></code></pre></div>
<p>Similar to the approach in <a href="S06-simultaneous.html#coordinates-of-the-outline">section 6</a>,
we can plot a confidence ellipse. (Don’t worry about the details of the
commands used to plot the ellipse.)</p>
<div class="sourceCode" id="cb243"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb243-1"><a href="S15-multicoll.html#cb243-1" tabindex="-1"></a>sigma.hat <span class="ot">&lt;-</span> <span class="fu">summary</span>(m)<span class="sc">$</span>sigma</span>
<span id="cb243-2"><a href="S15-multicoll.html#cb243-2" tabindex="-1"></a>X <span class="ot">&lt;-</span> <span class="fu">model.matrix</span>(m)</span>
<span id="cb243-3"><a href="S15-multicoll.html#cb243-3" tabindex="-1"></a>svd <span class="ot">&lt;-</span> <span class="fu">La.svd</span>(<span class="fu">t</span>(X) <span class="sc">%*%</span> X)</span>
<span id="cb243-4"><a href="S15-multicoll.html#cb243-4" tabindex="-1"></a>alpha <span class="ot">&lt;-</span> <span class="fl">0.05</span></span>
<span id="cb243-5"><a href="S15-multicoll.html#cb243-5" tabindex="-1"></a>f.crit <span class="ot">&lt;-</span> <span class="fu">qf</span>(<span class="dv">1</span> <span class="sc">-</span> alpha, <span class="fu">ncol</span>(X), <span class="fu">nrow</span>(X) <span class="sc">-</span> <span class="fu">ncol</span>(X))</span>
<span id="cb243-6"><a href="S15-multicoll.html#cb243-6" tabindex="-1"></a>phi <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="dv">0</span>, <span class="dv">2</span><span class="sc">*</span>pi, <span class="at">length.out =</span> <span class="dv">201</span>)</span>
<span id="cb243-7"><a href="S15-multicoll.html#cb243-7" tabindex="-1"></a>circ <span class="ot">&lt;-</span> <span class="fu">rbind</span>(<span class="fu">cos</span>(phi), <span class="fu">sin</span>(phi)) <span class="sc">*</span> <span class="fu">sqrt</span>(f.crit <span class="sc">*</span> <span class="fu">ncol</span>(X) <span class="sc">*</span> sigma.hat<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb243-8"><a href="S15-multicoll.html#cb243-8" tabindex="-1"></a>ellipse <span class="ot">&lt;-</span> svd<span class="sc">$</span>u <span class="sc">%*%</span> (circ <span class="sc">/</span> <span class="fu">sqrt</span>(svd<span class="sc">$</span>d)) <span class="sc">+</span> <span class="fu">coef</span>(m)</span>
<span id="cb243-9"><a href="S15-multicoll.html#cb243-9" tabindex="-1"></a></span>
<span id="cb243-10"><a href="S15-multicoll.html#cb243-10" tabindex="-1"></a><span class="fu">plot</span>(ellipse[<span class="dv">1</span>,], ellipse[<span class="dv">2</span>,], <span class="at">type =</span> <span class="st">&quot;l&quot;</span>, <span class="at">asp =</span> <span class="dv">1</span>,</span>
<span id="cb243-11"><a href="S15-multicoll.html#cb243-11" tabindex="-1"></a>     <span class="at">xlab =</span> <span class="fu">expression</span>(beta[<span class="dv">1</span>]),</span>
<span id="cb243-12"><a href="S15-multicoll.html#cb243-12" tabindex="-1"></a>     <span class="at">ylab =</span> <span class="fu">expression</span>(beta[<span class="dv">2</span>]))</span>
<span id="cb243-13"><a href="S15-multicoll.html#cb243-13" tabindex="-1"></a><span class="fu">abline</span>(<span class="dv">2</span>, <span class="sc">-</span><span class="dv">1</span>, <span class="at">lty =</span> <span class="st">&quot;dashed&quot;</span>, <span class="at">col =</span> <span class="st">&quot;blue&quot;</span>)</span>
<span id="cb243-14"><a href="S15-multicoll.html#cb243-14" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">v =</span> <span class="fu">coef</span>(m)[<span class="dv">1</span>], <span class="at">lty =</span> <span class="st">&quot;dotted&quot;</span>)</span>
<span id="cb243-15"><a href="S15-multicoll.html#cb243-15" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">h =</span> <span class="fu">coef</span>(m)[<span class="dv">2</span>], <span class="at">lty =</span> <span class="st">&quot;dotted&quot;</span>)</span></code></pre></div>
<p><img src="MATH3714_files/figure-html/multicollellipse-1.png" width="672" /></p>
<p>We can see that, as in the toy example above, the confidence region
places <span class="math inline">\((\beta_1, \beta_2)\)</span> close to the line where <span class="math inline">\(\beta_1 + \beta_2 = 2\)</span>
(the diagonal dashed line), but there is considerable uncertainty about
where on this line the coefficients are located. The effect gets
more pronounced when the amount of noise in the definition of <code>x1</code> and <code>x2</code>
is reduced.</p>
</div>
<p>There are two, slightly different effects of multicollinearity:</p>
<ol style="list-style-type: decimal">
<li><p>In the case of exact multicollinearity, <span class="math inline">\(X^\top X\)</span> is not invertible.
If the columns of <span class="math inline">\(X\)</span> are approximately linearly dependent, then
<span class="math inline">\((X^\top X)^{-1}\)</span> does exist, but small changes of <span class="math inline">\(X\)</span> lead to large changes
of <span class="math inline">\((X^\top X)^{-1}\)</span> and numerical computation of the inverse is
strongly affected by rounding errors.</p></li>
<li><p>If the columns of <span class="math inline">\(X\)</span> are approximately linearly dependent,
the computed value of the estimator <span class="math inline">\(\hat\beta\)</span> is strongly affected
by small changes to the system: the noise in the model strongly affects
<span class="math inline">\(\hat\beta\)</span> (as demonstrated in example <a href="S15-multicoll.html#exm:mulcollell">15.2</a>, above),
leaving out a single observation may lead to large changes in <span class="math inline">\(\hat\beta\)</span>
and computation of <span class="math inline">\(\hat\beta\)</span> is sensitive to rounding errors.</p></li>
</ol>
<p>While multicollinearity can make the regression coefficients ambiguous,
the outputs <span class="math inline">\(y\)</span> are not affected. Predictions made using a model
where multicollinearity is present are still reliable.</p>
</div>
<div id="detecting-multicollinearity" class="section level2 hasAnchor" number="15.2">
<h2><span class="header-section-number">15.2</span> Detecting Multicollinearity<a href="S15-multicoll.html#detecting-multicollinearity" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div class="videowrap">
<div class="videowrapper">
<iframe width="560" height="315" src="https://www.youtube.com/embed/JGykLGrluoo" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen>
</iframe>
</div>
</div>
<p>While collinearity of two columns of <span class="math inline">\(X\)</span> is easy to spot, for example in
a pair scatter plot of the inputs <span class="math inline">\(x_i\)</span>, multicollinearity which involves
more than two columns can be harder to notice. The condition number of
<span class="math inline">\(X\)</span> is a quantitative measure of how close <span class="math inline">\(X\)</span> is to multicollinearity.</p>
<div class="definition">
<p><span id="def:unlabeled-div-51" class="definition"><strong>Definition 15.2  </strong></span>The <strong>condition number</strong> of <span class="math inline">\(X\)</span> is defined to be
<span class="math display">\[\begin{equation*}
  \kappa(X)
  = \frac{\sigma_\mathrm{max}(X)}{\sigma_\mathrm{min}(X)},
\end{equation*}\]</span>
where <span class="math inline">\(\sigma_\mathrm{max}(X) = \sqrt{\lambda_\mathrm{max}(X^\top X)}\)</span> is the
largest singular value of <span class="math inline">\(X\)</span>, computed as the square root of the largest
eigenvalue of <span class="math inline">\(X^\top X\)</span>, and similarly <span class="math inline">\(\sigma_\mathrm{min}(X) =
\sqrt{\lambda_\mathrm{min}(X^\top X)}\)</span> is the smallest singular value of <span class="math inline">\(X\)</span>,
computed as the square root of the smallest eigenvalue of <span class="math inline">\(X^\top X\)</span>.</p>
</div>
<p>As a rule of thumb, if <span class="math inline">\(\kappa(X) &lt; 10\)</span> there are no significant problems
with multicollinearity, and if <span class="math inline">\(\kappa(X) &gt; 30\)</span> the regression problem
sufferes severe problems with multicollinearity. In the case where the
columns of <span class="math inline">\(X\)</span> are exactly linearly dependent, we have <span class="math inline">\(\sigma_\mathrm{min}(X)
= 0\)</span> and <span class="math inline">\(\kappa(X) = \infty\)</span>.</p>
<p>In R, the condition number can be computed using the
<a href="https://rdrr.io/r/base/kappa.html">function <code>kappa()</code></a>. The function
can either be called as <code>kappa(X, exact = TRUE)</code>,
where <code>X</code> is the design matrix,
or as <code>kappa(m, exact = TRUE)</code>
where <code>m</code> is the object returned by <code>lm()</code>. If the optional
argument <code>exact = TRUE</code> is omitted, only an approximate result
is returned (using a faster algorithm).</p>
<div class="example">
<p><span id="exm:multcoll3" class="example"><strong>Example 15.3  </strong></span>Consider the following toy dataset:</p>
<div class="sourceCode" id="cb244"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb244-1"><a href="S15-multicoll.html#cb244-1" tabindex="-1"></a>data</span></code></pre></div>
<pre class="routput"><code>       y   x.1    x.2    x.3    x.4
1   7.37 4.182  0.078  0.008  1.043
2   9.86 6.039  1.106 -0.009  0.137
3  13.44 9.220  0.151 -0.158  0.965
4  12.95 8.260 -0.018  1.133  0.203
5  13.05 8.415  1.078  0.057  0.002
6  13.17 9.272 -0.019  0.062  0.974
7   5.28 1.575 -0.160  1.031  0.099
8   8.18 4.595  0.091  0.014  0.909
9   5.13 2.779 -0.074  0.923 -0.004
10  6.80 2.248 -0.045  0.182  1.088</code></pre>
<p>To inspect these data, we use a pair scatter plot of the input variables,
leaving out the responses in column 1:</p>
<div class="sourceCode" id="cb246"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb246-1"><a href="S15-multicoll.html#cb246-1" tabindex="-1"></a><span class="fu">pairs</span>(data[,<span class="sc">-</span><span class="dv">1</span>])</span></code></pre></div>
<p><img src="MATH3714_files/figure-html/multicollairs-1.png" width="672" /></p>
<p>While there are visbile patterns, there are no clear signs of
a linear dependency between any two columns.
To see whether there are problems with multicollinearity, we fit
a linear model and determine the condition number.</p>
<div class="sourceCode" id="cb247"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb247-1"><a href="S15-multicoll.html#cb247-1" tabindex="-1"></a>m <span class="ot">&lt;-</span> <span class="fu">lm</span>(y <span class="sc">~</span> ., <span class="at">data =</span> data)</span>
<span id="cb247-2"><a href="S15-multicoll.html#cb247-2" tabindex="-1"></a><span class="fu">kappa</span>(m, <span class="at">exact =</span> <span class="cn">TRUE</span>)</span></code></pre></div>
<pre class="routput"><code>[1] 97.38214</code></pre>
<p>Since the condition number is larger than 30, we can say that the
data shows severe multicollinearity.</p>
<p>To find out which variables
are involved, we can use <a href="https://en.wikipedia.org/wiki/Singular_value_decomposition">singular value decomposition</a>.
This allows to write <span class="math inline">\(X\)</span> as <span class="math inline">\(X = U D V^\top\)</span>, where <span class="math inline">\(D\in\mathbb{R}^{(p+1)\times(p+1)}\)</span>
is a diagonal matrix and <span class="math inline">\(U\in\mathbb{R}^{n\times(p+1)}\)</span> and
<span class="math inline">\(V\in\mathbb{R}^{(p+1)\times(p+1)}\)</span> are matrices with orthonormal columns.</p>
<div class="sourceCode" id="cb249"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb249-1"><a href="S15-multicoll.html#cb249-1" tabindex="-1"></a>X <span class="ot">&lt;-</span> <span class="fu">model.matrix</span>(m)</span>
<span id="cb249-2"><a href="S15-multicoll.html#cb249-2" tabindex="-1"></a>s <span class="ot">&lt;-</span> <span class="fu">svd</span>(X, <span class="at">nu =</span> <span class="dv">0</span>)</span>
<span id="cb249-3"><a href="S15-multicoll.html#cb249-3" tabindex="-1"></a>s</span></code></pre></div>
<pre class="routput"><code>$d
[1] 20.3002516  2.0294781  1.8122508  1.2526330  0.2084597

$v
            [,1]       [,2]        [,3]        [,4]          [,5]
[1,] -0.14024576 -0.5552821 -0.04218055 -0.62161197  0.5327403485
[2,] -0.98554152  0.1088264  0.04131956  0.12311216  0.0009051211
[3,] -0.04170949  0.4036310  0.21603327 -0.75981456 -0.4597323397
[4,] -0.03395454 -0.6495911  0.55665792  0.11926737 -0.5027780067
[5,] -0.07839927 -0.3081105 -0.79998442 -0.08306065 -0.5020431792</code></pre>
<p>We used the optional argument <code>nu = 0</code> to tell R that we won’t need the
matrix <span class="math inline">\(U\)</span>. The diagonal elements <span class="math inline">\(\sigma_0(X), \ldots, \sigma_{p}(X) \geq 0\)</span>,
stored in <code>s$d</code>, are the singular values of <span class="math inline">\(X\)</span> in decreasing order.
We can find the condition number using these values:</p>
<div class="sourceCode" id="cb251"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb251-1"><a href="S15-multicoll.html#cb251-1" tabindex="-1"></a>s<span class="sc">$</span>d[<span class="dv">1</span>] <span class="sc">/</span> s<span class="sc">$</span>d[<span class="fu">length</span>(s<span class="sc">$</span>d)]</span></code></pre></div>
<pre class="routput"><code>[1] 97.38214</code></pre>
<p>This agrees with the value for <span class="math inline">\(\kappa(X)\)</span> we found above.</p>
<p>Finally, the columns <span class="math inline">\(v_1, \ldots, v_{p+1}\)</span> of <code>s$v</code> are called the (right)
singular vectors of <span class="math inline">\(X\)</span>. We can use these vectors to identify which variables
are involved in multicollinearity: It is easy to show that <span class="math inline">\(\| X v_k \| =
\sigma_k(X)\)</span>, so every “small” <span class="math inline">\(\sigma_k(X)\)</span> corresponds to a vector <span class="math inline">\(v_k\)</span>
which describes an approximate linear dependency between the columns of <span class="math inline">\(X\)</span>.
Looking at <span class="math inline">\(\sigma_4(X)\)</span> (the 5th element of <code>s$d</code>) we get</p>
<div class="sourceCode" id="cb253"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb253-1"><a href="S15-multicoll.html#cb253-1" tabindex="-1"></a><span class="fu">round</span>(s<span class="sc">$</span>v[,<span class="dv">5</span>], <span class="dv">3</span>)</span></code></pre></div>
<pre class="routput"><code>[1]  0.533  0.001 -0.460 -0.503 -0.502</code></pre>
<p>Rounding the numbers some more and remembering that the first
value corresponds to the intercept, we get that
<span class="math display">\[\begin{equation*}
  -0.5 \cdot 1 + 0.5 \cdot x_2 + 0.5 \cdot x_3 + 0.5 \cdot x_4
  \approx 0
\end{equation*}\]</span>
or, equivalently
<span class="math display">\[\begin{equation*}
  x_2 + x_3 + x_4
  \approx 1.
\end{equation*}\]</span>
Looking back over the original numbers we see that this relation
indeed holds.</p>
</div>
</div>
<div id="mitigations" class="section level2 hasAnchor" number="15.3">
<h2><span class="header-section-number">15.3</span> Mitigations<a href="S15-multicoll.html#mitigations" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>There are various ways problems resulting from multicollinearity can
be addressed:</p>
<ul>
<li><p>Sometimes columns are linearly dependent, because a redundant input
is present. Removing one of the input variables in a group
of linearly dependent inputs can solve this problem.</p></li>
<li><p>The inputs can be transformed by choosing new variables as functions
of the original inputs. For example, in example <a href="S15-multicoll.html#exm:mulcollell">15.2</a>
one could try the input variables <span class="math inline">\(\tilde x_1 = (x_1 + x_2) / 2\)</span> and
<span class="math inline">\(\tilde x_2 = (x_1 - x_2) / 2\)</span>. The confidence ellipse shown above
indicates that it should be possible to get good estimates for the
coefficient corresponding to <span class="math inline">\(\tilde x_1\)</span>.</p></li>
<li><p>If <span class="math inline">\(n\)</span> is small, the problem may be resolved by getting more data.
In particular, for <span class="math inline">\(n &lt; p+1\)</span>, we <em>always</em> have strict multicollinearity,
so in this case we definitely need more data.</p></li>
<li><p>Alternative estimation approaches may be used. The basic idea is to sacrifice the
requirement that <span class="math inline">\(\hat\beta\)</span> is unbiased, in exchange for a large variance
reduction. In the next section we will discuss “ridge regression” as an
example of this approach.</p></li>
</ul>
<div class="mysummary">
<p><strong>Summary</strong></p>
<ul>
<li>Multicollinearity can lead to numerical problems and large variances in the
estimated regression coefficients.</li>
<li>The condition number of the design matrix can be used to detect
multicollinearity.</li>
<li>Singular value decomposition can used to better understand linear
dependencies in the inputs.</li>
</ul>
</div>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="S14-examples.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="P04.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": null,
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["MATH3714.pdf"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
