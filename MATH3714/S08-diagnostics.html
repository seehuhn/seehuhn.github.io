<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Section 8 Regression Diagnostics | MATH3714 Linear Regression and Robustness</title>
  <meta name="description" content="Lecture notes for the course MATH3714 Linear Regression and Robustness at the University of Leeds, 2021/22" />
  <meta name="generator" content="bookdown 0.24 and GitBook 2.6.7" />

  <meta property="og:title" content="Section 8 Regression Diagnostics | MATH3714 Linear Regression and Robustness" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="https://seehuhn.github.io/MATH3714/" />
  
  <meta property="og:description" content="Lecture notes for the course MATH3714 Linear Regression and Robustness at the University of Leeds, 2021/22" />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Section 8 Regression Diagnostics | MATH3714 Linear Regression and Robustness" />
  
  <meta name="twitter:description" content="Lecture notes for the course MATH3714 Linear Regression and Robustness at the University of Leeds, 2021/22" />
  

<meta name="author" content="Jochen Voss" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="P02.html"/>
<link rel="next" href="S09-influence.html"/>
<script src="libs/header-attrs-2.11/header-attrs.js"></script>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-P96L0SF56N"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-P96L0SF56N');
</script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./index.html">MATH3714 Notes</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="chapter" data-level="" data-path="S00-about.html"><a href="S00-about.html"><i class="fa fa-check"></i>About MATH3714</a>
<ul>
<li class="chapter" data-level="" data-path="S00-about.html"><a href="S00-about.html#notes"><i class="fa fa-check"></i>Notes and videos</a></li>
<li class="chapter" data-level="" data-path="S00-about.html"><a href="S00-about.html#lectures"><i class="fa fa-check"></i>Lectures</a></li>
<li class="chapter" data-level="" data-path="S00-about.html"><a href="S00-about.html#workshops"><i class="fa fa-check"></i>Workshops and Problem Sheets</a></li>
<li class="chapter" data-level="" data-path="S00-about.html"><a href="S00-about.html#teams"><i class="fa fa-check"></i>Discussion Board</a></li>
<li class="chapter" data-level="" data-path="S00-about.html"><a href="S00-about.html#software"><i class="fa fa-check"></i>Software</a></li>
<li class="chapter" data-level="" data-path="S00-about.html"><a href="S00-about.html#assessments"><i class="fa fa-check"></i>Assessments</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="S01-simple.html"><a href="S01-simple.html"><i class="fa fa-check"></i><b>1</b> Simple Linear Regression</a>
<ul>
<li class="chapter" data-level="1.1" data-path="S01-simple.html"><a href="S01-simple.html#residual-sum-of-squares"><i class="fa fa-check"></i><b>1.1</b> Residual Sum of Squares</a></li>
<li class="chapter" data-level="1.2" data-path="S01-simple.html"><a href="S01-simple.html#linear-regression-as-a-parameter-estimation-problem"><i class="fa fa-check"></i><b>1.2</b> Linear Regression as a Parameter Estimation Problem</a></li>
<li class="chapter" data-level="1.3" data-path="S01-simple.html"><a href="S01-simple.html#sec:simple-mat"><i class="fa fa-check"></i><b>1.3</b> Matrix Notation</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="S02-multiple.html"><a href="S02-multiple.html"><i class="fa fa-check"></i><b>2</b> Least Squares Estimates</a>
<ul>
<li class="chapter" data-level="2.1" data-path="S02-multiple.html"><a href="S02-multiple.html#data-and-models"><i class="fa fa-check"></i><b>2.1</b> Data and Models</a></li>
<li class="chapter" data-level="2.2" data-path="S02-multiple.html"><a href="S02-multiple.html#the-normal-equations"><i class="fa fa-check"></i><b>2.2</b> The Normal Equations</a></li>
<li class="chapter" data-level="2.3" data-path="S02-multiple.html"><a href="S02-multiple.html#fitted-values"><i class="fa fa-check"></i><b>2.3</b> Fitted Values</a></li>
<li class="chapter" data-level="2.4" data-path="S02-multiple.html"><a href="S02-multiple.html#example"><i class="fa fa-check"></i><b>2.4</b> Example</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="I01-lm.html"><a href="I01-lm.html"><i class="fa fa-check"></i>Interlude: Linear Regression in R</a>
<ul>
<li class="chapter" data-level="" data-path="I01-lm.html"><a href="I01-lm.html#lm-fitting"><i class="fa fa-check"></i>Fitting a Model</a></li>
<li class="chapter" data-level="" data-path="I01-lm.html"><a href="I01-lm.html#lm-model"><i class="fa fa-check"></i>Understanding the Model</a></li>
<li class="chapter" data-level="" data-path="I01-lm.html"><a href="I01-lm.html#lm-predict"><i class="fa fa-check"></i>Making Predictions</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="P01.html"><a href="P01.html"><i class="fa fa-check"></i>Problem Sheet 1</a></li>
<li class="chapter" data-level="3" data-path="S03-cov.html"><a href="S03-cov.html"><i class="fa fa-check"></i><b>3</b> Random Vectors and Covariance</a>
<ul>
<li class="chapter" data-level="3.1" data-path="S03-cov.html"><a href="S03-cov.html#expectation"><i class="fa fa-check"></i><b>3.1</b> Expectation</a></li>
<li class="chapter" data-level="3.2" data-path="S03-cov.html"><a href="S03-cov.html#sec:covariance"><i class="fa fa-check"></i><b>3.2</b> Covariance Matrix</a></li>
<li class="chapter" data-level="3.3" data-path="S03-cov.html"><a href="S03-cov.html#the-multivariate-normal-distribution"><i class="fa fa-check"></i><b>3.3</b> The Multivariate Normal Distribution</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="S04-model.html"><a href="S04-model.html"><i class="fa fa-check"></i><b>4</b> Properties of the Least Squares Estimate</a>
<ul>
<li class="chapter" data-level="4.1" data-path="S04-model.html"><a href="S04-model.html#mean-and-covariance"><i class="fa fa-check"></i><b>4.1</b> Mean and Covariance</a></li>
<li class="chapter" data-level="4.2" data-path="S04-model.html"><a href="S04-model.html#hat-matrix"><i class="fa fa-check"></i><b>4.2</b> Properties of the Hat Matrix</a></li>
<li class="chapter" data-level="4.3" data-path="S04-model.html"><a href="S04-model.html#Cochran"><i class="fa fa-check"></i><b>4.3</b> Cochran’s theorem</a></li>
<li class="chapter" data-level="4.4" data-path="S04-model.html"><a href="S04-model.html#var-est-bias"><i class="fa fa-check"></i><b>4.4</b> Estimating the Error Variance</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="S05-single.html"><a href="S05-single.html"><i class="fa fa-check"></i><b>5</b> Uncertainty for Individual Regression Coefficients</a>
<ul>
<li class="chapter" data-level="5.1" data-path="S05-single.html"><a href="S05-single.html#measuring-the-estimation-error"><i class="fa fa-check"></i><b>5.1</b> Measuring the Estimation Error</a></li>
<li class="chapter" data-level="5.2" data-path="S05-single.html"><a href="S05-single.html#confidence-intervals"><i class="fa fa-check"></i><b>5.2</b> Confidence Intervals</a></li>
<li class="chapter" data-level="5.3" data-path="S05-single.html"><a href="S05-single.html#hypthesis-tests"><i class="fa fa-check"></i><b>5.3</b> Hypthesis Tests</a></li>
<li class="chapter" data-level="5.4" data-path="S05-single.html"><a href="S05-single.html#r-experiments"><i class="fa fa-check"></i><b>5.4</b> R Experiments</a>
<ul>
<li class="chapter" data-level="5.4.1" data-path="S05-single.html"><a href="S05-single.html#fitting-the-model"><i class="fa fa-check"></i><b>5.4.1</b> Fitting the model</a></li>
<li class="chapter" data-level="5.4.2" data-path="S05-single.html"><a href="S05-single.html#estimating-the-variance-of-the-error"><i class="fa fa-check"></i><b>5.4.2</b> Estimating the Variance of the Error</a></li>
<li class="chapter" data-level="5.4.3" data-path="S05-single.html"><a href="S05-single.html#estimating-the-standard-errors"><i class="fa fa-check"></i><b>5.4.3</b> Estimating the Standard Errors</a></li>
<li class="chapter" data-level="5.4.4" data-path="S05-single.html"><a href="S05-single.html#hypothesis-tests"><i class="fa fa-check"></i><b>5.4.4</b> Hypothesis tests</a></li>
<li class="chapter" data-level="5.4.5" data-path="S05-single.html"><a href="S05-single.html#confidence-intervals-1"><i class="fa fa-check"></i><b>5.4.5</b> Confidence Intervals</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="S06-simultaneous.html"><a href="S06-simultaneous.html"><i class="fa fa-check"></i><b>6</b> Estimating Coefficients Simultaneously</a>
<ul>
<li class="chapter" data-level="6.1" data-path="S06-simultaneous.html"><a href="S06-simultaneous.html#sec:simult-dist"><i class="fa fa-check"></i><b>6.1</b> Linear Combinations of Coefficients</a></li>
<li class="chapter" data-level="6.2" data-path="S06-simultaneous.html"><a href="S06-simultaneous.html#sec:simult-CI"><i class="fa fa-check"></i><b>6.2</b> Confidence Regions</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="S06-simultaneous.html"><a href="S06-simultaneous.html#result"><i class="fa fa-check"></i><b>6.2.1</b> Result</a></li>
<li class="chapter" data-level="6.2.2" data-path="S06-simultaneous.html"><a href="S06-simultaneous.html#numerical-experiments"><i class="fa fa-check"></i><b>6.2.2</b> Numerical Experiments</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="S06-simultaneous.html"><a href="S06-simultaneous.html#sec:simult-test"><i class="fa fa-check"></i><b>6.3</b> Hypothesis Tests</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="I02-read.html"><a href="I02-read.html"><i class="fa fa-check"></i>Interlude: Loading Data into R</a>
<ul>
<li class="chapter" data-level="" data-path="I02-read.html"><a href="I02-read.html#importing-csv-files"><i class="fa fa-check"></i>Importing CSV Files</a></li>
<li class="chapter" data-level="" data-path="I02-read.html"><a href="I02-read.html#importing-microsoft-excel-files"><i class="fa fa-check"></i>Importing Microsoft Excel Files</a></li>
<li class="chapter" data-level="" data-path="I02-read.html"><a href="I02-read.html#checking-the-imported-data"><i class="fa fa-check"></i>Checking the Imported Data</a></li>
<li class="chapter" data-level="" data-path="I02-read.html"><a href="I02-read.html#common-problems"><i class="fa fa-check"></i>Common Problems</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="S07-examples.html"><a href="S07-examples.html"><i class="fa fa-check"></i><b>7</b> Examples</a>
<ul>
<li class="chapter" data-level="7.1" data-path="S07-examples.html"><a href="S07-examples.html#simple-confidence-interval"><i class="fa fa-check"></i><b>7.1</b> Simple Confidence Interval</a>
<ul>
<li class="chapter" data-level="7.1.1" data-path="S07-examples.html"><a href="S07-examples.html#from-first-principles"><i class="fa fa-check"></i><b>7.1.1</b> From First Principles</a></li>
<li class="chapter" data-level="7.1.2" data-path="S07-examples.html"><a href="S07-examples.html#from-the-lm-output"><i class="fa fa-check"></i><b>7.1.2</b> From the <code>lm()</code> Output</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="S07-examples.html"><a href="S07-examples.html#confidence-intervals-for-the-mean"><i class="fa fa-check"></i><b>7.2</b> Confidence Intervals for the Mean</a></li>
<li class="chapter" data-level="7.3" data-path="S07-examples.html"><a href="S07-examples.html#testing-a-single-coefficient"><i class="fa fa-check"></i><b>7.3</b> Testing a Single Coefficient</a>
<ul>
<li class="chapter" data-level="7.3.1" data-path="S07-examples.html"><a href="S07-examples.html#from-first-principles-1"><i class="fa fa-check"></i><b>7.3.1</b> From First Principles</a></li>
<li class="chapter" data-level="7.3.2" data-path="S07-examples.html"><a href="S07-examples.html#using-the-lm-output-i"><i class="fa fa-check"></i><b>7.3.2</b> Using the <code>lm()</code> Output, I</a></li>
<li class="chapter" data-level="7.3.3" data-path="S07-examples.html"><a href="S07-examples.html#using-the-lm-output-ii"><i class="fa fa-check"></i><b>7.3.3</b> Using the <code>lm()</code> Output, II</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="S07-examples.html"><a href="S07-examples.html#testing-multiple-coefficents"><i class="fa fa-check"></i><b>7.4</b> Testing Multiple Coefficents</a>
<ul>
<li class="chapter" data-level="7.4.1" data-path="S07-examples.html"><a href="S07-examples.html#from-first-principles-2"><i class="fa fa-check"></i><b>7.4.1</b> From First Principles</a></li>
<li class="chapter" data-level="7.4.2" data-path="S07-examples.html"><a href="S07-examples.html#using-the-lm-output"><i class="fa fa-check"></i><b>7.4.2</b> Using the <code>lm()</code> output</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="P02.html"><a href="P02.html"><i class="fa fa-check"></i>Problem Sheet 2</a></li>
<li class="chapter" data-level="8" data-path="S08-diagnostics.html"><a href="S08-diagnostics.html"><i class="fa fa-check"></i><b>8</b> Regression Diagnostics</a>
<ul>
<li class="chapter" data-level="8.1" data-path="S08-diagnostics.html"><a href="S08-diagnostics.html#plots"><i class="fa fa-check"></i><b>8.1</b> Diagnostic Plots</a></li>
<li class="chapter" data-level="8.2" data-path="S08-diagnostics.html"><a href="S08-diagnostics.html#R-squared"><i class="fa fa-check"></i><b>8.2</b> The Coefficient of Multiple Determination</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="S09-influence.html"><a href="S09-influence.html"><i class="fa fa-check"></i><b>9</b> The Influence of Observations</a>
<ul>
<li class="chapter" data-level="9.1" data-path="S09-influence.html"><a href="S09-influence.html#deleting-observations"><i class="fa fa-check"></i><b>9.1</b> Deleting Observations</a></li>
<li class="chapter" data-level="9.2" data-path="S09-influence.html"><a href="S09-influence.html#cooks-distance"><i class="fa fa-check"></i><b>9.2</b> Cook’s Distance</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="S10-multicoll.html"><a href="S10-multicoll.html"><i class="fa fa-check"></i><b>10</b> Multicollinearity</a>
<ul>
<li class="chapter" data-level="10.1" data-path="S10-multicoll.html"><a href="S10-multicoll.html#consequences-of-multicollinearity"><i class="fa fa-check"></i><b>10.1</b> Consequences of Multicollinearity</a></li>
<li class="chapter" data-level="10.2" data-path="S10-multicoll.html"><a href="S10-multicoll.html#detecting-multicollinearity"><i class="fa fa-check"></i><b>10.2</b> Detecting Multicollinearity</a></li>
<li class="chapter" data-level="10.3" data-path="S10-multicoll.html"><a href="S10-multicoll.html#mitigations"><i class="fa fa-check"></i><b>10.3</b> Mitigations</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="P03.html"><a href="P03.html"><i class="fa fa-check"></i>Problem Sheet 3</a></li>
<li class="chapter" data-level="11" data-path="S11-improving.html"><a href="S11-improving.html"><i class="fa fa-check"></i><b>11</b> Improving the Model Fit</a>
<ul>
<li class="chapter" data-level="11.1" data-path="S11-improving.html"><a href="S11-improving.html#linearising-the-mean"><i class="fa fa-check"></i><b>11.1</b> Linearising the Mean</a></li>
<li class="chapter" data-level="11.2" data-path="S11-improving.html"><a href="S11-improving.html#stabilising-the-variance"><i class="fa fa-check"></i><b>11.2</b> Stabilising the Variance</a></li>
<li class="chapter" data-level="11.3" data-path="S11-improving.html"><a href="S11-improving.html#power-transform"><i class="fa fa-check"></i><b>11.3</b> The Power Transform</a></li>
<li class="chapter" data-level="11.4" data-path="S11-improving.html"><a href="S11-improving.html#orthogonal-inputs"><i class="fa fa-check"></i><b>11.4</b> Orthogonal Inputs</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="S12-ridge.html"><a href="S12-ridge.html"><i class="fa fa-check"></i><b>12</b> Ridge Regression</a>
<ul>
<li class="chapter" data-level="12.1" data-path="S12-ridge.html"><a href="S12-ridge.html#definition-the-estimator"><i class="fa fa-check"></i><b>12.1</b> Definition the Estimator</a></li>
<li class="chapter" data-level="12.2" data-path="S12-ridge.html"><a href="S12-ridge.html#properties-of-the-estimate"><i class="fa fa-check"></i><b>12.2</b> Properties of the Estimate</a>
<ul>
<li class="chapter" data-level="12.2.1" data-path="S12-ridge.html"><a href="S12-ridge.html#bias"><i class="fa fa-check"></i><b>12.2.1</b> Bias</a></li>
<li class="chapter" data-level="12.2.2" data-path="S12-ridge.html"><a href="S12-ridge.html#variance"><i class="fa fa-check"></i><b>12.2.2</b> Variance</a></li>
<li class="chapter" data-level="12.2.3" data-path="S12-ridge.html"><a href="S12-ridge.html#mean-squared-error"><i class="fa fa-check"></i><b>12.2.3</b> Mean Squared Error</a></li>
</ul></li>
<li class="chapter" data-level="12.3" data-path="S12-ridge.html"><a href="S12-ridge.html#standardisation"><i class="fa fa-check"></i><b>12.3</b> Standardisation</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="S13-models.html"><a href="S13-models.html"><i class="fa fa-check"></i><b>13</b> Model selection</a>
<ul>
<li class="chapter" data-level="13.1" data-path="S13-models.html"><a href="S13-models.html#candidates-models"><i class="fa fa-check"></i><b>13.1</b> Candidates Models</a></li>
<li class="chapter" data-level="13.2" data-path="S13-models.html"><a href="S13-models.html#misspecified-models"><i class="fa fa-check"></i><b>13.2</b> Misspecified Models</a>
<ul>
<li class="chapter" data-level="13.2.1" data-path="S13-models.html"><a href="S13-models.html#missing-variables"><i class="fa fa-check"></i><b>13.2.1</b> Missing Variables</a></li>
<li class="chapter" data-level="13.2.2" data-path="S13-models.html"><a href="S13-models.html#unnecessary-variables"><i class="fa fa-check"></i><b>13.2.2</b> Unnecessary Variables</a></li>
</ul></li>
<li class="chapter" data-level="13.3" data-path="S13-models.html"><a href="S13-models.html#criteria"><i class="fa fa-check"></i><b>13.3</b> Assessing Models</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="P04.html"><a href="P04.html"><i class="fa fa-check"></i>Problem Sheet 4</a></li>
<li class="chapter" data-level="14" data-path="S14-methods.html"><a href="S14-methods.html"><i class="fa fa-check"></i><b>14</b> Methods for Model Selection</a>
<ul>
<li class="chapter" data-level="14.1" data-path="S14-methods.html"><a href="S14-methods.html#exhaustive-search"><i class="fa fa-check"></i><b>14.1</b> Exhaustive Search</a></li>
<li class="chapter" data-level="14.2" data-path="S14-methods.html"><a href="S14-methods.html#search-algorithm"><i class="fa fa-check"></i><b>14.2</b> Search Algorithm</a></li>
<li class="chapter" data-level="14.3" data-path="S14-methods.html"><a href="S14-methods.html#other-methods"><i class="fa fa-check"></i><b>14.3</b> Other Methods</a>
<ul>
<li class="chapter" data-level="14.3.1" data-path="S14-methods.html"><a href="S14-methods.html#stepwise-forward-selection"><i class="fa fa-check"></i><b>14.3.1</b> Stepwise Forward Selection</a></li>
<li class="chapter" data-level="14.3.2" data-path="S14-methods.html"><a href="S14-methods.html#stepwise-backward-selection"><i class="fa fa-check"></i><b>14.3.2</b> Stepwise Backward Selection</a></li>
<li class="chapter" data-level="14.3.3" data-path="S14-methods.html"><a href="S14-methods.html#hybrid-methods"><i class="fa fa-check"></i><b>14.3.3</b> Hybrid Methods</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="15" data-path="S15-factors.html"><a href="S15-factors.html"><i class="fa fa-check"></i><b>15</b> Factors</a>
<ul>
<li class="chapter" data-level="15.1" data-path="S15-factors.html"><a href="S15-factors.html#indicator-variables"><i class="fa fa-check"></i><b>15.1</b> Indicator Variables</a></li>
<li class="chapter" data-level="15.2" data-path="S15-factors.html"><a href="S15-factors.html#interactions"><i class="fa fa-check"></i><b>15.2</b> Interactions</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="practical.html"><a href="practical.html"><i class="fa fa-check"></i>Practical</a>
<ul>
<li class="chapter" data-level="" data-path="practical.html"><a href="practical.html#dataset"><i class="fa fa-check"></i>Dataset</a></li>
<li class="chapter" data-level="" data-path="practical.html"><a href="practical.html#tasks"><i class="fa fa-check"></i>Tasks</a></li>
<li class="chapter" data-level="" data-path="practical.html"><a href="practical.html#references"><i class="fa fa-check"></i>References</a></li>
</ul></li>
<li class="chapter" data-level="16" data-path="S16-examples.html"><a href="S16-examples.html"><i class="fa fa-check"></i><b>16</b> Examples</a>
<ul>
<li class="chapter" data-level="16.1" data-path="S16-examples.html"><a href="S16-examples.html#interactions-example"><i class="fa fa-check"></i><b>16.1</b> Use of Interaction Terms in Modelling</a></li>
<li class="chapter" data-level="16.2" data-path="S16-examples.html"><a href="S16-examples.html#codings"><i class="fa fa-check"></i><b>16.2</b> Alternative Factor Codings</a></li>
</ul></li>
<li class="appendix"><span><b>Appendices</b></span></li>
<li class="chapter" data-level="A" data-path="Sx1-matrices.html"><a href="Sx1-matrices.html"><i class="fa fa-check"></i><b>A</b> Linear Algebra Reminders</a>
<ul>
<li class="chapter" data-level="A.1" data-path="Sx1-matrices.html"><a href="Sx1-matrices.html#vectors"><i class="fa fa-check"></i><b>A.1</b> Vectors</a></li>
<li class="chapter" data-level="A.2" data-path="Sx1-matrices.html"><a href="Sx1-matrices.html#matrix-rules"><i class="fa fa-check"></i><b>A.2</b> Matrices</a>
<ul>
<li class="chapter" data-level="A.2.1" data-path="Sx1-matrices.html"><a href="Sx1-matrices.html#transpose"><i class="fa fa-check"></i><b>A.2.1</b> Transpose</a></li>
<li class="chapter" data-level="A.2.2" data-path="Sx1-matrices.html"><a href="Sx1-matrices.html#matrix-vector-product"><i class="fa fa-check"></i><b>A.2.2</b> Matrix-vector Product</a></li>
<li class="chapter" data-level="A.2.3" data-path="Sx1-matrices.html"><a href="Sx1-matrices.html#matrix-matrix-product"><i class="fa fa-check"></i><b>A.2.3</b> Matrix-matrix Product</a></li>
<li class="chapter" data-level="A.2.4" data-path="Sx1-matrices.html"><a href="Sx1-matrices.html#rank"><i class="fa fa-check"></i><b>A.2.4</b> Rank</a></li>
<li class="chapter" data-level="A.2.5" data-path="Sx1-matrices.html"><a href="Sx1-matrices.html#trace"><i class="fa fa-check"></i><b>A.2.5</b> Trace</a></li>
<li class="chapter" data-level="A.2.6" data-path="Sx1-matrices.html"><a href="Sx1-matrices.html#matrix-inverse"><i class="fa fa-check"></i><b>A.2.6</b> Matrix Inverse</a></li>
<li class="chapter" data-level="A.2.7" data-path="Sx1-matrices.html"><a href="Sx1-matrices.html#orthogonal-matrices"><i class="fa fa-check"></i><b>A.2.7</b> Orthogonal Matrices</a></li>
<li class="chapter" data-level="A.2.8" data-path="Sx1-matrices.html"><a href="Sx1-matrices.html#positive-definite"><i class="fa fa-check"></i><b>A.2.8</b> Positive Definite Matrices</a></li>
<li class="chapter" data-level="A.2.9" data-path="Sx1-matrices.html"><a href="Sx1-matrices.html#idempotent"><i class="fa fa-check"></i><b>A.2.9</b> Idempotent Matrices</a></li>
</ul></li>
<li class="chapter" data-level="A.3" data-path="Sx1-matrices.html"><a href="Sx1-matrices.html#eigenvalues"><i class="fa fa-check"></i><b>A.3</b> Eigenvalues</a></li>
</ul></li>
<li class="chapter" data-level="B" data-path="Sx2-probability.html"><a href="Sx2-probability.html"><i class="fa fa-check"></i><b>B</b> Probability Reminders</a>
<ul>
<li class="chapter" data-level="B.1" data-path="Sx2-probability.html"><a href="Sx2-probability.html#independence"><i class="fa fa-check"></i><b>B.1</b> Independence</a></li>
<li class="chapter" data-level="B.2" data-path="Sx2-probability.html"><a href="Sx2-probability.html#chi-square"><i class="fa fa-check"></i><b>B.2</b> The Chi-Squared Distribution</a></li>
<li class="chapter" data-level="B.3" data-path="Sx2-probability.html"><a href="Sx2-probability.html#t"><i class="fa fa-check"></i><b>B.3</b> The t-distribution</a></li>
</ul></li>
<li class="divider"></li>
<li class="chapter"><span><b>THE END</b></span></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">MATH3714 Linear Regression and Robustness</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="S08-diagnostics" class="section level1" number="8">
<h1><span class="header-section-number">Section 8</span> Regression Diagnostics</h1>
<p>The traditional principle of data analysis could be described by the following
steps</p>
<ol style="list-style-type: decimal">
<li>Explore the data; identify a plausible model.</li>
<li>Estimate any parameters specified by the model.</li>
<li>Check that the model is adequate — often by examining the discrepancy
between the observed data and that predicted (or fitted) by the model — if
necessary go back a step with a refined/revised model.</li>
<li>See if the model can be simplified; if necessary go to step 2.</li>
<li>Conclude (using the results as required).</li>
</ol>
<p>In (multiple) regression there are many checks which can be used in step 3.
These can consider the model as a whole, or be very specific by examining each
observation, and the effect it has on the model.</p>
<div id="plots" class="section level2" number="8.1">
<h2><span class="header-section-number">8.1</span> Diagnostic Plots</h2>
<div class="videowrap">
<div class="videowrapper">
<iframe width="560" height="315" src="https://www.youtube.com/embed/AOZICnbvLms" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen>
</iframe>
</div>
</div>
<p>The regression model is often checked by examining the residuals. Various plots
are used:</p>
<ol style="list-style-type: decimal">
<li><p>A scatter plot of the response <span class="math inline">\(y\)</span> against each of the explanatory
variables <span class="math inline">\(x_j\)</span> for <span class="math inline">\(j \in \{1, \ldots, p\}\)</span>.</p></li>
<li><p>A scatter plot of <span class="math inline">\(\hat\varepsilon\)</span> against each of the explanatory variables
<span class="math inline">\(x_j\)</span> for <span class="math inline">\(j \in \{1, \ldots, p\}\)</span>. The presence of a curvilinear
relationship (in this plot, or the ones above) suggests a higher-order term,
perhaps a quadratic in the explanatory variable, should be added to the
model. Or possibly a transformation.</p></li>
<li><p>A plot of <span class="math inline">\(\hat\varepsilon_i\)</span> <em>vs.</em> <span class="math inline">\(\hat y_i\)</span>. If the variance of the residuals
seems to increase with <span class="math inline">\(\hat y\)</span> then a transformation may be necessary.</p></li>
<li><p>A plot of <span class="math inline">\(\hat\varepsilon_i\)</span> <em>vs.</em> any explanatory variables not
used in the model. A relationship suggests that the variable should be
included.</p></li>
<li><p>A <a href="https://en.wikipedia.org/wiki/Q%E2%80%93Q_plot">Q-Q plot</a>
of the residuals can be used to assess whether the residuals are normally
distributed. These plots plot quantiles of the data against quantiles
of a normal distribution. If the residual are normally distributed,
the points in a Q-Q plot will approximately lie on a straight line.
(Most inference assumes that the errors are normally distributed, though
the least squares estimate for <span class="math inline">\(\hat\beta\)</span> itself does not.) The R
command to produce Q-Q plots for the normal distribution is <code>qqnorm()</code>.</p></li>
<li><p>Data are often collected in time order. Even if time is not an explanatory
variable, a plot of <span class="math inline">\(y\)</span> <em>vs.</em> time can be of interest. It can reveal
serial correlation in the data. Similarly, plotting the residuals <em>vs.</em>
time.</p></li>
<li><p>A plot of <span class="math inline">\(x_j\)</span> <em>vs.</em> <span class="math inline">\(x_k\)</span> for <span class="math inline">\(j\neq k\)</span> can also be useful.
If two or more regressors are highly correlated, we say that
multicollinearity is present. When this occurs the least squares estimate
<span class="math inline">\(\hat\beta\)</span> becomes numerically unstable.</p></li>
</ol>
<div class="example">
<p><span id="exm:stackloss-plot" class="example"><strong>Example 8.1  </strong></span>An example for the first type of diagnostic plot would be to
plot <code>stack.loss</code> against <code>Water.Temp</code> for the <code>stackloss</code> dataset:</p>
<div class="sourceCode" id="cb125"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb125-1"><a href="S08-diagnostics.html#cb125-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(stackloss<span class="sc">$</span>Water.Temp, stackloss<span class="sc">$</span>stack.loss,</span>
<span id="cb125-2"><a href="S08-diagnostics.html#cb125-2" aria-hidden="true" tabindex="-1"></a>     <span class="at">xlab =</span> <span class="st">&quot;water temperature&quot;</span>, <span class="at">ylab =</span> <span class="st">&quot;Stack loss&quot;</span>)</span></code></pre></div>
<p><img src="MATH3714_files/figure-html/stackloss-plot-1.png" width="672" /></p>
<p>Clearly the stack loss increases with water temperature, but the
relationship may not be linear. It may make sense to include
the square of the water temperature as an additional input variable
in the model.</p>
</div>
</div>
<div id="R-squared" class="section level2" number="8.2">
<h2><span class="header-section-number">8.2</span> The Coefficient of Multiple Determination</h2>
<div class="videowrap">
<div class="videowrapper">
<iframe width="560" height="315" src="https://www.youtube.com/embed/rBzSlQVx3A0" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen>
</iframe>
</div>
</div>
<p>In equation <a href="S04-model.html#eq:eps-y-orth">(4.5)</a> we have seen that
<span class="math display">\[\begin{equation*}
  \|y\|^2
  = \|\hat y\|^2 + \|\hat\varepsilon\|^2.
\end{equation*}\]</span>
The following lemma shows that a similar relation also holds after the sample
means are subtracted.</p>
<div class="lemma">
<p><span id="lem:explained-variance" class="lemma"><strong>Lemma 8.1  </strong></span>Assume that the fitted model includes an intercept. Then we have
<span class="math display">\[\begin{align*}
  \sum_{i=1}^n (y_i - \overline{y})^2
  &amp;= \sum_{i=1}^n (\hat y_i - \overline{y})^2
    + \sum_{i=1}^n \hat \varepsilon_i^2 \\
  &amp;= \sum_{i=1}^n \bigl( \hat y_i - \overline{\hat y} \bigr)^2
    + \sum_{i=1}^n \bigl( \hat \varepsilon_i - \overline{\hat\varepsilon} \bigr)^2,
\end{align*}\]</span>
where <span class="math inline">\(\overline{y}\)</span>, <span class="math inline">\(\overline{\hat y}\)</span> and <span class="math inline">\(\overline{\hat\varepsilon}\)</span>
are the sample means of the three vectors <span class="math inline">\(y\)</span>, <span class="math inline">\(\hat y\)</span> and <span class="math inline">\(\hat\varepsilon\)</span>.</p>
</div>
<div class="proof">
<p><span id="unlabeled-div-28" class="proof"><em>Proof</em>. </span>Define <span class="math inline">\(\mathbf{1} = (1, \ldots, 1) \in \mathbb{R}^p\)</span>. From exercise 2 on
problem sheet 1 we know that <span class="math inline">\(H\mathbf{1} = \mathbf{1}\)</span> and since <span class="math inline">\(H\)</span>
is symmetric we also have <span class="math inline">\(\mathbf{1}^\top H = \mathbf{1}^\top\)</span>.
This gives
<span class="math display" id="eq:I-H-left">\[\begin{equation}
  \mathbf{1}^\top (I - H)
  = \mathbf{1}^\top - \mathbf{1}^\top H
  = \mathbf{1}^\top - \mathbf{1}^\top
  = 0.  \tag{8.1}
\end{equation}\]</span></p>
<p>As we have already seen previously, we have
<span class="math display">\[\begin{align*}
  \hat y^\top \hat\varepsilon
  &amp;= (H y)^\top (I - H) y \\
  &amp;= y^\top H (I - H) y \\
  &amp;= 0
\end{align*}\]</span>
and using equation <a href="S08-diagnostics.html#eq:I-H-left">(8.1)</a> we also get
<span class="math display">\[\begin{equation}
  \mathbf{1}^\top \hat\varepsilon
  = \mathbf{1}^\top (I - H) y
  = 0.
\end{equation}\]</span>
Thus, <span class="math inline">\((\hat y - \overline{y} \mathbf{1})^\top \hat\varepsilon= 0\)</span> and using
Pythagoras’ theorem as in the section about <a href="S04-model.html#hat-matrix">Properties of the Hat Matrix</a>, we
find
<span class="math display">\[\begin{align*}
  \| y - \overline{y} \mathbf{1} \|^2
  &amp;= \| y - \hat y + \hat y - \overline{y} \mathbf{1} \|^2 \\
  &amp;= \| \hat \varepsilon+ \hat y - \overline{y} \mathbf{1} \|^2 \\
  &amp;= \| \hat \varepsilon\|^2 + \| \hat y - \overline{y} \mathbf{1} \|^2.
\end{align*}\]</span>
This proves the first equality.</p>
<p>Using equation <a href="S08-diagnostics.html#eq:I-H-left">(8.1)</a> again, we find
<span class="math display">\[\begin{equation*}
  \sum_{i=1}^n \hat\varepsilon_i
  = \mathbf{1}^\top \hat\varepsilon
  = \mathbf{1}^\top (y - \hat y)
  = \mathbf{1}^\top (I - H) y
  = 0
\end{equation*}\]</span>
and thus <span class="math inline">\(\overline{\hat\varepsilon} = 0\)</span>.
Since <span class="math inline">\(y = \hat y + (y - \hat y) = \hat y + \hat\varepsilon\)</span> we also have
<span class="math display">\[\begin{equation*}
  \overline{y}
  = \overline{\hat y} + \overline{\hat\varepsilon}
  = \overline{\hat y}.
\end{equation*}\]</span>
This completes the proof.</p>
</div>
<p>We can express the terms in the statement of lemma <a href="S08-diagnostics.html#lem:explained-variance">8.1</a>
as sample variances. For example, we write
<span class="math display">\[\begin{equation*}
  \mathrm{s}_y^2
  = \frac{1}{n-1} \sum_{i=1}^n (y_i - \bar y)^2
\end{equation*}\]</span>
for the sample variance of <span class="math inline">\(y\)</span>. Using this notation, the statement of
the lemma can be written as
<span class="math display">\[\begin{equation*}
  \mathrm{s}_y^2
  = \mathrm{s}_{\hat y}^2 + \mathrm{s}_{\hat\varepsilon}^2.
\end{equation*}\]</span>
Different from equation <a href="S04-model.html#eq:eps-y-orth">(4.5)</a>, the current relation is
only true for models which include an intercept.</p>
<p>Some authors define</p>
<ul>
<li><span class="math inline">\(\mathrm{SS}_\mathrm{tot} = \sum_{i=1}^n (y_i - \bar y)^2\)</span>
(where “tot” stands for “total”)</li>
<li><span class="math inline">\(\mathrm{SS}_\mathrm{reg} = \sum_{i=1}^n (\hat y_i - \overline{\hat y})^2\)</span>
(where “reg” stands for “regression”)</li>
<li><span class="math inline">\(\mathrm{SS}_\mathrm{res} = \sum_{i=1}^n (y_i-\hat y_i)^2\)</span>
(where “res” stands for “residual”)</li>
</ul>
<p>Using this notation, the statement of lemma <a href="S08-diagnostics.html#lem:explained-variance">8.1</a>
becomes
<span class="math display">\[\begin{equation*}
  \mathrm{SS}_\mathrm{tot}
  = \mathrm{SS}_\mathrm{reg} + \mathrm{SS}_\mathrm{res}.
\end{equation*}\]</span></p>
<div class="definition">
<p><span id="def:R-squared" class="definition"><strong>Definition 8.1  </strong></span>The <strong>coefficient of multiple determination</strong> is defined to be
<span class="math display">\[\begin{equation*}
  R^2
  := 1 - \frac{\mathrm{s}_{\hat\varepsilon}^2}{\mathrm{s}_y^2}
  = 1 - \frac{\sum_{i=1}^n \hat\varepsilon_i^2}{\sum_{i=1}^n (y_i - \bar y)^2}.
\end{equation*}\]</span></p>
</div>
<p>Using the result of lemma <a href="S08-diagnostics.html#lem:explained-variance">8.1</a>, for models which
include an intercept we can also
express <span class="math inline">\(R^2\)</span> as
<span class="math display">\[\begin{equation*}
  R^2
  = \mathrm{s}_{\hat y}^2 / \mathrm{s}_y^2.
\end{equation*}\]</span>
Since both numerator and denominator are positive, if is clear the <span class="math inline">\(R^2 \geq 0\)</span>. Similarly, from the definition it is clear that <span class="math inline">\(R^2 \leq 1\)</span>, so that we
always have <span class="math inline">\(R^2 \in [0, 1]\)</span>. A large value of <span class="math inline">\(R^2\)</span> indicates that
the residuals are small, compared to the sample variance of the <span class="math inline">\(y_i\)</span>
and thus often indicates good model fit.</p>
<div class="example">
<p><span id="exm:unlabeled-div-29" class="example"><strong>Example 8.2  </strong></span>We can easily compute the <span class="math inline">\(R^2\)</span> value for the <code>stackloss</code> dataset
manually:</p>
<div class="sourceCode" id="cb126"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb126-1"><a href="S08-diagnostics.html#cb126-1" aria-hidden="true" tabindex="-1"></a>m <span class="ot">&lt;-</span> <span class="fu">lm</span>(stack.loss <span class="sc">~</span> ., <span class="at">data =</span> stackloss)</span>
<span id="cb126-2"><a href="S08-diagnostics.html#cb126-2" aria-hidden="true" tabindex="-1"></a>R.squared <span class="ot">&lt;-</span> <span class="dv">1</span> <span class="sc">-</span> <span class="fu">var</span>(<span class="fu">resid</span>(m)) <span class="sc">/</span> <span class="fu">var</span>(stackloss<span class="sc">$</span>stack.loss)</span>
<span id="cb126-3"><a href="S08-diagnostics.html#cb126-3" aria-hidden="true" tabindex="-1"></a>R.squared</span></code></pre></div>
<pre class="rOutput"><code>[1] 0.9135769</code></pre>
<p>We can also find this value near the bottom of the output of
<code>summary(m)</code>, listed as <code>Multiple R-squared</code>:</p>
<div class="sourceCode" id="cb128"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb128-1"><a href="S08-diagnostics.html#cb128-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(m)</span></code></pre></div>
<pre class="rOutput"><code>
Call:
lm(formula = stack.loss ~ ., data = stackloss)

Residuals:
    Min      1Q  Median      3Q     Max 
-7.2377 -1.7117 -0.4551  2.3614  5.6978 

Coefficients:
            Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept) -39.9197    11.8960  -3.356  0.00375 ** 
Air.Flow      0.7156     0.1349   5.307  5.8e-05 ***
Water.Temp    1.2953     0.3680   3.520  0.00263 ** 
Acid.Conc.   -0.1521     0.1563  -0.973  0.34405    
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

Residual standard error: 3.243 on 17 degrees of freedom
Multiple R-squared:  0.9136,    Adjusted R-squared:  0.8983 
F-statistic:  59.9 on 3 and 17 DF,  p-value: 3.016e-09</code></pre>
</div>
<p>One problem with the <span class="math inline">\(R^2\)</span> value is, that it always increases when another
input variable is added to the model. Thus, the <span class="math inline">\(R^2\)</span> value cannot be used
to compare model fit for models with different numbers of variables. An
attempt to compensate for this effect is the adjusted <span class="math inline">\(R^2\)</span> value:</p>
<div class="definition">
<p><span id="def:adjusted-R-squared" class="definition"><strong>Definition 8.2  </strong></span>The <strong>adjusted <span class="math inline">\(R^2\)</span> value</strong> is given by
<span class="math display">\[\begin{equation*}
  R^2_\mathrm{adj}
  := 1 - \frac{\frac{1}{n-p-1}\mathrm{s}_{\hat\varepsilon}^2}{\frac{1}{n-1}\mathrm{s}_y^2}
  = 1 - \frac{n-1}{n-p-1}(1 - R^2).
\end{equation*}\]</span></p>
</div>
<p>The value <span class="math inline">\(R^2_\mathrm{adj}\)</span> is always smaller than the <span class="math inline">\(R^2\)</span> value, and
<span class="math inline">\(R^2_\mathrm{adj}\)</span> can be (slightly) negative.</p>
<div class="example">
<p><span id="exm:unlabeled-div-30" class="example"><strong>Example 8.3  </strong></span>The adjusted <span class="math inline">\(R^2\)</span> value for the stackloss dataset
can be found as follows:</p>
<div class="sourceCode" id="cb130"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb130-1"><a href="S08-diagnostics.html#cb130-1" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="fu">nrow</span>(stackloss)</span>
<span id="cb130-2"><a href="S08-diagnostics.html#cb130-2" aria-hidden="true" tabindex="-1"></a>p <span class="ot">&lt;-</span> <span class="fu">ncol</span>(stackloss) <span class="sc">-</span> <span class="dv">1</span></span>
<span id="cb130-3"><a href="S08-diagnostics.html#cb130-3" aria-hidden="true" tabindex="-1"></a>R.squared.adj <span class="ot">&lt;-</span> <span class="dv">1</span> <span class="sc">-</span> (n <span class="sc">-</span> <span class="dv">1</span>) <span class="sc">/</span> (n <span class="sc">-</span> p <span class="sc">-</span> <span class="dv">1</span>) <span class="sc">*</span> (<span class="dv">1</span> <span class="sc">-</span> R.squared)</span>
<span id="cb130-4"><a href="S08-diagnostics.html#cb130-4" aria-hidden="true" tabindex="-1"></a>R.squared.adj</span></code></pre></div>
<pre class="rOutput"><code>[1] 0.8983258</code></pre>
<p>We can also find this value near the bottom of the output of
<code>summary(m)</code>, listed as <code>Adjusted R-squared</code>.</p>
</div>
<div class="example">
<p><span id="exm:unlabeled-div-31" class="example"><strong>Example 8.4  </strong></span>As suggested in example <a href="S08-diagnostics.html#exm:stackloss-plot">8.1</a>, we may want to
include a new quadratic term in the stackloss dataset:</p>
<div class="sourceCode" id="cb132"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb132-1"><a href="S08-diagnostics.html#cb132-1" aria-hidden="true" tabindex="-1"></a>m2 <span class="ot">&lt;-</span> <span class="fu">lm</span>(stack.loss <span class="sc">~</span> . <span class="sc">+</span> <span class="fu">I</span>(Water.Temp<span class="sc">^</span><span class="dv">2</span>), <span class="at">data =</span> stackloss)</span>
<span id="cb132-2"><a href="S08-diagnostics.html#cb132-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(m2)</span></code></pre></div>
<pre class="rOutput"><code>
Call:
lm(formula = stack.loss ~ . + I(Water.Temp^2), data = stackloss)

Residuals:
    Min      1Q  Median      3Q     Max 
-4.1217 -1.5205 -0.3091  0.9753  6.0554 

Coefficients:
                Estimate Std. Error t value Pr(&gt;|t|)   
(Intercept)     57.73727   46.08487   1.253  0.22826   
Air.Flow         0.53683    0.14708   3.650  0.00216 **
Water.Temp      -7.62030    4.10441  -1.857  0.08188 . 
Acid.Conc.      -0.09697    0.14371  -0.675  0.50946   
I(Water.Temp^2)  0.21224    0.09738   2.179  0.04459 * 
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

Residual standard error: 2.936 on 16 degrees of freedom
Multiple R-squared:  0.9334,    Adjusted R-squared:  0.9167 
F-statistic: 56.02 on 4 and 16 DF,  p-value: 3.293e-09</code></pre>
<p>As expected, the <span class="math inline">\(R^2\)</span> value has increased here (from 0.9136 to 0.9334).
Since the adjusted <span class="math inline">\(R^2\)</span> value has also increased (from 0.8983 to 0.9167),
the extended model may be better than the original model.</p>
</div>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="P02.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="S09-influence.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": null,
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["MATH3714.pdf"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
