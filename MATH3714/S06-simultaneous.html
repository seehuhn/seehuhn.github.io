<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Section 6 Estimating Coefficients Simultaneously | MATH3714 Linear Regression and Robustness</title>
  <meta name="description" content="Lecture notes for the course MATH3714 Linear Regression and Robustness at the University of Leeds, 2021/22" />
  <meta name="generator" content="bookdown 0.24 and GitBook 2.6.7" />

  <meta property="og:title" content="Section 6 Estimating Coefficients Simultaneously | MATH3714 Linear Regression and Robustness" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="https://seehuhn.github.io/MATH3714/" />
  
  <meta property="og:description" content="Lecture notes for the course MATH3714 Linear Regression and Robustness at the University of Leeds, 2021/22" />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Section 6 Estimating Coefficients Simultaneously | MATH3714 Linear Regression and Robustness" />
  
  <meta name="twitter:description" content="Lecture notes for the course MATH3714 Linear Regression and Robustness at the University of Leeds, 2021/22" />
  

<meta name="author" content="Jochen Voss" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="S05-single.html"/>
<link rel="next" href="I02-read.html"/>
<script src="libs/header-attrs-2.11/header-attrs.js"></script>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-P96L0SF56N"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-P96L0SF56N');
</script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./index.html">MATH3714 Notes</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="chapter" data-level="" data-path="S00-about.html"><a href="S00-about.html"><i class="fa fa-check"></i>About MATH3714</a>
<ul>
<li class="chapter" data-level="" data-path="S00-about.html"><a href="S00-about.html#notes"><i class="fa fa-check"></i>Notes and videos</a></li>
<li class="chapter" data-level="" data-path="S00-about.html"><a href="S00-about.html#lectures"><i class="fa fa-check"></i>Lectures</a></li>
<li class="chapter" data-level="" data-path="S00-about.html"><a href="S00-about.html#workshops"><i class="fa fa-check"></i>Workshops and Problem Sheets</a></li>
<li class="chapter" data-level="" data-path="S00-about.html"><a href="S00-about.html#teams"><i class="fa fa-check"></i>Discussion Board</a></li>
<li class="chapter" data-level="" data-path="S00-about.html"><a href="S00-about.html#software"><i class="fa fa-check"></i>Software</a></li>
<li class="chapter" data-level="" data-path="S00-about.html"><a href="S00-about.html#assessments"><i class="fa fa-check"></i>Assessments</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="S01-simple.html"><a href="S01-simple.html"><i class="fa fa-check"></i><b>1</b> Simple Linear Regression</a>
<ul>
<li class="chapter" data-level="1.1" data-path="S01-simple.html"><a href="S01-simple.html#residual-sum-of-squares"><i class="fa fa-check"></i><b>1.1</b> Residual Sum of Squares</a></li>
<li class="chapter" data-level="1.2" data-path="S01-simple.html"><a href="S01-simple.html#linear-regression-as-a-parameter-estimation-problem"><i class="fa fa-check"></i><b>1.2</b> Linear Regression as a Parameter Estimation Problem</a></li>
<li class="chapter" data-level="1.3" data-path="S01-simple.html"><a href="S01-simple.html#sec:simple-mat"><i class="fa fa-check"></i><b>1.3</b> Matrix Notation</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="S02-multiple.html"><a href="S02-multiple.html"><i class="fa fa-check"></i><b>2</b> Least Squares Estimates</a>
<ul>
<li class="chapter" data-level="2.1" data-path="S02-multiple.html"><a href="S02-multiple.html#data-and-models"><i class="fa fa-check"></i><b>2.1</b> Data and Models</a></li>
<li class="chapter" data-level="2.2" data-path="S02-multiple.html"><a href="S02-multiple.html#the-normal-equations"><i class="fa fa-check"></i><b>2.2</b> The Normal Equations</a></li>
<li class="chapter" data-level="2.3" data-path="S02-multiple.html"><a href="S02-multiple.html#fitted-values"><i class="fa fa-check"></i><b>2.3</b> Fitted Values</a></li>
<li class="chapter" data-level="2.4" data-path="S02-multiple.html"><a href="S02-multiple.html#example"><i class="fa fa-check"></i><b>2.4</b> Example</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="I01-lm.html"><a href="I01-lm.html"><i class="fa fa-check"></i>Interlude: Linear Regression in R</a>
<ul>
<li class="chapter" data-level="" data-path="I01-lm.html"><a href="I01-lm.html#lm-fitting"><i class="fa fa-check"></i>Fitting a Model</a></li>
<li class="chapter" data-level="" data-path="I01-lm.html"><a href="I01-lm.html#lm-model"><i class="fa fa-check"></i>Understanding the Model</a></li>
<li class="chapter" data-level="" data-path="I01-lm.html"><a href="I01-lm.html#lm-predict"><i class="fa fa-check"></i>Making Predictions</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="P01.html"><a href="P01.html"><i class="fa fa-check"></i>Problem Sheet 1</a></li>
<li class="chapter" data-level="3" data-path="S03-cov.html"><a href="S03-cov.html"><i class="fa fa-check"></i><b>3</b> Random Vectors and Covariance</a>
<ul>
<li class="chapter" data-level="3.1" data-path="S03-cov.html"><a href="S03-cov.html#expectation"><i class="fa fa-check"></i><b>3.1</b> Expectation</a></li>
<li class="chapter" data-level="3.2" data-path="S03-cov.html"><a href="S03-cov.html#sec:covariance"><i class="fa fa-check"></i><b>3.2</b> Covariance Matrix</a></li>
<li class="chapter" data-level="3.3" data-path="S03-cov.html"><a href="S03-cov.html#the-multivariate-normal-distribution"><i class="fa fa-check"></i><b>3.3</b> The Multivariate Normal Distribution</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="S04-model.html"><a href="S04-model.html"><i class="fa fa-check"></i><b>4</b> Properties of the Least Squares Estimate</a>
<ul>
<li class="chapter" data-level="4.1" data-path="S04-model.html"><a href="S04-model.html#mean-and-covariance"><i class="fa fa-check"></i><b>4.1</b> Mean and Covariance</a></li>
<li class="chapter" data-level="4.2" data-path="S04-model.html"><a href="S04-model.html#hat-matrix"><i class="fa fa-check"></i><b>4.2</b> Properties of the Hat Matrix</a></li>
<li class="chapter" data-level="4.3" data-path="S04-model.html"><a href="S04-model.html#Cochran"><i class="fa fa-check"></i><b>4.3</b> Cochran’s theorem</a></li>
<li class="chapter" data-level="4.4" data-path="S04-model.html"><a href="S04-model.html#var-est-bias"><i class="fa fa-check"></i><b>4.4</b> Estimating the Error Variance</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="S05-single.html"><a href="S05-single.html"><i class="fa fa-check"></i><b>5</b> Uncertainty for Individual Regression Coefficients</a>
<ul>
<li class="chapter" data-level="5.1" data-path="S05-single.html"><a href="S05-single.html#measuring-the-estimation-error"><i class="fa fa-check"></i><b>5.1</b> Measuring the Estimation Error</a></li>
<li class="chapter" data-level="5.2" data-path="S05-single.html"><a href="S05-single.html#confidence-intervals"><i class="fa fa-check"></i><b>5.2</b> Confidence Intervals</a></li>
<li class="chapter" data-level="5.3" data-path="S05-single.html"><a href="S05-single.html#hypthesis-tests"><i class="fa fa-check"></i><b>5.3</b> Hypthesis Tests</a></li>
<li class="chapter" data-level="5.4" data-path="S05-single.html"><a href="S05-single.html#r-experiments"><i class="fa fa-check"></i><b>5.4</b> R Experiments</a>
<ul>
<li class="chapter" data-level="5.4.1" data-path="S05-single.html"><a href="S05-single.html#fitting-the-model"><i class="fa fa-check"></i><b>5.4.1</b> Fitting the model</a></li>
<li class="chapter" data-level="5.4.2" data-path="S05-single.html"><a href="S05-single.html#estimating-the-variance-of-the-error"><i class="fa fa-check"></i><b>5.4.2</b> Estimating the Variance of the Error</a></li>
<li class="chapter" data-level="5.4.3" data-path="S05-single.html"><a href="S05-single.html#estimating-the-standard-errors"><i class="fa fa-check"></i><b>5.4.3</b> Estimating the Standard Errors</a></li>
<li class="chapter" data-level="5.4.4" data-path="S05-single.html"><a href="S05-single.html#hypothesis-tests"><i class="fa fa-check"></i><b>5.4.4</b> Hypothesis tests</a></li>
<li class="chapter" data-level="5.4.5" data-path="S05-single.html"><a href="S05-single.html#confidence-intervals-1"><i class="fa fa-check"></i><b>5.4.5</b> Confidence Intervals</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="S06-simultaneous.html"><a href="S06-simultaneous.html"><i class="fa fa-check"></i><b>6</b> Estimating Coefficients Simultaneously</a>
<ul>
<li class="chapter" data-level="6.1" data-path="S06-simultaneous.html"><a href="S06-simultaneous.html#sec:simult-dist"><i class="fa fa-check"></i><b>6.1</b> Linear Combinations of Coefficients</a></li>
<li class="chapter" data-level="6.2" data-path="S06-simultaneous.html"><a href="S06-simultaneous.html#sec:simult-CI"><i class="fa fa-check"></i><b>6.2</b> Confidence Regions</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="S06-simultaneous.html"><a href="S06-simultaneous.html#result"><i class="fa fa-check"></i><b>6.2.1</b> Result</a></li>
<li class="chapter" data-level="6.2.2" data-path="S06-simultaneous.html"><a href="S06-simultaneous.html#numerical-experiments"><i class="fa fa-check"></i><b>6.2.2</b> Numerical Experiments</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="S06-simultaneous.html"><a href="S06-simultaneous.html#sec:simult-test"><i class="fa fa-check"></i><b>6.3</b> Hypothesis Tests</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="I02-read.html"><a href="I02-read.html"><i class="fa fa-check"></i>Interlude: Loading Data into R</a>
<ul>
<li class="chapter" data-level="" data-path="I02-read.html"><a href="I02-read.html#importing-csv-files"><i class="fa fa-check"></i>Importing CSV Files</a></li>
<li class="chapter" data-level="" data-path="I02-read.html"><a href="I02-read.html#importing-microsoft-excel-files"><i class="fa fa-check"></i>Importing Microsoft Excel Files</a></li>
<li class="chapter" data-level="" data-path="I02-read.html"><a href="I02-read.html#checking-the-imported-data"><i class="fa fa-check"></i>Checking the Imported Data</a></li>
<li class="chapter" data-level="" data-path="I02-read.html"><a href="I02-read.html#common-problems"><i class="fa fa-check"></i>Common Problems</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="S07-examples.html"><a href="S07-examples.html"><i class="fa fa-check"></i><b>7</b> Examples</a>
<ul>
<li class="chapter" data-level="7.1" data-path="S07-examples.html"><a href="S07-examples.html#simple-confidence-interval"><i class="fa fa-check"></i><b>7.1</b> Simple Confidence Interval</a>
<ul>
<li class="chapter" data-level="7.1.1" data-path="S07-examples.html"><a href="S07-examples.html#from-first-principles"><i class="fa fa-check"></i><b>7.1.1</b> From First Principles</a></li>
<li class="chapter" data-level="7.1.2" data-path="S07-examples.html"><a href="S07-examples.html#from-the-lm-output"><i class="fa fa-check"></i><b>7.1.2</b> From the <code>lm()</code> Output</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="S07-examples.html"><a href="S07-examples.html#confidence-intervals-for-the-mean"><i class="fa fa-check"></i><b>7.2</b> Confidence Intervals for the Mean</a></li>
<li class="chapter" data-level="7.3" data-path="S07-examples.html"><a href="S07-examples.html#testing-a-single-coefficient"><i class="fa fa-check"></i><b>7.3</b> Testing a Single Coefficient</a>
<ul>
<li class="chapter" data-level="7.3.1" data-path="S07-examples.html"><a href="S07-examples.html#from-first-principles-1"><i class="fa fa-check"></i><b>7.3.1</b> From First Principles</a></li>
<li class="chapter" data-level="7.3.2" data-path="S07-examples.html"><a href="S07-examples.html#using-the-lm-output-i"><i class="fa fa-check"></i><b>7.3.2</b> Using the <code>lm()</code> Output, I</a></li>
<li class="chapter" data-level="7.3.3" data-path="S07-examples.html"><a href="S07-examples.html#using-the-lm-output-ii"><i class="fa fa-check"></i><b>7.3.3</b> Using the <code>lm()</code> Output, II</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="S07-examples.html"><a href="S07-examples.html#testing-multiple-coefficents"><i class="fa fa-check"></i><b>7.4</b> Testing Multiple Coefficents</a>
<ul>
<li class="chapter" data-level="7.4.1" data-path="S07-examples.html"><a href="S07-examples.html#from-first-principles-2"><i class="fa fa-check"></i><b>7.4.1</b> From First Principles</a></li>
<li class="chapter" data-level="7.4.2" data-path="S07-examples.html"><a href="S07-examples.html#using-the-lm-output"><i class="fa fa-check"></i><b>7.4.2</b> Using the <code>lm()</code> output</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="P02.html"><a href="P02.html"><i class="fa fa-check"></i>Problem Sheet 2</a></li>
<li class="chapter" data-level="8" data-path="S08-diagnostics.html"><a href="S08-diagnostics.html"><i class="fa fa-check"></i><b>8</b> Regression Diagnostics</a>
<ul>
<li class="chapter" data-level="8.1" data-path="S08-diagnostics.html"><a href="S08-diagnostics.html#plots"><i class="fa fa-check"></i><b>8.1</b> Diagnostic Plots</a></li>
<li class="chapter" data-level="8.2" data-path="S08-diagnostics.html"><a href="S08-diagnostics.html#R-squared"><i class="fa fa-check"></i><b>8.2</b> The Coefficient of Multiple Determination</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="S09-influence.html"><a href="S09-influence.html"><i class="fa fa-check"></i><b>9</b> The Influence of Observations</a>
<ul>
<li class="chapter" data-level="9.1" data-path="S09-influence.html"><a href="S09-influence.html#deleting"><i class="fa fa-check"></i><b>9.1</b> Deleting Observations</a></li>
<li class="chapter" data-level="9.2" data-path="S09-influence.html"><a href="S09-influence.html#influence"><i class="fa fa-check"></i><b>9.2</b> Cook’s Distance</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="S10-multicoll.html"><a href="S10-multicoll.html"><i class="fa fa-check"></i><b>10</b> Multicollinearity</a>
<ul>
<li class="chapter" data-level="10.1" data-path="S10-multicoll.html"><a href="S10-multicoll.html#consequences-of-multicollinearity"><i class="fa fa-check"></i><b>10.1</b> Consequences of Multicollinearity</a></li>
<li class="chapter" data-level="10.2" data-path="S10-multicoll.html"><a href="S10-multicoll.html#detecting-multicollinearity"><i class="fa fa-check"></i><b>10.2</b> Detecting Multicollinearity</a></li>
<li class="chapter" data-level="10.3" data-path="S10-multicoll.html"><a href="S10-multicoll.html#mitigations"><i class="fa fa-check"></i><b>10.3</b> Mitigations</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="P03.html"><a href="P03.html"><i class="fa fa-check"></i>Problem Sheet 3</a></li>
<li class="chapter" data-level="11" data-path="S11-improving.html"><a href="S11-improving.html"><i class="fa fa-check"></i><b>11</b> Improving the Model Fit</a>
<ul>
<li class="chapter" data-level="11.1" data-path="S11-improving.html"><a href="S11-improving.html#linearising-the-mean"><i class="fa fa-check"></i><b>11.1</b> Linearising the Mean</a></li>
<li class="chapter" data-level="11.2" data-path="S11-improving.html"><a href="S11-improving.html#stabilising-the-variance"><i class="fa fa-check"></i><b>11.2</b> Stabilising the Variance</a></li>
<li class="chapter" data-level="11.3" data-path="S11-improving.html"><a href="S11-improving.html#power-transform"><i class="fa fa-check"></i><b>11.3</b> The Power Transform</a></li>
<li class="chapter" data-level="11.4" data-path="S11-improving.html"><a href="S11-improving.html#orthogonal-inputs"><i class="fa fa-check"></i><b>11.4</b> Orthogonal Inputs</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="S12-ridge.html"><a href="S12-ridge.html"><i class="fa fa-check"></i><b>12</b> Ridge Regression</a>
<ul>
<li class="chapter" data-level="12.1" data-path="S12-ridge.html"><a href="S12-ridge.html#definition-the-estimator"><i class="fa fa-check"></i><b>12.1</b> Definition the Estimator</a></li>
<li class="chapter" data-level="12.2" data-path="S12-ridge.html"><a href="S12-ridge.html#properties-of-the-estimate"><i class="fa fa-check"></i><b>12.2</b> Properties of the Estimate</a>
<ul>
<li class="chapter" data-level="12.2.1" data-path="S12-ridge.html"><a href="S12-ridge.html#bias"><i class="fa fa-check"></i><b>12.2.1</b> Bias</a></li>
<li class="chapter" data-level="12.2.2" data-path="S12-ridge.html"><a href="S12-ridge.html#variance"><i class="fa fa-check"></i><b>12.2.2</b> Variance</a></li>
<li class="chapter" data-level="12.2.3" data-path="S12-ridge.html"><a href="S12-ridge.html#mean-squared-error"><i class="fa fa-check"></i><b>12.2.3</b> Mean Squared Error</a></li>
</ul></li>
<li class="chapter" data-level="12.3" data-path="S12-ridge.html"><a href="S12-ridge.html#standardisation"><i class="fa fa-check"></i><b>12.3</b> Standardisation</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="S13-models.html"><a href="S13-models.html"><i class="fa fa-check"></i><b>13</b> Model selection</a>
<ul>
<li class="chapter" data-level="13.1" data-path="S13-models.html"><a href="S13-models.html#candidates-models"><i class="fa fa-check"></i><b>13.1</b> Candidates Models</a></li>
<li class="chapter" data-level="13.2" data-path="S13-models.html"><a href="S13-models.html#misspecified-models"><i class="fa fa-check"></i><b>13.2</b> Misspecified Models</a>
<ul>
<li class="chapter" data-level="13.2.1" data-path="S13-models.html"><a href="S13-models.html#missing-variables"><i class="fa fa-check"></i><b>13.2.1</b> Missing Variables</a></li>
<li class="chapter" data-level="13.2.2" data-path="S13-models.html"><a href="S13-models.html#unnecessary-variables"><i class="fa fa-check"></i><b>13.2.2</b> Unnecessary Variables</a></li>
</ul></li>
<li class="chapter" data-level="13.3" data-path="S13-models.html"><a href="S13-models.html#criteria"><i class="fa fa-check"></i><b>13.3</b> Assessing Models</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="P04.html"><a href="P04.html"><i class="fa fa-check"></i>Problem Sheet 4</a></li>
<li class="chapter" data-level="14" data-path="S14-methods.html"><a href="S14-methods.html"><i class="fa fa-check"></i><b>14</b> Methods for Model Selection</a>
<ul>
<li class="chapter" data-level="14.1" data-path="S14-methods.html"><a href="S14-methods.html#exhaustive-search"><i class="fa fa-check"></i><b>14.1</b> Exhaustive Search</a></li>
<li class="chapter" data-level="14.2" data-path="S14-methods.html"><a href="S14-methods.html#search-algorithm"><i class="fa fa-check"></i><b>14.2</b> Search Algorithm</a></li>
<li class="chapter" data-level="14.3" data-path="S14-methods.html"><a href="S14-methods.html#other-methods"><i class="fa fa-check"></i><b>14.3</b> Other Methods</a>
<ul>
<li class="chapter" data-level="14.3.1" data-path="S14-methods.html"><a href="S14-methods.html#stepwise-forward-selection"><i class="fa fa-check"></i><b>14.3.1</b> Stepwise Forward Selection</a></li>
<li class="chapter" data-level="14.3.2" data-path="S14-methods.html"><a href="S14-methods.html#stepwise-backward-selection"><i class="fa fa-check"></i><b>14.3.2</b> Stepwise Backward Selection</a></li>
<li class="chapter" data-level="14.3.3" data-path="S14-methods.html"><a href="S14-methods.html#hybrid-methods"><i class="fa fa-check"></i><b>14.3.3</b> Hybrid Methods</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="15" data-path="S15-factors.html"><a href="S15-factors.html"><i class="fa fa-check"></i><b>15</b> Factors</a>
<ul>
<li class="chapter" data-level="15.1" data-path="S15-factors.html"><a href="S15-factors.html#indicator-variables"><i class="fa fa-check"></i><b>15.1</b> Indicator Variables</a></li>
<li class="chapter" data-level="15.2" data-path="S15-factors.html"><a href="S15-factors.html#interactions"><i class="fa fa-check"></i><b>15.2</b> Interactions</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="practical.html"><a href="practical.html"><i class="fa fa-check"></i>Practical</a>
<ul>
<li class="chapter" data-level="" data-path="practical.html"><a href="practical.html#dataset"><i class="fa fa-check"></i>Dataset</a></li>
<li class="chapter" data-level="" data-path="practical.html"><a href="practical.html#tasks"><i class="fa fa-check"></i>Tasks</a></li>
<li class="chapter" data-level="" data-path="practical.html"><a href="practical.html#references"><i class="fa fa-check"></i>References</a></li>
</ul></li>
<li class="chapter" data-level="16" data-path="S16-examples.html"><a href="S16-examples.html"><i class="fa fa-check"></i><b>16</b> Examples</a>
<ul>
<li class="chapter" data-level="16.1" data-path="S16-examples.html"><a href="S16-examples.html#interactions-example"><i class="fa fa-check"></i><b>16.1</b> Use of Interaction Terms in Modelling</a></li>
<li class="chapter" data-level="16.2" data-path="S16-examples.html"><a href="S16-examples.html#codings"><i class="fa fa-check"></i><b>16.2</b> Alternative Factor Codings</a></li>
</ul></li>
<li class="chapter" data-level="17" data-path="S17-robust.html"><a href="S17-robust.html"><i class="fa fa-check"></i><b>17</b> Robust Regression</a>
<ul>
<li class="chapter" data-level="17.1" data-path="S17-robust.html"><a href="S17-robust.html#outliers"><i class="fa fa-check"></i><b>17.1</b> Outliers</a>
<ul>
<li class="chapter" data-level="17.1.1" data-path="S17-robust.html"><a href="S17-robust.html#leverage"><i class="fa fa-check"></i><b>17.1.1</b> Leverage</a></li>
<li class="chapter" data-level="17.1.2" data-path="S17-robust.html"><a href="S17-robust.html#studentised-residuals"><i class="fa fa-check"></i><b>17.1.2</b> Studentised Residuals</a></li>
</ul></li>
<li class="chapter" data-level="17.2" data-path="S17-robust.html"><a href="S17-robust.html#breakdown-points"><i class="fa fa-check"></i><b>17.2</b> Breakdown points</a></li>
</ul></li>
<li class="chapter" data-level="18" data-path="S18-m-est.html"><a href="S18-m-est.html"><i class="fa fa-check"></i><b>18</b> M-Estimators</a>
<ul>
<li class="chapter" data-level="18.1" data-path="S18-m-est.html"><a href="S18-m-est.html#definition"><i class="fa fa-check"></i><b>18.1</b> Definition</a></li>
<li class="chapter" data-level="18.2" data-path="S18-m-est.html"><a href="S18-m-est.html#iterative-methods"><i class="fa fa-check"></i><b>18.2</b> Iterative Methods</a></li>
<li class="chapter" data-level="18.3" data-path="S18-m-est.html"><a href="S18-m-est.html#objective-functions"><i class="fa fa-check"></i><b>18.3</b> Objective Functions</a>
<ul>
<li class="chapter" data-level="18.3.1" data-path="S18-m-est.html"><a href="S18-m-est.html#least-squares-method"><i class="fa fa-check"></i><b>18.3.1</b> Least Squares Method</a></li>
<li class="chapter" data-level="18.3.2" data-path="S18-m-est.html"><a href="S18-m-est.html#least-absolute-values"><i class="fa fa-check"></i><b>18.3.2</b> Least Absolute Values</a></li>
<li class="chapter" data-level="18.3.3" data-path="S18-m-est.html"><a href="S18-m-est.html#hubers-t-function"><i class="fa fa-check"></i><b>18.3.3</b> Huber’s <span class="math inline">\(t\)</span>-function</a></li>
<li class="chapter" data-level="18.3.4" data-path="S18-m-est.html"><a href="S18-m-est.html#hampels-method"><i class="fa fa-check"></i><b>18.3.4</b> Hampel’s Method</a></li>
<li class="chapter" data-level="18.3.5" data-path="S18-m-est.html"><a href="S18-m-est.html#tukeys-bisquare-method"><i class="fa fa-check"></i><b>18.3.5</b> Tukey’s Bisquare Method</a></li>
</ul></li>
</ul></li>
<li class="appendix"><span><b>Appendices</b></span></li>
<li class="chapter" data-level="A" data-path="Sx1-matrices.html"><a href="Sx1-matrices.html"><i class="fa fa-check"></i><b>A</b> Linear Algebra Reminders</a>
<ul>
<li class="chapter" data-level="A.1" data-path="Sx1-matrices.html"><a href="Sx1-matrices.html#vectors"><i class="fa fa-check"></i><b>A.1</b> Vectors</a></li>
<li class="chapter" data-level="A.2" data-path="Sx1-matrices.html"><a href="Sx1-matrices.html#matrix-rules"><i class="fa fa-check"></i><b>A.2</b> Matrices</a>
<ul>
<li class="chapter" data-level="A.2.1" data-path="Sx1-matrices.html"><a href="Sx1-matrices.html#transpose"><i class="fa fa-check"></i><b>A.2.1</b> Transpose</a></li>
<li class="chapter" data-level="A.2.2" data-path="Sx1-matrices.html"><a href="Sx1-matrices.html#matrix-vector-product"><i class="fa fa-check"></i><b>A.2.2</b> Matrix-vector Product</a></li>
<li class="chapter" data-level="A.2.3" data-path="Sx1-matrices.html"><a href="Sx1-matrices.html#matrix-matrix-product"><i class="fa fa-check"></i><b>A.2.3</b> Matrix-matrix Product</a></li>
<li class="chapter" data-level="A.2.4" data-path="Sx1-matrices.html"><a href="Sx1-matrices.html#rank"><i class="fa fa-check"></i><b>A.2.4</b> Rank</a></li>
<li class="chapter" data-level="A.2.5" data-path="Sx1-matrices.html"><a href="Sx1-matrices.html#trace"><i class="fa fa-check"></i><b>A.2.5</b> Trace</a></li>
<li class="chapter" data-level="A.2.6" data-path="Sx1-matrices.html"><a href="Sx1-matrices.html#matrix-inverse"><i class="fa fa-check"></i><b>A.2.6</b> Matrix Inverse</a></li>
<li class="chapter" data-level="A.2.7" data-path="Sx1-matrices.html"><a href="Sx1-matrices.html#orthogonal-matrices"><i class="fa fa-check"></i><b>A.2.7</b> Orthogonal Matrices</a></li>
<li class="chapter" data-level="A.2.8" data-path="Sx1-matrices.html"><a href="Sx1-matrices.html#positive-definite"><i class="fa fa-check"></i><b>A.2.8</b> Positive Definite Matrices</a></li>
<li class="chapter" data-level="A.2.9" data-path="Sx1-matrices.html"><a href="Sx1-matrices.html#idempotent"><i class="fa fa-check"></i><b>A.2.9</b> Idempotent Matrices</a></li>
</ul></li>
<li class="chapter" data-level="A.3" data-path="Sx1-matrices.html"><a href="Sx1-matrices.html#eigenvalues"><i class="fa fa-check"></i><b>A.3</b> Eigenvalues</a></li>
</ul></li>
<li class="chapter" data-level="B" data-path="Sx2-probability.html"><a href="Sx2-probability.html"><i class="fa fa-check"></i><b>B</b> Probability Reminders</a>
<ul>
<li class="chapter" data-level="B.1" data-path="Sx2-probability.html"><a href="Sx2-probability.html#independence"><i class="fa fa-check"></i><b>B.1</b> Independence</a></li>
<li class="chapter" data-level="B.2" data-path="Sx2-probability.html"><a href="Sx2-probability.html#chi-square"><i class="fa fa-check"></i><b>B.2</b> The Chi-Squared Distribution</a></li>
<li class="chapter" data-level="B.3" data-path="Sx2-probability.html"><a href="Sx2-probability.html#t"><i class="fa fa-check"></i><b>B.3</b> The t-distribution</a></li>
</ul></li>
<li class="divider"></li>
<li class="chapter"><span><b>THE END</b></span></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">MATH3714 Linear Regression and Robustness</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="S06-simultaneous" class="section level1" number="6">
<h1><span class="header-section-number">Section 6</span> Estimating Coefficients Simultaneously</h1>
<p>In this section we will study how to assess the uncertainty in two or more
regression coefficients simultaneously. This is needed since the estimates for
different coefficients will usually not be independent.</p>
<div id="sec:simult-dist" class="section level2" number="6.1">
<h2><span class="header-section-number">6.1</span> Linear Combinations of Coefficients</h2>
<div class="videowrap">
<div class="videowrapper">
<iframe width="560" height="315" src="https://www.youtube.com/embed/OajCqVmApeg" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen>
</iframe>
</div>
</div>
<p>As a general setup which allows to describe which coefficients we are
interested in, we consider the image <span class="math inline">\(K\beta\)</span>, where <span class="math inline">\(K \in \mathbb{R}^{k \times (p+1)}\)</span> with <span class="math inline">\(k \leq p+1\)</span>.</p>
<div class="example">
<p><span id="exm:unlabeled-div-21" class="example"><strong>Example 6.1  </strong></span>If <span class="math inline">\(p = 3\)</span> and
<span class="math display">\[\begin{equation*}
  K = \begin{pmatrix}
    0 &amp; 1 &amp; 0 &amp; 0 \\
    0 &amp; 0 &amp; 1 &amp; 0
  \end{pmatrix},
\end{equation*}\]</span>
then
<span class="math display">\[\begin{equation*}
  K\beta
  = \begin{pmatrix}
      0 &amp; 1 &amp; 0 &amp; 0 \\
      0 &amp; 0 &amp; 1 &amp; 0
    \end{pmatrix} \begin{pmatrix}
      \beta_0 \\ \beta_1 \\ \beta_2 \\ \beta_3
    \end{pmatrix}
  = \begin{pmatrix}
      \beta_1 \\ \beta_2
    \end{pmatrix}.
\end{equation*}\]</span>
Thus, this choice of <span class="math inline">\(K\)</span> would be appropriate if we are interested
in <span class="math inline">\(\beta_1\)</span> and <span class="math inline">\(\beta_2\)</span> only.</p>
</div>
<p>The setup allows for more general questions than just selecting components
of <span class="math inline">\(\beta\)</span>. We can also derive statements about linear combination of
the <span class="math inline">\(\beta_i\)</span>, <em>e.g.</em> we will be able to derive confidence intervals
for quantities like <span class="math inline">\(\beta_1 - \beta_2\)</span>.</p>
<p>Since <span class="math inline">\(\hat\beta\)</span> is an estimator for <span class="math inline">\(\beta\)</span>, we can use <span class="math inline">\(K\hat\beta\)</span> as an
estimator for <span class="math inline">\(K\beta\)</span>. From lemma <a href="S04-model.html#lem:hat-beta-dist">4.1</a> we know that
<span class="math inline">\(\hat\beta \sim \mathcal{N}\bigl( \beta, \sigma^2 (X^\top X)^{-1} \bigr)\)</span> and thus
we get
<span class="math display">\[\begin{equation*}
  K\hat\beta
  \sim \mathcal{N}\bigl( K \beta, \sigma^2 K (X^\top X)^{-1} K^\top \bigr).
\end{equation*}\]</span>
This shows that the estimator <span class="math inline">\(K\hat\beta\)</span> is unbiased.</p>
<p>Given an invertible matrix <span class="math inline">\(Q\)</span>, we define the shorthand notation
<span class="math display">\[\begin{equation*}
  \| v \|_Q^2
  := v^\top Q^{-1} v.
\end{equation*}\]</span>
Using this notation for <span class="math inline">\(Q = K(X^\top X)^{-1} K^\top\)</span>, we define
<span class="math display" id="eq:simult-F">\[\begin{equation}
  F
  := \frac{\bigl\| K \hat\beta - K \beta \bigr\|_{K(X^\top X)^{-1} K^\top}^2}
          {k \hat\sigma^2} \tag{6.1}
\end{equation}\]</span>
as a measure for the distance between <span class="math inline">\(K\hat\beta\)</span> and <span class="math inline">\(K\beta\)</span>. This
quantity plays the role of <span class="math inline">\(T\)</span> (or more precisely, <span class="math inline">\(T^2\)</span>) from the previous
section. We also need to introduce the <span class="math inline">\(F\)</span>-distribution, which will take the
place of the <span class="math inline">\(t\)</span>-distribution from the previous section.</p>
<div class="definition">
<p><span id="def:unlabeled-div-22" class="definition"><strong>Definition 6.1  </strong></span>The <span class="math inline">\(F\)</span>-distribution with <span class="math inline">\(\nu_1\)</span> and <span class="math inline">\(\nu_2\)</span> degrees of freedom is the
distribution of
<span class="math display">\[\begin{equation*}
  X
  =\frac{S_1/\nu_1}{S_2/\nu_2},
\end{equation*}\]</span>
where <span class="math inline">\(S_1\)</span> and <span class="math inline">\(S_2\)</span> are independent random variables with chi-square
distributions with <span class="math inline">\(\nu_1\)</span> and <span class="math inline">\(\nu_2\)</span> degrees of freedom, respectively.</p>
</div>
<p>With these preparations in place, we can state the main result.</p>
<div class="lemma">
<p><span id="lem:F-dist" class="lemma"><strong>Lemma 6.1  </strong></span>Assume that the data follows the model <a href="S04-model.html#eq:lmstats">(4.1)</a>
and that <span class="math inline">\(Q := K(X^\top X)^{-1} K^\top\)</span> is invertible.
Then <span class="math inline">\(F \sim F_{k,n-p-1}\)</span>, <em>i.e.</em> <span class="math inline">\(F\)</span> follows a
<span class="math inline">\(F\)</span>-distribution with <span class="math inline">\(k\)</span> and <span class="math inline">\(n-p-1\)</span> degrees of freedom.</p>
</div>
<div class="proof">
<p><span id="unlabeled-div-23" class="proof"><em>Proof</em>. </span>We have
<span class="math display">\[\begin{align*}
  \hskip-5mm
  &amp; \bigl\| K \hat\beta - K \beta \bigr\|_Q^2 \\
  &amp;= \bigl\| K (\hat\beta - \beta) \bigr\|_Q^2 \\
  &amp;= \bigl\| K (X^\top X)^{-1} X^\top \varepsilon\bigr\|_Q^2 \\
  &amp;= \varepsilon^\top X (X^\top X)^{-1} K^\top Q^{-1} K (X^\top X)^{-1} X^\top \varepsilon\\
  &amp;=: \varepsilon^\top R \varepsilon.
\end{align*}\]</span>
It is tedious but easy to check that <span class="math inline">\(R\)</span> is idempotent:
<span class="math display">\[\begin{align*}
  R^2
  &amp;= \Bigl(X (X^\top X)^{-1} K^\top Q^{-1} K (X^\top X)^{-1} X^\top\Bigr)
     \Bigl(X (X^\top X)^{-1} K^\top Q^{-1} K (X^\top X)^{-1} X^\top\Bigr) \\
  &amp;= X (X^\top X)^{-1} K^\top Q^{-1} K (X^\top X)^{-1} \Bigl(X^\top
     X (X^\top X)^{-1} \Bigr) K^\top Q^{-1} K (X^\top X)^{-1} X^\top \\
  &amp;= X (X^\top X)^{-1} K^\top \Bigl( Q^{-1} K (X^\top X)^{-1} K^\top \Bigr)
      Q^{-1} K (X^\top X)^{-1} X^\top \\
  &amp;= X (X^\top X)^{-1} K^\top Q^{-1} K (X^\top X)^{-1} X^\top \\
  &amp;= R.
\end{align*}\]</span>
When we checked in the proof of <a href="S04-model.html#thm:Cochran">Cochran’s theorem</a> that
<span class="math inline">\(\varepsilon^\top H \varepsilon\)</span> was chi-squared distributed, the only property of <span class="math inline">\(H\)</span>
we used was that <span class="math inline">\(H\)</span> is idempotent. (If you don’t remember the details,
it would be a good idea to re-read the proof before continuing.) Thus,
the same argument gives that <span class="math inline">\(\varepsilon^\top R \varepsilon/ \sigma^2\)</span> is chi-squared distributed,
and as before the number of degrees of freedom of this chi-squared distribution
equals the rank of <span class="math inline">\(R\)</span>. Using the assumption that <span class="math inline">\(Q\)</span> is invertible,
one can show (we skip this part of the proof again)
that the rank of <span class="math inline">\(Q\)</span> equals <span class="math inline">\(\min(k, p+1) = k\)</span> and thus we find that
<span class="math display">\[\begin{equation*}
  S_1
  := \frac{1}{\sigma^2} \bigl\| K \hat\beta - K \beta \bigr\|_Q^2
  \sim \chi^2(k).
\end{equation*}\]</span></p>
<p>Similarly, from the direct application of Cochran’s theorem in
equation <a href="S04-model.html#eq:sigma-hat-chi-squared">(4.7)</a>, we know
<span class="math display">\[\begin{equation*}
  S_2
  := \frac{1}{\sigma^2} (n - p - 1) \hat\sigma^2
  \sim \chi^2(n - p - 1).
\end{equation*}\]</span></p>
<p>Since <span class="math inline">\(S_1\)</span> is a function of <span class="math inline">\(\hat\beta\)</span> and <span class="math inline">\(S_2\)</span> is a function of
<span class="math inline">\(\hat\sigma^2\)</span>, we can use lemma <a href="S05-single.html#lem:hat-beta-sigma-indep">5.1</a> to
conclude that <span class="math inline">\(S_1\)</span> and <span class="math inline">\(S_2\)</span> are independent.
Combining these results we find
<span class="math display">\[\begin{align*}
  F
  &amp;= \frac{\bigl\| K \hat\beta - K \beta \bigr\|_{K(X^\top X)^{-1} K^\top}^2}
          {k \hat\sigma^2} \\
  &amp;= \frac{\frac{1}{\sigma^2} \bigl\| K \hat\beta - K \beta \bigr\|_{K(X^\top X)^{-1} K^\top}^2 / k}
          {\frac{1}{\sigma^2} (n - p - 1) \hat\sigma^2 / (n - p - 1)} \\
  &amp;= \frac{S_1 / k}{S_2 / (n - p - 1)} \\
  &amp;\sim F_{k, n - p - 1}.
\end{align*}\]</span>
This completes the proof.</p>
</div>
</div>
<div id="sec:simult-CI" class="section level2" number="6.2">
<h2><span class="header-section-number">6.2</span> Confidence Regions</h2>
<div class="videowrap">
<div class="videowrapper">
<iframe width="560" height="315" src="https://www.youtube.com/embed/rHXIaQYljDk" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen>
</iframe>
</div>
</div>
<p>Using <span class="math inline">\(F\)</span> as a distance between the unknown true <span class="math inline">\(K\beta\)</span> and the estimator
<span class="math inline">\(\hat\beta\)</span>, it is easy to find a region of <span class="math inline">\(\mathbb{R}^k\)</span> which covers <span class="math inline">\(K\beta\)</span> with
high probability. Since we now have an <span class="math inline">\(k\)</span>-dimensional parameter vector, this
region will no longer be an interval. Instead, we will get an <span class="math inline">\(k\)</span>-dimensional
ellipsoid.</p>
<div id="result" class="section level3" number="6.2.1">
<h3><span class="header-section-number">6.2.1</span> Result</h3>
<p>Define
<span class="math display">\[\begin{equation*}
  E
  := \Bigl\{
      z \in \mathbb{R}^k
    \Bigm|
      \bigl\| z - K \hat\beta \bigr\|_{K(X^\top X)^{-1} K^\top}
        \leq \sqrt{k \hat\sigma^2 f_{k,n-p-1}(\alpha)}
    \Bigr\},
\end{equation*}\]</span>
where <span class="math inline">\(f_{k,n-p-1}(\alpha)\)</span> is the <span class="math inline">\((1-\alpha)\)</span>-quantile of the
<span class="math inline">\(F_{k,n-p-1}\)</span>-distribution. This is a “ball” around <span class="math inline">\(K\hat\beta\)</span> in <span class="math inline">\(\mathbb{R}^k\)</span>,
where distance is measured using the norm <span class="math inline">\(\| \;\cdot\; \|_{K(X^\top X)^{-1} K^\top}\)</span> introduced above. The following lemma shows that <span class="math inline">\(\sqrt{k \hat\sigma^2 f_{k,n-p-1}(\alpha)}\)</span> is the correct choice of “radius” to make the
ball cover the true value <span class="math inline">\(K\beta\)</span> with probability <span class="math inline">\(1-\alpha\)</span>.</p>
<div class="lemma">
<p><span id="lem:unlabeled-div-24" class="lemma"><strong>Lemma 6.2  </strong></span>We have
<span class="math display">\[\begin{equation*}
  P\bigl( K\beta \in E \bigr)
  = 1 - \alpha,
\end{equation*}\]</span>
<em>i.e.</em> the set <span class="math inline">\(E\)</span> is a <span class="math inline">\((1-\alpha)\)</span>-confidence region for <span class="math inline">\(K\beta\)</span>.</p>
</div>
<div class="proof">
<p><span id="unlabeled-div-25" class="proof"><em>Proof</em>. </span>We have
<span class="math display">\[\begin{align*}
  &amp;\hskip-5mm K\beta \in E \\
  &amp;\Longleftrightarrow
      \bigl\| K\beta - K \hat\beta \bigr\|_{K(X^\top X)^{-1} K^\top}
        \leq \sqrt{k \hat\sigma^2 f_{k,n-p-1}(\alpha)} \\
  &amp;\Longleftrightarrow
      \bigl\| K\hat\beta - K\beta \bigr\|_{K(X^\top X)^{-1} K^\top}^2
        \leq k \hat\sigma^2 f_{k,n-p-1}(\alpha) \\
  &amp;\Longleftrightarrow
      \frac{\bigl\| K\hat\beta - K\beta \bigr\|_{K(X^\top X)^{-1} K^\top}^2}
           {k \hat\sigma^2}
        \leq f_{k,n-p-1}(\alpha) \\
  &amp;\Longleftrightarrow
    F \leq f_{k,n-p-1}(\alpha)
\end{align*}\]</span>
Now the claim follows, since <span class="math inline">\(f_{k,n-p-1}(\alpha)\)</span> is the
<span class="math inline">\((1-\alpha)\)</span>-quantile of <span class="math inline">\(F\)</span>.</p>
</div>
</div>
<div id="numerical-experiments" class="section level3" number="6.2.2">
<h3><span class="header-section-number">6.2.2</span> Numerical Experiments</h3>
<p>We start by fitting a linear model to the <code>stackloss</code> dataset as
before:</p>
<div class="sourceCode" id="cb59"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb59-1"><a href="S06-simultaneous.html#cb59-1" aria-hidden="true" tabindex="-1"></a>m <span class="ot">&lt;-</span> <span class="fu">lm</span>(stack.loss <span class="sc">~</span> ., <span class="at">data =</span> stackloss)</span>
<span id="cb59-2"><a href="S06-simultaneous.html#cb59-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(m)</span></code></pre></div>
<pre class="rOutput"><code>
Call:
lm(formula = stack.loss ~ ., data = stackloss)

Residuals:
    Min      1Q  Median      3Q     Max 
-7.2377 -1.7117 -0.4551  2.3614  5.6978 

Coefficients:
            Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept) -39.9197    11.8960  -3.356  0.00375 ** 
Air.Flow      0.7156     0.1349   5.307  5.8e-05 ***
Water.Temp    1.2953     0.3680   3.520  0.00263 ** 
Acid.Conc.   -0.1521     0.1563  -0.973  0.34405    
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

Residual standard error: 3.243 on 17 degrees of freedom
Multiple R-squared:  0.9136,    Adjusted R-squared:  0.8983 
F-statistic:  59.9 on 3 and 17 DF,  p-value: 3.016e-09</code></pre>
<p>Here I want to consider the two regressions coefficients <span class="math inline">\(\beta_1\)</span> (<code>Air.Flow</code>)
and <span class="math inline">\(\beta_2\)</span> (<code>Water.Temp</code>). For this we need to construct a matrix <span class="math inline">\(K\)</span>
with two rows, where each row selects one of the two coefficients:</p>
<div class="sourceCode" id="cb61"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb61-1"><a href="S06-simultaneous.html#cb61-1" aria-hidden="true" tabindex="-1"></a>X <span class="ot">&lt;-</span> <span class="fu">model.matrix</span>(m)</span>
<span id="cb61-2"><a href="S06-simultaneous.html#cb61-2" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="fu">nrow</span>(X)</span>
<span id="cb61-3"><a href="S06-simultaneous.html#cb61-3" aria-hidden="true" tabindex="-1"></a>p <span class="ot">&lt;-</span> <span class="fu">ncol</span>(X) <span class="sc">-</span> <span class="dv">1</span></span>
<span id="cb61-4"><a href="S06-simultaneous.html#cb61-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb61-5"><a href="S06-simultaneous.html#cb61-5" aria-hidden="true" tabindex="-1"></a>K <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">0</span>,   <span class="co"># indices in R start at 1, so beta_1 is col. 2</span></span>
<span id="cb61-6"><a href="S06-simultaneous.html#cb61-6" aria-hidden="true" tabindex="-1"></a>              <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">0</span>),  <span class="co"># ... and beta_2 is column 3.</span></span>
<span id="cb61-7"><a href="S06-simultaneous.html#cb61-7" aria-hidden="true" tabindex="-1"></a>            <span class="at">byrow =</span> <span class="cn">TRUE</span>,</span>
<span id="cb61-8"><a href="S06-simultaneous.html#cb61-8" aria-hidden="true" tabindex="-1"></a>            <span class="at">nrow =</span> <span class="dv">2</span>, <span class="at">ncol =</span> <span class="dv">4</span>)</span>
<span id="cb61-9"><a href="S06-simultaneous.html#cb61-9" aria-hidden="true" tabindex="-1"></a>k <span class="ot">&lt;-</span> <span class="fu">nrow</span>(K)</span>
<span id="cb61-10"><a href="S06-simultaneous.html#cb61-10" aria-hidden="true" tabindex="-1"></a>K.beta.hat <span class="ot">&lt;-</span> <span class="fu">as.vector</span>(K <span class="sc">%*%</span> <span class="fu">coef</span>(m))</span></code></pre></div>
<p>As we have seen in the previous section, for this <span class="math inline">\(K\)</span> the covariance matrix for
the ellipse is <span class="math inline">\(Q = K (X^\top X)^{-1} K^\top\)</span>:</p>
<div class="sourceCode" id="cb62"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb62-1"><a href="S06-simultaneous.html#cb62-1" aria-hidden="true" tabindex="-1"></a>Q <span class="ot">&lt;-</span> K <span class="sc">%*%</span> <span class="fu">solve</span>(<span class="fu">t</span>(X) <span class="sc">%*%</span> X) <span class="sc">%*%</span> <span class="fu">t</span>(K)</span></code></pre></div>
<div id="a-single-point" class="section level4" number="6.2.2.1">
<h4><span class="header-section-number">6.2.2.1</span> A Single Point</h4>
<p>To try out the method, we first consider the test point <span class="math inline">\(m = K\beta = (1, 1)\)</span>
and we compute the <span class="math inline">\(F\)</span> value for this point to see whether the point is
inside or outside the ellipse:</p>
<div class="sourceCode" id="cb63"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb63-1"><a href="S06-simultaneous.html#cb63-1" aria-hidden="true" tabindex="-1"></a>a <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb63-2"><a href="S06-simultaneous.html#cb63-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb63-3"><a href="S06-simultaneous.html#cb63-3" aria-hidden="true" tabindex="-1"></a>sigma.hat <span class="ot">&lt;-</span> <span class="fu">summary</span>(m)<span class="sc">$</span>sigma</span>
<span id="cb63-4"><a href="S06-simultaneous.html#cb63-4" aria-hidden="true" tabindex="-1"></a>d <span class="ot">&lt;-</span> a <span class="sc">-</span> K.beta.hat</span>
<span id="cb63-5"><a href="S06-simultaneous.html#cb63-5" aria-hidden="true" tabindex="-1"></a>F <span class="ot">&lt;-</span> <span class="fu">t</span>(d) <span class="sc">%*%</span> <span class="fu">solve</span>(Q, d) <span class="sc">/</span> (k <span class="sc">*</span> sigma.hat<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb63-6"><a href="S06-simultaneous.html#cb63-6" aria-hidden="true" tabindex="-1"></a>F</span></code></pre></div>
<pre class="rOutput"><code>         [,1]
[1,] 2.834083</code></pre>
<p>The <span class="math inline">\(F\)</span> value, measuring the distance from the centre of the ellipse
is <span class="math inline">\(2.834\)</span> for this test point. This has to be compared to the
critical value:</p>
<div class="sourceCode" id="cb65"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb65-1"><a href="S06-simultaneous.html#cb65-1" aria-hidden="true" tabindex="-1"></a>alpha <span class="ot">&lt;-</span> <span class="fl">0.05</span></span>
<span id="cb65-2"><a href="S06-simultaneous.html#cb65-2" aria-hidden="true" tabindex="-1"></a>f.crit <span class="ot">&lt;-</span> <span class="fu">qf</span>(<span class="dv">1</span> <span class="sc">-</span> alpha, k, n <span class="sc">-</span> p <span class="sc">-</span> <span class="dv">1</span>)</span>
<span id="cb65-3"><a href="S06-simultaneous.html#cb65-3" aria-hidden="true" tabindex="-1"></a>f.crit</span></code></pre></div>
<pre class="rOutput"><code>[1] 3.591531</code></pre>
<p>Since the <span class="math inline">\(F\)</span> value is less than the critical value, the point <span class="math inline">\((1, 1)\)</span>
is inside the ellipse. As the next step, we will plot a picture of the
full ellipse.</p>
</div>
<div id="points-on-a-grid" class="section level4" number="6.2.2.2">
<h4><span class="header-section-number">6.2.2.2</span> Points on a Grid</h4>
<p>An easy way to show the ellipse is to repeat the above procedure for
all points on a rectangular grid, and then colour the points
depending on whether they are inside or outside the ellipse.
We start by making a list of grid points.</p>
<div class="sourceCode" id="cb67"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb67-1"><a href="S06-simultaneous.html#cb67-1" aria-hidden="true" tabindex="-1"></a>x.min <span class="ot">&lt;-</span> <span class="sc">-</span><span class="dv">1</span></span>
<span id="cb67-2"><a href="S06-simultaneous.html#cb67-2" aria-hidden="true" tabindex="-1"></a>x.max <span class="ot">&lt;-</span> <span class="dv">3</span></span>
<span id="cb67-3"><a href="S06-simultaneous.html#cb67-3" aria-hidden="true" tabindex="-1"></a>y.min <span class="ot">&lt;-</span> <span class="sc">-</span><span class="fl">0.5</span></span>
<span id="cb67-4"><a href="S06-simultaneous.html#cb67-4" aria-hidden="true" tabindex="-1"></a>y.max <span class="ot">&lt;-</span> <span class="dv">3</span></span>
<span id="cb67-5"><a href="S06-simultaneous.html#cb67-5" aria-hidden="true" tabindex="-1"></a>L <span class="ot">&lt;-</span> <span class="dv">200</span></span>
<span id="cb67-6"><a href="S06-simultaneous.html#cb67-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb67-7"><a href="S06-simultaneous.html#cb67-7" aria-hidden="true" tabindex="-1"></a>xx <span class="ot">&lt;-</span> <span class="fu">seq</span>(x.min, x.max, <span class="at">length.out =</span> L)</span>
<span id="cb67-8"><a href="S06-simultaneous.html#cb67-8" aria-hidden="true" tabindex="-1"></a>yy <span class="ot">&lt;-</span> <span class="fu">seq</span>(y.min, y.max, <span class="at">length.out =</span> L)</span>
<span id="cb67-9"><a href="S06-simultaneous.html#cb67-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb67-10"><a href="S06-simultaneous.html#cb67-10" aria-hidden="true" tabindex="-1"></a>Z <span class="ot">&lt;-</span> <span class="fu">as.matrix</span>(<span class="fu">expand.grid</span>(<span class="at">x =</span> xx <span class="sc">-</span> K.beta.hat[<span class="dv">1</span>],</span>
<span id="cb67-11"><a href="S06-simultaneous.html#cb67-11" aria-hidden="true" tabindex="-1"></a>                           <span class="at">y =</span> yy <span class="sc">-</span> K.beta.hat[<span class="dv">2</span>],</span>
<span id="cb67-12"><a href="S06-simultaneous.html#cb67-12" aria-hidden="true" tabindex="-1"></a>                           <span class="at">KEEP.OUT.ATTRS =</span> <span class="cn">FALSE</span>))</span>
<span id="cb67-13"><a href="S06-simultaneous.html#cb67-13" aria-hidden="true" tabindex="-1"></a><span class="fu">dim</span>(Z)</span></code></pre></div>
<pre class="rOutput"><code>[1] 40000     2</code></pre>
<p>The matrix <span class="math inline">\(Z\)</span> now has two columns, containing the <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span> coordinates
respectively of the <span class="math inline">\(200\times 200\)</span> points in our grid.
Now we need to compute the <span class="math inline">\(F\)</span> value for every grid point:</p>
<div class="sourceCode" id="cb69"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb69-1"><a href="S06-simultaneous.html#cb69-1" aria-hidden="true" tabindex="-1"></a>F <span class="ot">&lt;-</span> <span class="fu">rowSums</span>(Z <span class="sc">*</span> <span class="fu">t</span>(<span class="fu">solve</span>(Q, <span class="fu">t</span>(Z)))) <span class="sc">/</span> (k <span class="sc">*</span> sigma.hat<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb69-2"><a href="S06-simultaneous.html#cb69-2" aria-hidden="true" tabindex="-1"></a>F <span class="ot">&lt;-</span> <span class="fu">matrix</span>(F, <span class="at">byrow =</span> <span class="cn">TRUE</span>, L, L)</span>
<span id="cb69-3"><a href="S06-simultaneous.html#cb69-3" aria-hidden="true" tabindex="-1"></a><span class="fu">dim</span>(F)</span></code></pre></div>
<pre class="rOutput"><code>[1] 200 200</code></pre>
<p>The resulting matrix contains the <span class="math inline">\(F\)</span> value for every grid point.
Finally, we can mark all the points where <span class="math inline">\(F\)</span> exceeds the critical
value in a plot:</p>
<div class="sourceCode" id="cb71"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb71-1"><a href="S06-simultaneous.html#cb71-1" aria-hidden="true" tabindex="-1"></a><span class="fu">image</span>(<span class="at">x =</span> xx, <span class="at">y =</span> yy, <span class="fu">t</span>(F <span class="sc">&gt;</span> f.crit), <span class="at">asp =</span> <span class="dv">1</span>,</span>
<span id="cb71-2"><a href="S06-simultaneous.html#cb71-2" aria-hidden="true" tabindex="-1"></a>      <span class="at">col =</span> <span class="fu">c</span>(<span class="st">&quot;green&quot;</span>, <span class="st">&quot;white&quot;</span>),</span>
<span id="cb71-3"><a href="S06-simultaneous.html#cb71-3" aria-hidden="true" tabindex="-1"></a>      <span class="at">xlab =</span> <span class="fu">expression</span>(beta[<span class="dv">1</span>]), <span class="at">ylab =</span> <span class="fu">expression</span>(beta[<span class="dv">2</span>]))</span>
<span id="cb71-4"><a href="S06-simultaneous.html#cb71-4" aria-hidden="true" tabindex="-1"></a><span class="fu">points</span>(K.beta.hat[<span class="dv">1</span>], K.beta.hat[<span class="dv">2</span>], <span class="at">pch =</span> <span class="st">&quot;+&quot;</span>)</span></code></pre></div>
<p><img src="MATH3714_files/figure-html/ellipse-1.png" width="672" /></p>
<p>The green ellipse in this plot is the 95% confidence ellipse
for the vector <span class="math inline">\((\beta_1, \beta_2)\)</span>.</p>
</div>
<div id="coordinates-of-the-outline" class="section level4" number="6.2.2.3">
<h4><span class="header-section-number">6.2.2.3</span> Coordinates of the Outline</h4>
<p><strong>This sub-section is non-examinable (but hopefully interesting).</strong></p>
<p>Using some more linear algebra, we can find a formula for the coordinates
of the points on the ellipse which forms the boundary of the confidence
region. For this, we use the
<a href="https://en.wikipedia.org/wiki/Singular_value_decomposition">Singular Value Decomposition</a>
of the matrix <span class="math inline">\(Q\)</span>. This allows to write <span class="math inline">\(Q\)</span> as
<span class="math display">\[\begin{equation*}
  Q = U D V^\top
\end{equation*}\]</span>
where <span class="math inline">\(U\)</span> and <span class="math inline">\(V\)</span> are orthogonal matrices and <span class="math inline">\(D\)</span> is a diagonal matrix:</p>
<div class="sourceCode" id="cb72"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb72-1"><a href="S06-simultaneous.html#cb72-1" aria-hidden="true" tabindex="-1"></a>svd <span class="ot">&lt;-</span> <span class="fu">La.svd</span>(Q)</span>
<span id="cb72-2"><a href="S06-simultaneous.html#cb72-2" aria-hidden="true" tabindex="-1"></a>svd</span></code></pre></div>
<pre class="rOutput"><code>$d
[1] 0.0138678012 0.0007364967

$u
           [,1]      [,2]
[1,] -0.2749061 0.9614711
[2,]  0.9614711 0.2749061

$vt
           [,1]      [,2]
[1,] -0.2749061 0.9614711
[2,]  0.9614711 0.2749061</code></pre>
<p>The R output shows the diagonal elements <span class="math inline">\(d_{ii}\)</span> of <span class="math inline">\(D\)</span> and the matrices <span class="math inline">\(U\)</span>
and <span class="math inline">\(V^\top\)</span>. Since <span class="math inline">\(Q\)</span> is symmetric, we have <span class="math inline">\(U = V\)</span> and thus <span class="math inline">\(Q = U D U^\top\)</span>
in this case, <span class="math inline">\(i.e.\)</span> we have found a diagonalisation of <span class="math inline">\(Q\)</span>.</p>
<p>Using the SVD we can simplify the norm used in the
definition of the ellipse. We write <span class="math inline">\(D^{-1/2}\)</span> for the matrix
which has <span class="math inline">\(1/\sqrt{d_{ii}}\)</span> on the diagonal. Then we have
<span class="math display">\[\begin{align*}
  Q \bigl(D^{-1/2} U^\top \bigr)^\top \bigl(D^{-1/2} U^\top \bigr)
  &amp;= Q U D^{-1/2} D^{-1/2} U^\top \\
  &amp;= U D U^\top U D^{-1} U^\top \\
  &amp;= U D D^{-1} U^\top \\
  &amp;= U U^\top \\
  &amp;= I.
\end{align*}\]</span>
Thus, <span class="math inline">\(\bigl(D^{-1/2} U^\top\bigr)^\top \bigl(D^{-1/2} U^\top\bigr)\)</span> is
the inverse of <span class="math inline">\(Q\)</span> and we get
<span class="math display">\[\begin{align*}
  \bigl\| z - K \hat\beta \bigr\|_Q^2
  &amp;= (z - K \hat\beta)^\top Q^{-1} (z - K \hat\beta) \\
  &amp;= (z - K \hat\beta)^\top \bigl(D^{-1/2} U^\top\bigr)^\top \bigl(D^{-1/2} U^\top\bigr) (z - K \hat\beta) \\
  &amp;= \Bigl\| D^{-1/2} U^\top (z - K \hat\beta) \Bigr\|^2,
\end{align*}\]</span>
where the norm on the right-hand side is the usual Euclidean norm.
Thus, the boundary of the ellipse consists of all points of the
form <span class="math inline">\(K \hat\beta + d\)</span>, where <span class="math inline">\(e := D^{-1/2} U^\top d\)</span> is a vector
of length
<span class="math display">\[ \| e \| = \sqrt{k \hat\sigma^2 f_{k,n-p-1}(\alpha)}. \]</span>
Finally, using polar coordinates, we find the points on the boundary
to be
<span class="math display">\[\begin{equation*}
  d
  = U D^{1/2} e
  = U D^{1/2} \sqrt{k \hat\sigma^2 f_{k,n-p-1}(\alpha)}
    \begin{pmatrix}
      \cos(\varphi) \\ \sin(\varphi)
    \end{pmatrix}
\end{equation*}\]</span>
with <span class="math inline">\(\varphi\in [0, 2\pi]\)</span>. This allows to plot the boundary line in R.</p>
<div class="sourceCode" id="cb74"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb74-1"><a href="S06-simultaneous.html#cb74-1" aria-hidden="true" tabindex="-1"></a>phi <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="dv">0</span>, <span class="dv">2</span><span class="sc">*</span>pi, <span class="at">length.out =</span> <span class="dv">201</span>)</span>
<span id="cb74-2"><a href="S06-simultaneous.html#cb74-2" aria-hidden="true" tabindex="-1"></a>circ <span class="ot">&lt;-</span> <span class="fu">rbind</span>(<span class="fu">cos</span>(phi), <span class="fu">sin</span>(phi)) <span class="sc">*</span> <span class="fu">sqrt</span>(f.crit <span class="sc">*</span> k <span class="sc">*</span> sigma.hat<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb74-3"><a href="S06-simultaneous.html#cb74-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-4"><a href="S06-simultaneous.html#cb74-4" aria-hidden="true" tabindex="-1"></a>ellipse <span class="ot">&lt;-</span> svd<span class="sc">$</span>u <span class="sc">%*%</span> (circ <span class="sc">*</span> <span class="fu">sqrt</span>(svd<span class="sc">$</span>d)) <span class="sc">+</span> K.beta.hat</span>
<span id="cb74-5"><a href="S06-simultaneous.html#cb74-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-6"><a href="S06-simultaneous.html#cb74-6" aria-hidden="true" tabindex="-1"></a><span class="fu">image</span>(<span class="at">x =</span> xx, <span class="at">y =</span> yy, <span class="fu">t</span>(F <span class="sc">&gt;</span> f.crit), <span class="at">asp =</span> <span class="dv">1</span>,</span>
<span id="cb74-7"><a href="S06-simultaneous.html#cb74-7" aria-hidden="true" tabindex="-1"></a>      <span class="at">col =</span> <span class="fu">c</span>(<span class="st">&quot;green&quot;</span>, <span class="st">&quot;white&quot;</span>),</span>
<span id="cb74-8"><a href="S06-simultaneous.html#cb74-8" aria-hidden="true" tabindex="-1"></a>      <span class="at">xlab =</span> <span class="fu">expression</span>(beta[<span class="dv">1</span>]), <span class="at">ylab =</span> <span class="fu">expression</span>(beta[<span class="dv">2</span>]))</span>
<span id="cb74-9"><a href="S06-simultaneous.html#cb74-9" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(ellipse[<span class="dv">1</span>,], ellipse[<span class="dv">2</span>,])</span></code></pre></div>
<p><img src="MATH3714_files/figure-html/ellipse2-1.png" width="672" /></p>
<p>To verify that everything is consistent, we have plotted the line on top
of the image from the previous subsection. Since the black line perfectly
surrounds the green area, both approaches are consistent.</p>
</div>
</div>
</div>
<div id="sec:simult-test" class="section level2" number="6.3">
<h2><span class="header-section-number">6.3</span> Hypothesis Tests</h2>
<p>We can easily derive a hypothesis test to test the hypothesis
<span class="math display">\[\begin{equation*}
  H_0\colon K\beta = m
\end{equation*}\]</span>
against the alternative
<span class="math display">\[\begin{equation*}
  H_1\colon K\beta \neq m,
\end{equation*}\]</span>
where <span class="math inline">\(m \in \mathbb{R}^k\)</span>.</p>
<p>We redefine <span class="math inline">\(F\)</span> as
<span class="math display">\[\begin{equation*}
  F
  := \frac{\bigl\| K \hat\beta - m \bigr\|_{K(X^\top X)^{-1} K^\top}^2}
          {k \hat\sigma^2}
\end{equation*}\]</span>
using <span class="math inline">\(m\)</span> in place of the <span class="math inline">\(K\beta\)</span> above. Then the new defintion of <span class="math inline">\(F\)</span>
is the same as <a href="S06-simultaneous.html#eq:simult-F">(6.1)</a> if <span class="math inline">\(H_0\)</span> is true.</p>
<div class="lemma">
<p><span id="lem:simult-test" class="lemma"><strong>Lemma 6.3  </strong></span>The test which rejects <span class="math inline">\(H_0\)</span> if and only if <span class="math inline">\(|F| &gt; f_{k,n-p-1}(\alpha)\)</span>
has significance level <span class="math inline">\(\alpha\)</span>.</p>
</div>
<div class="proof">
<p><span id="unlabeled-div-26" class="proof"><em>Proof</em>. </span>Assume that <span class="math inline">\(H_0\)</span> is true. Then we have <span class="math inline">\(K\beta = m\)</span> and thus
the <span class="math inline">\(F\)</span> defined in this section coincides with the expression from
equation <a href="S06-simultaneous.html#eq:simult-F">(6.1)</a>. From lemma <a href="S06-simultaneous.html#lem:F-dist">6.1</a>
we know that <span class="math inline">\(F \sim F_{k, n-p-1}\)</span>. Thus we have
<span class="math display">\[\begin{align*}
  P( \mbox{type I error} )
  &amp;= P\bigl( F &gt; f_{k,n-p-1}(\alpha) \bigr) \\
  &amp;= 1 - P\bigl( F \leq f_{k,n-p-1}(\alpha) \bigr) \\
  &amp;= 1 - (1 - \alpha) \\
  &amp;= \alpha.
\end{align*}\]</span>
This completes the proof.</p>
</div>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="S05-single.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="I02-read.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": null,
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["MATH3714.pdf"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
