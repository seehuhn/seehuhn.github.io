<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Problem Sheet 3 | MATH3714 Linear Regression and Robustness</title>
  <meta name="description" content="Lecture notes for the course MATH3714 Linear Regression and Robustness at the University of Leeds, 2025/26" />
  <meta name="generator" content="bookdown 0.44 and GitBook 2.6.7" />

  <meta property="og:title" content="Problem Sheet 3 | MATH3714 Linear Regression and Robustness" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="Lecture notes for the course MATH3714 Linear Regression and Robustness at the University of Leeds, 2025/26" />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Problem Sheet 3 | MATH3714 Linear Regression and Robustness" />
  
  <meta name="twitter:description" content="Lecture notes for the course MATH3714 Linear Regression and Robustness at the University of Leeds, 2025/26" />
  

<meta name="author" content="Jochen Voss" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="S11-improving.html"/>
<link rel="next" href="S12-selection.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>


<style type="text/css">
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>

<link rel="stylesheet" href="jvstyle.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./index.html">MATH3714 Notes</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="chapter" data-level="1" data-path="S01-simple.html"><a href="S01-simple.html"><i class="fa fa-check"></i><b>1</b> Simple Linear Regression</a>
<ul>
<li class="chapter" data-level="1.1" data-path="S01-simple.html"><a href="S01-simple.html#residual-sum-of-squares"><i class="fa fa-check"></i><b>1.1</b> Residual Sum of Squares</a></li>
<li class="chapter" data-level="1.2" data-path="S01-simple.html"><a href="S01-simple.html#linear-regression-as-a-parameter-estimation-problem"><i class="fa fa-check"></i><b>1.2</b> Linear Regression as a Parameter Estimation Problem</a></li>
<li class="chapter" data-level="1.3" data-path="S01-simple.html"><a href="S01-simple.html#sec:simple-mat"><i class="fa fa-check"></i><b>1.3</b> Matrix Notation</a></li>
</ul></li>
<li class="part"><span><b>I Theory</b></span></li>
<li class="chapter" data-level="2" data-path="S02-multiple.html"><a href="S02-multiple.html"><i class="fa fa-check"></i><b>2</b> Least Squares Estimates</a>
<ul>
<li class="chapter" data-level="2.1" data-path="S02-multiple.html"><a href="S02-multiple.html#data-and-models"><i class="fa fa-check"></i><b>2.1</b> Data and Models</a></li>
<li class="chapter" data-level="2.2" data-path="S02-multiple.html"><a href="S02-multiple.html#the-normal-equations"><i class="fa fa-check"></i><b>2.2</b> The Normal Equations</a></li>
<li class="chapter" data-level="2.3" data-path="S02-multiple.html"><a href="S02-multiple.html#fitted-values"><i class="fa fa-check"></i><b>2.3</b> Fitted Values</a></li>
<li class="chapter" data-level="2.4" data-path="S02-multiple.html"><a href="S02-multiple.html#example"><i class="fa fa-check"></i><b>2.4</b> Example</a></li>
<li class="chapter" data-level="2.5" data-path="S02-multiple.html"><a href="S02-multiple.html#models-without-intercept"><i class="fa fa-check"></i><b>2.5</b> Models Without Intercept</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="I01-lm.html"><a href="I01-lm.html"><i class="fa fa-check"></i>Interlude: Linear Regression in R</a>
<ul>
<li class="chapter" data-level="" data-path="I01-lm.html"><a href="I01-lm.html#lm-fitting"><i class="fa fa-check"></i>Fitting a Model</a></li>
<li class="chapter" data-level="" data-path="I01-lm.html"><a href="I01-lm.html#lm-model"><i class="fa fa-check"></i>Understanding the Model</a></li>
<li class="chapter" data-level="" data-path="I01-lm.html"><a href="I01-lm.html#lm-predict"><i class="fa fa-check"></i>Making Predictions</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="S03-cov.html"><a href="S03-cov.html"><i class="fa fa-check"></i><b>3</b> Random Vectors and Covariance</a>
<ul>
<li class="chapter" data-level="3.1" data-path="S03-cov.html"><a href="S03-cov.html#expectation"><i class="fa fa-check"></i><b>3.1</b> Expectation</a></li>
<li class="chapter" data-level="3.2" data-path="S03-cov.html"><a href="S03-cov.html#sec:covariance"><i class="fa fa-check"></i><b>3.2</b> Covariance Matrix</a></li>
<li class="chapter" data-level="3.3" data-path="S03-cov.html"><a href="S03-cov.html#the-multivariate-normal-distribution"><i class="fa fa-check"></i><b>3.3</b> The Multivariate Normal Distribution</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="P01.html"><a href="P01.html"><i class="fa fa-check"></i>Problem Sheet 1</a></li>
<li class="chapter" data-level="4" data-path="S04-model.html"><a href="S04-model.html"><i class="fa fa-check"></i><b>4</b> Properties of the Least Squares Estimate</a>
<ul>
<li class="chapter" data-level="4.1" data-path="S04-model.html"><a href="S04-model.html#mean-and-covariance"><i class="fa fa-check"></i><b>4.1</b> Mean and Covariance</a></li>
<li class="chapter" data-level="4.2" data-path="S04-model.html"><a href="S04-model.html#hat-matrix"><i class="fa fa-check"></i><b>4.2</b> Properties of the Hat Matrix</a></li>
<li class="chapter" data-level="4.3" data-path="S04-model.html"><a href="S04-model.html#Cochran"><i class="fa fa-check"></i><b>4.3</b> Cochran’s theorem</a></li>
<li class="chapter" data-level="4.4" data-path="S04-model.html"><a href="S04-model.html#var-est-bias"><i class="fa fa-check"></i><b>4.4</b> Estimating the Error Variance</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="S05-single.html"><a href="S05-single.html"><i class="fa fa-check"></i><b>5</b> Uncertainty for Individual Regression Coefficients</a>
<ul>
<li class="chapter" data-level="5.1" data-path="S05-single.html"><a href="S05-single.html#measuring-the-estimation-error"><i class="fa fa-check"></i><b>5.1</b> Measuring the Estimation Error</a></li>
<li class="chapter" data-level="5.2" data-path="S05-single.html"><a href="S05-single.html#confidence-intervals"><i class="fa fa-check"></i><b>5.2</b> Confidence Intervals</a></li>
<li class="chapter" data-level="5.3" data-path="S05-single.html"><a href="S05-single.html#hypothesis-tests"><i class="fa fa-check"></i><b>5.3</b> Hypothesis Tests</a></li>
<li class="chapter" data-level="5.4" data-path="S05-single.html"><a href="S05-single.html#r-experiments"><i class="fa fa-check"></i><b>5.4</b> R Experiments</a>
<ul>
<li class="chapter" data-level="5.4.1" data-path="S05-single.html"><a href="S05-single.html#fitting-the-model"><i class="fa fa-check"></i><b>5.4.1</b> Fitting the model</a></li>
<li class="chapter" data-level="5.4.2" data-path="S05-single.html"><a href="S05-single.html#estimating-the-variance-of-the-error"><i class="fa fa-check"></i><b>5.4.2</b> Estimating the Variance of the Error</a></li>
<li class="chapter" data-level="5.4.3" data-path="S05-single.html"><a href="S05-single.html#estimating-the-standard-errors"><i class="fa fa-check"></i><b>5.4.3</b> Estimating the Standard Errors</a></li>
<li class="chapter" data-level="5.4.4" data-path="S05-single.html"><a href="S05-single.html#hypothesis-tests-1"><i class="fa fa-check"></i><b>5.4.4</b> Hypothesis tests</a></li>
<li class="chapter" data-level="5.4.5" data-path="S05-single.html"><a href="S05-single.html#confidence-intervals-1"><i class="fa fa-check"></i><b>5.4.5</b> Confidence Intervals</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="S06-simultaneous.html"><a href="S06-simultaneous.html"><i class="fa fa-check"></i><b>6</b> Estimating Coefficients Simultaneously</a>
<ul>
<li class="chapter" data-level="6.1" data-path="S06-simultaneous.html"><a href="S06-simultaneous.html#sec:simult-dist"><i class="fa fa-check"></i><b>6.1</b> Linear Combinations of Coefficients</a></li>
<li class="chapter" data-level="6.2" data-path="S06-simultaneous.html"><a href="S06-simultaneous.html#sec:simult-CI"><i class="fa fa-check"></i><b>6.2</b> Confidence Regions</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="S06-simultaneous.html"><a href="S06-simultaneous.html#result"><i class="fa fa-check"></i><b>6.2.1</b> Result</a></li>
<li class="chapter" data-level="6.2.2" data-path="S06-simultaneous.html"><a href="S06-simultaneous.html#numerical-experiments"><i class="fa fa-check"></i><b>6.2.2</b> Numerical Experiments</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="S06-simultaneous.html"><a href="S06-simultaneous.html#sec:simult-test"><i class="fa fa-check"></i><b>6.3</b> Hypothesis Tests</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="I02-read.html"><a href="I02-read.html"><i class="fa fa-check"></i>Interlude: Loading Data into R</a>
<ul>
<li class="chapter" data-level="" data-path="I02-read.html"><a href="I02-read.html#importing-csv-files"><i class="fa fa-check"></i>Importing CSV Files</a></li>
<li class="chapter" data-level="" data-path="I02-read.html"><a href="I02-read.html#importing-microsoft-excel-files"><i class="fa fa-check"></i>Importing Microsoft Excel Files</a></li>
<li class="chapter" data-level="" data-path="I02-read.html"><a href="I02-read.html#checking-the-imported-data"><i class="fa fa-check"></i>Checking the Imported Data</a></li>
<li class="chapter" data-level="" data-path="I02-read.html"><a href="I02-read.html#common-problems"><i class="fa fa-check"></i>Common Problems</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="S07-examples.html"><a href="S07-examples.html"><i class="fa fa-check"></i><b>7</b> Examples</a>
<ul>
<li class="chapter" data-level="7.1" data-path="S07-examples.html"><a href="S07-examples.html#simple-confidence-interval"><i class="fa fa-check"></i><b>7.1</b> Simple Confidence Interval</a>
<ul>
<li class="chapter" data-level="7.1.1" data-path="S07-examples.html"><a href="S07-examples.html#from-first-principles"><i class="fa fa-check"></i><b>7.1.1</b> From First Principles</a></li>
<li class="chapter" data-level="7.1.2" data-path="S07-examples.html"><a href="S07-examples.html#from-the-lm-output"><i class="fa fa-check"></i><b>7.1.2</b> From the <code>lm()</code> Output</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="S07-examples.html"><a href="S07-examples.html#confidence-intervals-for-the-mean"><i class="fa fa-check"></i><b>7.2</b> Confidence Intervals for the Mean</a></li>
<li class="chapter" data-level="7.3" data-path="S07-examples.html"><a href="S07-examples.html#testing-a-single-coefficient"><i class="fa fa-check"></i><b>7.3</b> Testing a Single Coefficient</a>
<ul>
<li class="chapter" data-level="7.3.1" data-path="S07-examples.html"><a href="S07-examples.html#from-first-principles-1"><i class="fa fa-check"></i><b>7.3.1</b> From First Principles</a></li>
<li class="chapter" data-level="7.3.2" data-path="S07-examples.html"><a href="S07-examples.html#using-the-lm-output-i"><i class="fa fa-check"></i><b>7.3.2</b> Using the <code>lm()</code> Output, I</a></li>
<li class="chapter" data-level="7.3.3" data-path="S07-examples.html"><a href="S07-examples.html#using-the-lm-output-ii"><i class="fa fa-check"></i><b>7.3.3</b> Using the <code>lm()</code> Output, II</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="S07-examples.html"><a href="S07-examples.html#testing-multiple-coefficients"><i class="fa fa-check"></i><b>7.4</b> Testing Multiple Coefficients</a>
<ul>
<li class="chapter" data-level="7.4.1" data-path="S07-examples.html"><a href="S07-examples.html#from-first-principles-2"><i class="fa fa-check"></i><b>7.4.1</b> From First Principles</a></li>
<li class="chapter" data-level="7.4.2" data-path="S07-examples.html"><a href="S07-examples.html#using-the-lm-output"><i class="fa fa-check"></i><b>7.4.2</b> Using the <code>lm()</code> output</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="P02.html"><a href="P02.html"><i class="fa fa-check"></i>Problem Sheet 2</a></li>
<li class="chapter" data-level="8" data-path="S08-influence.html"><a href="S08-influence.html"><i class="fa fa-check"></i><b>8</b> The Influence of Observations</a>
<ul>
<li class="chapter" data-level="8.1" data-path="S08-influence.html"><a href="S08-influence.html#deleting"><i class="fa fa-check"></i><b>8.1</b> Deleting Observations</a></li>
<li class="chapter" data-level="8.2" data-path="S08-influence.html"><a href="S08-influence.html#influence"><i class="fa fa-check"></i><b>8.2</b> Cook’s Distance</a></li>
</ul></li>
<li class="part"><span><b>II Linear Regression in Practice</b></span></li>
<li class="chapter" data-level="9" data-path="S09-plots.html"><a href="S09-plots.html"><i class="fa fa-check"></i><b>9</b> Diagnostic Plots</a>
<ul>
<li class="chapter" data-level="9.1" data-path="S09-plots.html"><a href="S09-plots.html#residual-plots"><i class="fa fa-check"></i><b>9.1</b> Residual Plots</a></li>
<li class="chapter" data-level="9.2" data-path="S09-plots.html"><a href="S09-plots.html#q-q-plots"><i class="fa fa-check"></i><b>9.2</b> Q-Q Plots</a></li>
<li class="chapter" data-level="9.3" data-path="S09-plots.html"><a href="S09-plots.html#other-plot-types"><i class="fa fa-check"></i><b>9.3</b> Other Plot Types</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="S10-diagnostics.html"><a href="S10-diagnostics.html"><i class="fa fa-check"></i><b>10</b> Measures for Model Fit</a>
<ul>
<li class="chapter" data-level="10.1" data-path="S10-diagnostics.html"><a href="S10-diagnostics.html#R-squared"><i class="fa fa-check"></i><b>10.1</b> The Coefficient of Multiple Determination</a></li>
<li class="chapter" data-level="10.2" data-path="S10-diagnostics.html"><a href="S10-diagnostics.html#adjusted-R-squared"><i class="fa fa-check"></i><b>10.2</b> Adjusted <span class="math inline">\(R^2\)</span></a></li>
<li class="chapter" data-level="10.3" data-path="S10-diagnostics.html"><a href="S10-diagnostics.html#error-var"><i class="fa fa-check"></i><b>10.3</b> Error Variance</a></li>
<li class="chapter" data-level="10.4" data-path="S10-diagnostics.html"><a href="S10-diagnostics.html#PRESS"><i class="fa fa-check"></i><b>10.4</b> Prediction Error Sum of Squares</a></li>
<li class="chapter" data-level="10.5" data-path="S10-diagnostics.html"><a href="S10-diagnostics.html#AIC"><i class="fa fa-check"></i><b>10.5</b> Akaike’s Information Criterion</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="I03-lm-output.html"><a href="I03-lm-output.html"><i class="fa fa-check"></i>Interlude: Understanding the <code>lm()</code> Output</a></li>
<li class="chapter" data-level="11" data-path="S11-improving.html"><a href="S11-improving.html"><i class="fa fa-check"></i><b>11</b> Improving the Model Fit</a>
<ul>
<li class="chapter" data-level="11.1" data-path="S11-improving.html"><a href="S11-improving.html#linearising-the-mean"><i class="fa fa-check"></i><b>11.1</b> Linearising the Mean</a></li>
<li class="chapter" data-level="11.2" data-path="S11-improving.html"><a href="S11-improving.html#stabilising-the-variance"><i class="fa fa-check"></i><b>11.2</b> Stabilising the Variance</a></li>
<li class="chapter" data-level="11.3" data-path="S11-improving.html"><a href="S11-improving.html#power-transform"><i class="fa fa-check"></i><b>11.3</b> The Power Transform</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="P03.html"><a href="P03.html"><i class="fa fa-check"></i>Problem Sheet 3</a></li>
<li class="chapter" data-level="12" data-path="S12-selection.html"><a href="S12-selection.html"><i class="fa fa-check"></i><b>12</b> Model Selection</a>
<ul>
<li class="chapter" data-level="12.1" data-path="S12-selection.html"><a href="S12-selection.html#candidate-models"><i class="fa fa-check"></i><b>12.1</b> Candidate Models</a></li>
<li class="chapter" data-level="12.2" data-path="S12-selection.html"><a href="S12-selection.html#misspecified-models"><i class="fa fa-check"></i><b>12.2</b> Misspecified Models</a>
<ul>
<li class="chapter" data-level="12.2.1" data-path="S12-selection.html"><a href="S12-selection.html#missing-variables"><i class="fa fa-check"></i><b>12.2.1</b> Missing Variables</a></li>
<li class="chapter" data-level="12.2.2" data-path="S12-selection.html"><a href="S12-selection.html#unnecessary-variables"><i class="fa fa-check"></i><b>12.2.2</b> Unnecessary Variables</a></li>
</ul></li>
<li class="chapter" data-level="12.3" data-path="S12-selection.html"><a href="S12-selection.html#choosing-between-models"><i class="fa fa-check"></i><b>12.3</b> Choosing Between Models</a>
<ul>
<li class="chapter" data-level="12.3.1" data-path="S12-selection.html"><a href="S12-selection.html#criteria-for-model-selection"><i class="fa fa-check"></i><b>12.3.1</b> Criteria for Model Selection</a></li>
<li class="chapter" data-level="12.3.2" data-path="S12-selection.html"><a href="S12-selection.html#exhaustive-search"><i class="fa fa-check"></i><b>12.3.2</b> Exhaustive Search</a></li>
<li class="chapter" data-level="12.3.3" data-path="S12-selection.html"><a href="S12-selection.html#stepwise-forward-selection"><i class="fa fa-check"></i><b>12.3.3</b> Stepwise Forward Selection</a></li>
<li class="chapter" data-level="12.3.4" data-path="S12-selection.html"><a href="S12-selection.html#stepwise-backward-selection"><i class="fa fa-check"></i><b>12.3.4</b> Stepwise Backward Selection</a></li>
<li class="chapter" data-level="12.3.5" data-path="S12-selection.html"><a href="S12-selection.html#hybrid-methods"><i class="fa fa-check"></i><b>12.3.5</b> Hybrid Methods</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="13" data-path="S13-exhaustive.html"><a href="S13-exhaustive.html"><i class="fa fa-check"></i><b>13</b> Exhaustive Model Search</a>
<ul>
<li class="chapter" data-level="13.1" data-path="S13-exhaustive.html"><a href="S13-exhaustive.html#exhaustive-search-1"><i class="fa fa-check"></i><b>13.1</b> Exhaustive Search</a></li>
<li class="chapter" data-level="13.2" data-path="S13-exhaustive.html"><a href="S13-exhaustive.html#search-algorithm"><i class="fa fa-check"></i><b>13.2</b> Search Algorithm</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="S14-factors.html"><a href="S14-factors.html"><i class="fa fa-check"></i><b>14</b> Factors</a>
<ul>
<li class="chapter" data-level="14.1" data-path="S14-factors.html"><a href="S14-factors.html#indicator-variables"><i class="fa fa-check"></i><b>14.1</b> Indicator Variables</a></li>
<li class="chapter" data-level="14.2" data-path="S14-factors.html"><a href="S14-factors.html#interactions"><i class="fa fa-check"></i><b>14.2</b> Interactions</a></li>
<li class="chapter" data-level="14.3" data-path="S14-factors.html"><a href="S14-factors.html#interactions-example"><i class="fa fa-check"></i><b>14.3</b> Example</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="S15-multicoll.html"><a href="S15-multicoll.html"><i class="fa fa-check"></i><b>15</b> Multicollinearity</a>
<ul>
<li class="chapter" data-level="15.1" data-path="S15-multicoll.html"><a href="S15-multicoll.html#consequences-of-multicollinearity"><i class="fa fa-check"></i><b>15.1</b> Consequences of Multicollinearity</a></li>
<li class="chapter" data-level="15.2" data-path="S15-multicoll.html"><a href="S15-multicoll.html#detecting-multicollinearity"><i class="fa fa-check"></i><b>15.2</b> Detecting Multicollinearity</a></li>
<li class="chapter" data-level="15.3" data-path="S15-multicoll.html"><a href="S15-multicoll.html#mitigations"><i class="fa fa-check"></i><b>15.3</b> Mitigations</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="P04.html"><a href="P04.html"><i class="fa fa-check"></i>Problem Sheet 4</a></li>
<li class="chapter" data-level="16" data-path="S16-ridge.html"><a href="S16-ridge.html"><i class="fa fa-check"></i><b>16</b> Ridge Regression</a>
<ul>
<li class="chapter" data-level="16.1" data-path="S16-ridge.html"><a href="S16-ridge.html#definition-the-estimator"><i class="fa fa-check"></i><b>16.1</b> Definition the Estimator</a></li>
<li class="chapter" data-level="16.2" data-path="S16-ridge.html"><a href="S16-ridge.html#properties-of-the-estimate"><i class="fa fa-check"></i><b>16.2</b> Properties of the Estimate</a>
<ul>
<li class="chapter" data-level="16.2.1" data-path="S16-ridge.html"><a href="S16-ridge.html#bias"><i class="fa fa-check"></i><b>16.2.1</b> Bias</a></li>
<li class="chapter" data-level="16.2.2" data-path="S16-ridge.html"><a href="S16-ridge.html#variance"><i class="fa fa-check"></i><b>16.2.2</b> Variance</a></li>
<li class="chapter" data-level="16.2.3" data-path="S16-ridge.html"><a href="S16-ridge.html#mean-squared-error"><i class="fa fa-check"></i><b>16.2.3</b> Mean Squared Error</a></li>
</ul></li>
<li class="chapter" data-level="16.3" data-path="S16-ridge.html"><a href="S16-ridge.html#standardisation"><i class="fa fa-check"></i><b>16.3</b> Standardisation</a></li>
</ul></li>
<li class="part"><span><b>III Robust Regression</b></span></li>
<li class="chapter" data-level="17" data-path="S17-robust.html"><a href="S17-robust.html"><i class="fa fa-check"></i><b>17</b> Robust Regression</a>
<ul>
<li class="chapter" data-level="17.1" data-path="S17-robust.html"><a href="S17-robust.html#outliers"><i class="fa fa-check"></i><b>17.1</b> Outliers</a>
<ul>
<li class="chapter" data-level="17.1.1" data-path="S17-robust.html"><a href="S17-robust.html#leverage"><i class="fa fa-check"></i><b>17.1.1</b> Leverage</a></li>
<li class="chapter" data-level="17.1.2" data-path="S17-robust.html"><a href="S17-robust.html#studentised-residuals"><i class="fa fa-check"></i><b>17.1.2</b> Studentised Residuals</a></li>
</ul></li>
<li class="chapter" data-level="17.2" data-path="S17-robust.html"><a href="S17-robust.html#breakdown-points"><i class="fa fa-check"></i><b>17.2</b> Breakdown Points</a></li>
</ul></li>
<li class="chapter" data-level="18" data-path="S18-m-est.html"><a href="S18-m-est.html"><i class="fa fa-check"></i><b>18</b> M-Estimators</a>
<ul>
<li class="chapter" data-level="18.1" data-path="S18-m-est.html"><a href="S18-m-est.html#definition"><i class="fa fa-check"></i><b>18.1</b> Definition</a></li>
<li class="chapter" data-level="18.2" data-path="S18-m-est.html"><a href="S18-m-est.html#iterative-methods"><i class="fa fa-check"></i><b>18.2</b> Iterative Methods</a></li>
<li class="chapter" data-level="18.3" data-path="S18-m-est.html"><a href="S18-m-est.html#objective-functions"><i class="fa fa-check"></i><b>18.3</b> Objective Functions</a>
<ul>
<li class="chapter" data-level="18.3.1" data-path="S18-m-est.html"><a href="S18-m-est.html#least-squares-method"><i class="fa fa-check"></i><b>18.3.1</b> Least Squares Method</a></li>
<li class="chapter" data-level="18.3.2" data-path="S18-m-est.html"><a href="S18-m-est.html#least-absolute-values"><i class="fa fa-check"></i><b>18.3.2</b> Least Absolute Values</a></li>
<li class="chapter" data-level="18.3.3" data-path="S18-m-est.html"><a href="S18-m-est.html#Huber"><i class="fa fa-check"></i><b>18.3.3</b> Huber’s <span class="math inline">\(t\)</span>-function</a></li>
<li class="chapter" data-level="18.3.4" data-path="S18-m-est.html"><a href="S18-m-est.html#hampel"><i class="fa fa-check"></i><b>18.3.4</b> Hampel’s Method</a></li>
<li class="chapter" data-level="18.3.5" data-path="S18-m-est.html"><a href="S18-m-est.html#bisquare"><i class="fa fa-check"></i><b>18.3.5</b> Tukey’s Bisquare Method</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="19" data-path="S19-efficiency.html"><a href="S19-efficiency.html"><i class="fa fa-check"></i><b>19</b> Efficiency of Robust Estimators</a>
<ul>
<li class="chapter" data-level="19.1" data-path="S19-efficiency.html"><a href="S19-efficiency.html#efficiency"><i class="fa fa-check"></i><b>19.1</b> Efficiency</a></li>
<li class="chapter" data-level="19.2" data-path="S19-efficiency.html"><a href="S19-efficiency.html#robust-estimators"><i class="fa fa-check"></i><b>19.2</b> Robust estimators</a>
<ul>
<li class="chapter" data-level="19.2.1" data-path="S19-efficiency.html"><a href="S19-efficiency.html#LMS"><i class="fa fa-check"></i><b>19.2.1</b> Least Median of Squares</a></li>
<li class="chapter" data-level="19.2.2" data-path="S19-efficiency.html"><a href="S19-efficiency.html#LTS"><i class="fa fa-check"></i><b>19.2.2</b> Least Trimmed Squares</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="I04-robust.html"><a href="I04-robust.html"><i class="fa fa-check"></i>Interlude: Robust Regression in R</a>
<ul>
<li class="chapter" data-level="" data-path="I04-robust.html"><a href="I04-robust.html#m-estimators"><i class="fa fa-check"></i>M-Estimators</a></li>
<li class="chapter" data-level="" data-path="I04-robust.html"><a href="I04-robust.html#lav-estimation"><i class="fa fa-check"></i>LAV Estimation</a></li>
<li class="chapter" data-level="" data-path="I04-robust.html"><a href="I04-robust.html#high-breakdown-point-methods"><i class="fa fa-check"></i>High Breakdown Point Methods</a></li>
<li class="chapter" data-level="" data-path="I04-robust.html"><a href="I04-robust.html#summary"><i class="fa fa-check"></i>Summary</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="P05.html"><a href="P05.html"><i class="fa fa-check"></i>Problem Sheet 5</a></li>
<li class="chapter" data-level="20" data-path="S20-examples.html"><a href="S20-examples.html"><i class="fa fa-check"></i><b>20</b> Examples</a>
<ul>
<li class="chapter" data-level="20.1" data-path="S20-examples.html"><a href="S20-examples.html#comparing-robust-methods"><i class="fa fa-check"></i><b>20.1</b> Comparing Robust Methods</a></li>
<li class="chapter" data-level="20.2" data-path="S20-examples.html"><a href="S20-examples.html#residual-analysis"><i class="fa fa-check"></i><b>20.2</b> Residual Analysis</a></li>
<li class="chapter" data-level="20.3" data-path="S20-examples.html"><a href="S20-examples.html#weight-comparisons"><i class="fa fa-check"></i><b>20.3</b> Weight Comparisons</a></li>
</ul></li>
<li class="appendix"><span><b>Appendices</b></span></li>
<li class="chapter" data-level="A" data-path="Sx1-matrices.html"><a href="Sx1-matrices.html"><i class="fa fa-check"></i><b>A</b> Linear Algebra Reminders</a>
<ul>
<li class="chapter" data-level="A.1" data-path="Sx1-matrices.html"><a href="Sx1-matrices.html#vectors"><i class="fa fa-check"></i><b>A.1</b> Vectors</a></li>
<li class="chapter" data-level="A.2" data-path="Sx1-matrices.html"><a href="Sx1-matrices.html#matrix-rules"><i class="fa fa-check"></i><b>A.2</b> Matrices</a>
<ul>
<li class="chapter" data-level="A.2.1" data-path="Sx1-matrices.html"><a href="Sx1-matrices.html#transpose"><i class="fa fa-check"></i><b>A.2.1</b> Transpose</a></li>
<li class="chapter" data-level="A.2.2" data-path="Sx1-matrices.html"><a href="Sx1-matrices.html#matrix-vector-product"><i class="fa fa-check"></i><b>A.2.2</b> Matrix-vector Product</a></li>
<li class="chapter" data-level="A.2.3" data-path="Sx1-matrices.html"><a href="Sx1-matrices.html#matrix-matrix-product"><i class="fa fa-check"></i><b>A.2.3</b> Matrix-matrix Product</a></li>
<li class="chapter" data-level="A.2.4" data-path="Sx1-matrices.html"><a href="Sx1-matrices.html#rank"><i class="fa fa-check"></i><b>A.2.4</b> Rank</a></li>
<li class="chapter" data-level="A.2.5" data-path="Sx1-matrices.html"><a href="Sx1-matrices.html#trace"><i class="fa fa-check"></i><b>A.2.5</b> Trace</a></li>
<li class="chapter" data-level="A.2.6" data-path="Sx1-matrices.html"><a href="Sx1-matrices.html#matrix-inverse"><i class="fa fa-check"></i><b>A.2.6</b> Matrix Inverse</a></li>
<li class="chapter" data-level="A.2.7" data-path="Sx1-matrices.html"><a href="Sx1-matrices.html#orthogonal-matrices"><i class="fa fa-check"></i><b>A.2.7</b> Orthogonal Matrices</a></li>
<li class="chapter" data-level="A.2.8" data-path="Sx1-matrices.html"><a href="Sx1-matrices.html#positive-definite"><i class="fa fa-check"></i><b>A.2.8</b> Positive Definite Matrices</a></li>
<li class="chapter" data-level="A.2.9" data-path="Sx1-matrices.html"><a href="Sx1-matrices.html#idempotent"><i class="fa fa-check"></i><b>A.2.9</b> Idempotent Matrices</a></li>
</ul></li>
<li class="chapter" data-level="A.3" data-path="Sx1-matrices.html"><a href="Sx1-matrices.html#eigenvalues"><i class="fa fa-check"></i><b>A.3</b> Eigenvalues</a></li>
</ul></li>
<li class="chapter" data-level="B" data-path="Sx2-probability.html"><a href="Sx2-probability.html"><i class="fa fa-check"></i><b>B</b> Probability Reminders</a>
<ul>
<li class="chapter" data-level="B.1" data-path="Sx2-probability.html"><a href="Sx2-probability.html#independence"><i class="fa fa-check"></i><b>B.1</b> Independence</a></li>
<li class="chapter" data-level="B.2" data-path="Sx2-probability.html"><a href="Sx2-probability.html#expectation-1"><i class="fa fa-check"></i><b>B.2</b> Expectation</a></li>
<li class="chapter" data-level="B.3" data-path="Sx2-probability.html"><a href="Sx2-probability.html#variance-1"><i class="fa fa-check"></i><b>B.3</b> Variance</a></li>
<li class="chapter" data-level="B.4" data-path="Sx2-probability.html"><a href="Sx2-probability.html#covariance"><i class="fa fa-check"></i><b>B.4</b> Covariance</a></li>
<li class="chapter" data-level="B.5" data-path="Sx2-probability.html"><a href="Sx2-probability.html#well-known-distributions"><i class="fa fa-check"></i><b>B.5</b> Well-Known Distributions</a>
<ul>
<li class="chapter" data-level="B.5.1" data-path="Sx2-probability.html"><a href="Sx2-probability.html#chi-square"><i class="fa fa-check"></i><b>B.5.1</b> The Chi-Squared Distribution</a></li>
<li class="chapter" data-level="B.5.2" data-path="Sx2-probability.html"><a href="Sx2-probability.html#t"><i class="fa fa-check"></i><b>B.5.2</b> The t-distribution</a></li>
</ul></li>
</ul></li>
<li class="divider"></li>
<li class="chapter"><span><b>THE END</b></span></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">MATH3714 Linear Regression and Robustness</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="P03" class="section level1 unnumbered hasAnchor">
<h1>Problem Sheet 3<a href="P03.html#P03" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<!--
TODO (voss):
* swap questions 8 and 9
* question 12 is out of place
-->
<style>
.fold-btn {
  float: right;
  margin: -12px 0 0 0;
}
</style>
<script type="text/javascript">
$(document).ready(function() {
  $folds = $(".myanswers");
  $folds.wrapInner("<div class=\"fold-blck\">"); // wrap a div container around content
  $folds.prepend("<button class=\"fold-btn\">Show solution</button>");  // add a button
  $(".fold-blck").toggle();  // fold all blocks
  $(".fold-btn").on("click", function() {  // add onClick event
    $(this).text($(this).text() === "Hide solution" ? "Show solution" : "Hide solution");
    $(this).next(".fold-blck").toggle("linear");  // "swing" is the default easing function. This can be further customized in its speed or the overall animation itself.
  })
});
</script>
<style>.myanswers { display: none !important; }</style>
<div class="mysummary">
<p>You should attempt all these questions and write up your solutions in advance
of the workshop in week 6 where the answers will be discussed.</p>
</div>
<div class="myq">
<p><strong>9.</strong> Consider the following dataset. Our aim is to predict <span class="math inline">\(y\)</span> from the
variables <span class="math inline">\(x_1\)</span>, <span class="math inline">\(x_2\)</span> and <span class="math inline">\(x_3\)</span>.</p>
<table>
<thead>
<tr class="header">
<th align="right"><span class="math inline">\(i\)</span></th>
<th align="right"><span class="math inline">\(x_{1,i}\)</span></th>
<th align="right"><span class="math inline">\(x_{2,i}\)</span></th>
<th align="right"><span class="math inline">\(x_{3,i}\)</span></th>
<th align="right"><span class="math inline">\(y_i\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">1</td>
<td align="right">-2.17</td>
<td align="right">-2.08</td>
<td align="right">-2.16</td>
<td align="right">4.47</td>
</tr>
<tr class="even">
<td align="right">2</td>
<td align="right">-1.35</td>
<td align="right">-0.50</td>
<td align="right">-0.74</td>
<td align="right">5.60</td>
</tr>
<tr class="odd">
<td align="right">3</td>
<td align="right">-1.22</td>
<td align="right">-1.00</td>
<td align="right">-1.78</td>
<td align="right">4.16</td>
</tr>
<tr class="even">
<td align="right">4</td>
<td align="right">-1.04</td>
<td align="right">-0.32</td>
<td align="right">-0.40</td>
<td align="right">5.52</td>
</tr>
<tr class="odd">
<td align="right">5</td>
<td align="right">-0.87</td>
<td align="right">-0.39</td>
<td align="right">-0.67</td>
<td align="right">5.27</td>
</tr>
<tr class="even">
<td align="right">6</td>
<td align="right">-0.41</td>
<td align="right">0.07</td>
<td align="right">-0.66</td>
<td align="right">4.70</td>
</tr>
<tr class="odd">
<td align="right">7</td>
<td align="right">0.07</td>
<td align="right">0.74</td>
<td align="right">0.37</td>
<td align="right">5.50</td>
</tr>
<tr class="even">
<td align="right">8</td>
<td align="right">0.25</td>
<td align="right">0.35</td>
<td align="right">0.02</td>
<td align="right">4.84</td>
</tr>
<tr class="odd">
<td align="right">9</td>
<td align="right">0.87</td>
<td align="right">1.28</td>
<td align="right">0.52</td>
<td align="right">4.92</td>
</tr>
<tr class="even">
<td align="right">10</td>
<td align="right">1.53</td>
<td align="right">2.30</td>
<td align="right">1.35</td>
<td align="right">5.35</td>
</tr>
<tr class="odd">
<td align="right">11</td>
<td align="right">2.46</td>
<td align="right">2.55</td>
<td align="right">1.77</td>
<td align="right">4.86</td>
</tr>
<tr class="even">
<td align="right">12</td>
<td align="right">5.00</td>
<td align="right">5.04</td>
<td align="right">4.05</td>
<td align="right">5.09</td>
</tr>
</tbody>
</table>
<p>These data are also available in machine-readable form at</p>
<ul>
<li><a href="https://teaching.seehuhn.de/2022/MATH3714/P03Q09.csv">https://teaching.seehuhn.de/2022/MATH3714/P03Q09.csv</a></li>
</ul>
<p>Using these data:</p>
<div class="subq">
<ol style="list-style-type: lower-alpha">
<li>Fit a linear model of the form
<span class="math inline">\(y_i = \beta_0 + x_{1,i} \beta_1 + x_{2,i} \beta_2 + x_{3,i} \beta_3 + \varepsilon_i\)</span>.</li>
</ol>
<div class="myanswers">
<p>To fit the required model we can use the following R commands:</p>
<div class="sourceCode" id="cb169"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb169-1"><a href="P03.html#cb169-1" tabindex="-1"></a>url <span class="ot">&lt;-</span> <span class="st">&quot;https://teaching.seehuhn.de/2022/MATH3714/P03Q09.csv&quot;</span></span>
<span id="cb169-2"><a href="P03.html#cb169-2" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">read.csv</span>(url)</span>
<span id="cb169-3"><a href="P03.html#cb169-3" tabindex="-1"></a>m <span class="ot">&lt;-</span> <span class="fu">lm</span>(y <span class="sc">~</span> x1 <span class="sc">+</span> x2 <span class="sc">+</span> x3, <span class="at">data=</span>x)</span></code></pre></div>
<p>The fitted model has the following coefficients:</p>
<div class="sourceCode" id="cb170"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb170-1"><a href="P03.html#cb170-1" tabindex="-1"></a><span class="fu">summary</span>(m)</span></code></pre></div>
<pre class="routput"><code>
Call:
lm(formula = y ~ x1 + x2 + x3, data = x)

Residuals:
      Min        1Q    Median        3Q       Max 
-0.104928 -0.032723 -0.001836  0.024802  0.142993 

Coefficients:
            Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)  4.97725    0.06026  82.598 5.15e-13 ***
x1          -1.11954    0.07427 -15.074 3.71e-07 ***
x2           0.28176    0.12023   2.344   0.0472 *  
x3           1.06621    0.09492  11.232 3.54e-06 ***
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

Residual standard error: 0.07109 on 8 degrees of freedom
Multiple R-squared:  0.9817,    Adjusted R-squared:  0.9748 
F-statistic: 142.8 on 3 and 8 DF,  p-value: 2.76e-07</code></pre>
</div>
</div>
<div class="subq">
<ol start="2" style="list-style-type: lower-alpha">
<li>Determine a <span class="math inline">\(95\%\)</span> confidence interval for the coefficient <span class="math inline">\(\beta_2\)</span>.</li>
</ol>
<div class="myanswers">
<p>From lectures we know that a confidence interval for a single
coefficient <span class="math inline">\(\beta_j\)</span> is given by
<span class="math display">\[\begin{equation*}
  [U, V]
  = \Bigl[ \hat\beta_j - t_{n-p-1}(\alpha/2) \sqrt{\widehat{\sigma^2} C_{jj}},
       \hat\beta_j + t_{n-p-1}(\alpha/2) \sqrt{\widehat{\sigma^2} C_{jj}} \Bigr],
\end{equation*}\]</span>
where <span class="math inline">\(t_{n-p-1}\)</span> is the <span class="math inline">\((1-\alpha/2)\)</span>-quantile of the <span class="math inline">\(t\)</span>-distribution,
<span class="math inline">\(C_{jj} = (X^\top X)^{-1}_{jj}\)</span>, and <span class="math inline">\(X\)</span> is the design matrix.</p>
<p>We can read off the required values for computing the confidence
interval from the output of <code>summary(m)</code>: the centre of the
confidence interval can be found in the column <code>Estimate</code>,
the standard error <span class="math inline">\(\sqrt{\widehat{\sigma^2} C_{jj}}\)</span> is given in
column <code>Std. Error</code>, and <span class="math inline">\(n-p-1 = 12 - 3 - 1 = 8\)</span>. Using
these values, we can find a <span class="math inline">\(95\%\)</span>-confidence interval for
<span class="math inline">\(\beta_2\)</span> as follows:</p>
<div class="sourceCode" id="cb172"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb172-1"><a href="P03.html#cb172-1" tabindex="-1"></a>  <span class="fu">c</span>(<span class="fl">0.28176</span> <span class="sc">-</span> <span class="fu">qt</span>(<span class="fl">0.975</span>, <span class="dv">8</span>) <span class="sc">*</span> <span class="fl">0.12023</span>, <span class="fl">0.28176</span> <span class="sc">+</span> <span class="fu">qt</span>(<span class="fl">0.975</span>, <span class="dv">8</span>) <span class="sc">*</span> <span class="fl">0.12023</span>)</span></code></pre></div>
<pre class="routput"><code>[1] 0.004509123 0.559010877</code></pre>
<p>Thus, the confidence interval is <span class="math inline">\(\bigl[ 0.0045, 0.5590 \bigr]\)</span>.</p>
</div>
</div>
<div class="subq">
<ol start="3" style="list-style-type: lower-alpha">
<li>Perform a hypothesis test, at the <span class="math inline">\(95\%\)</span>-level, for the
hypothesis <span class="math inline">\(H_0\colon \beta_2 = 0\)</span> with alternative <span class="math inline">\(H_1\colon \beta_2 \neq 0\)</span>.</li>
</ol>
<div class="myanswers">
<p>The test statistic is
<span class="math display">\[\begin{equation*}
  T
  = \frac{\bigl|\hat\beta_2\bigr|}{\sqrt{\widehat{\sigma^2} C_{jj}} }
  = \frac{0.28176}{0.12023}
  = 2.344.
\end{equation*}\]</span>
(This value is also shown in the column <code>t value</code> of the R
summary output.) The critical value is
<span class="math display">\[\begin{equation*}
  t
  = t_{n-p-1}(\alpha/2)
  = 2.306.
\end{equation*}\]</span>
Since <span class="math inline">\(T &gt; t\)</span>, we can reject the hypothesis <span class="math inline">\(\beta_2 = 0\)</span> at the
<span class="math inline">\(95\%\)</span>-level.</p>
</div>
</div>
</div>
<div class="myq">
<p><strong>10.</strong> Let <span class="math inline">\(x_1, \ldots, x_n, y_1, \ldots, y_n \in \mathbb{R}\)</span> be given. Assume
that it is known that the <span class="math inline">\(y\)</span>-values satisfy
<span class="math inline">\(y \approx 1 - x + c x^2 - d x^3\)</span>, where <span class="math inline">\(c\)</span> and <span class="math inline">\(d\)</span> are unknown
constants.</p>
<div class="subq">
<ol style="list-style-type: lower-alpha">
<li>Explain how linear regression can be used to estimate the
parameters <span class="math inline">\(c\)</span> and <span class="math inline">\(d\)</span> from the given data.</li>
</ol>
<div class="myanswers">
<p>We can rewrite the equation for <span class="math inline">\(y\)</span> as
<span class="math display">\[\begin{equation*}
  y + x - 1 = c x^2 - d x^3,
\end{equation*}\]</span>
where <span class="math inline">\(c\)</span> and <span class="math inline">\(d\)</span> are the unknown quantities, and <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span>
are given. Thus we can estimate <span class="math inline">\(c\)</span> and <span class="math inline">\(d\)</span> by fitting
a linear model with two inputs, <span class="math inline">\(x_i^2\)</span> and <span class="math inline">\(x_i^3\)</span>
and one output <span class="math inline">\(y_i + x_i - 1\)</span>. The model does not include
an intercept.</p>
</div>
</div>
<div class="subq">
<ol start="2" style="list-style-type: lower-alpha">
<li>What is the design matrix in this situation?</li>
</ol>
<div class="myanswers">
<p>Since there is no intercept, the design matrix is
<span class="math display">\[\begin{equation*}
  X = \begin{pmatrix}
    x_1^2 &amp; x_1^3 \\
    x_2^2 &amp; x_2^3 \\
    \vdots &amp; \vdots \\
    x_n^2 &amp; x_n^3 \\
  \end{pmatrix}
  \in \mathbb{R}^{n\times 2}.
\end{equation*}\]</span></p>
</div>
</div>
<div class="subq">
<ol start="3" style="list-style-type: lower-alpha">
<li>Why can <em>linear</em> regression be used, despite the presence
of the <em>non-linear</em> terms <span class="math inline">\(x^2\)</span> and <span class="math inline">\(x^3\)</span>?</li>
</ol>
<div class="myanswers">
<p>A linear model is appropriate, because the response depends
on the unknown coefficients <span class="math inline">\(c\)</span> and <span class="math inline">\(d\)</span> in a linear way: <span class="math inline">\(c\)</span> and <span class="math inline">\(d\)</span>
are only multiplied by known constants, and there are no non-linear
functions of <span class="math inline">\(c\)</span> and <span class="math inline">\(d\)</span> in the model.</p>
</div>
</div>
</div>
<div class="myq">
<p><strong>11.</strong> In this question we consider four different datasets, given by
inputs <span class="math inline">\(x_i\)</span> and responses <span class="math inline">\(y_i\)</span> for <span class="math inline">\(i \in \{1, 2, 3, 4\}\)</span>.</p>
<div class="subq">
<ol style="list-style-type: lower-alpha">
<li>Based on the following plots, discuss model fit of each model.
Describe all relevant features of the plots.
Describe any problems with the model fit you find.</li>
</ol>
<div class="sourceCode" id="cb174"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb174-1"><a href="P03.html#cb174-1" tabindex="-1"></a>    <span class="fu">par</span>(<span class="at">mfrow=</span><span class="fu">c</span>(<span class="dv">4</span>,<span class="dv">2</span>))</span>
<span id="cb174-2"><a href="P03.html#cb174-2" tabindex="-1"></a></span>
<span id="cb174-3"><a href="P03.html#cb174-3" tabindex="-1"></a>    m1 <span class="ot">&lt;-</span> <span class="fu">lm</span>(y1 <span class="sc">~</span> x1)</span>
<span id="cb174-4"><a href="P03.html#cb174-4" tabindex="-1"></a>    <span class="fu">plot</span>(<span class="fu">fitted</span>(m1), <span class="fu">resid</span>(m1), <span class="at">xlab=</span><span class="st">&quot;fitted values&quot;</span>, <span class="at">ylab=</span><span class="st">&quot;residuals&quot;</span>)</span>
<span id="cb174-5"><a href="P03.html#cb174-5" tabindex="-1"></a>    <span class="fu">qqnorm</span>(<span class="fu">resid</span>(m1), <span class="at">main=</span><span class="cn">NULL</span>)</span>
<span id="cb174-6"><a href="P03.html#cb174-6" tabindex="-1"></a></span>
<span id="cb174-7"><a href="P03.html#cb174-7" tabindex="-1"></a>    m2 <span class="ot">&lt;-</span> <span class="fu">lm</span>(y2 <span class="sc">~</span> x2)</span>
<span id="cb174-8"><a href="P03.html#cb174-8" tabindex="-1"></a>    <span class="fu">plot</span>(<span class="fu">fitted</span>(m2), <span class="fu">resid</span>(m2), <span class="at">xlab=</span><span class="st">&quot;fitted values&quot;</span>, <span class="at">ylab=</span><span class="st">&quot;residuals&quot;</span>)</span>
<span id="cb174-9"><a href="P03.html#cb174-9" tabindex="-1"></a>    <span class="fu">qqnorm</span>(<span class="fu">resid</span>(m2), <span class="at">main=</span><span class="cn">NULL</span>)</span>
<span id="cb174-10"><a href="P03.html#cb174-10" tabindex="-1"></a></span>
<span id="cb174-11"><a href="P03.html#cb174-11" tabindex="-1"></a>    m3 <span class="ot">&lt;-</span> <span class="fu">lm</span>(y3 <span class="sc">~</span> x3)</span>
<span id="cb174-12"><a href="P03.html#cb174-12" tabindex="-1"></a>    <span class="fu">plot</span>(<span class="fu">fitted</span>(m3), <span class="fu">resid</span>(m3), <span class="at">xlab=</span><span class="st">&quot;fitted values&quot;</span>, <span class="at">ylab=</span><span class="st">&quot;residuals&quot;</span>)</span>
<span id="cb174-13"><a href="P03.html#cb174-13" tabindex="-1"></a>    <span class="fu">qqnorm</span>(<span class="fu">resid</span>(m3), <span class="at">main=</span><span class="cn">NULL</span>)</span>
<span id="cb174-14"><a href="P03.html#cb174-14" tabindex="-1"></a></span>
<span id="cb174-15"><a href="P03.html#cb174-15" tabindex="-1"></a>    m4 <span class="ot">&lt;-</span> <span class="fu">lm</span>(y4 <span class="sc">~</span> x4)</span>
<span id="cb174-16"><a href="P03.html#cb174-16" tabindex="-1"></a>    <span class="fu">plot</span>(<span class="fu">fitted</span>(m4), <span class="fu">resid</span>(m4), <span class="at">xlab=</span><span class="st">&quot;fitted values&quot;</span>, <span class="at">ylab=</span><span class="st">&quot;residuals&quot;</span>)</span>
<span id="cb174-17"><a href="P03.html#cb174-17" tabindex="-1"></a>    <span class="fu">qqnorm</span>(<span class="fu">resid</span>(m4), <span class="at">main=</span><span class="cn">NULL</span>)</span></code></pre></div>
<p><img src="MATH3714_files/figure-html/four-models-1.png" width="672" /></p>
<div class="myanswers">
<p>We first note that the given R commands generate the plots along
rows, so the first row of plots corresponds to model <code>m1</code>, the
second row to model <code>m2</code>, and so on. The plots shown are
residual plots in the left column, and Q-Q-plots in the right
column.</p>
<ul>
<li><strong>m1:</strong> Samples in the residual plot on the left
seem to follow an upside down parabola indicating a non-linear
relationship between <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span>. Samples in the QQ-plot on the
right seem to (approximately?) follow a straight line, so
residuals seem to be (approximately?) normally distributed. No
outliers are visible.</li>
<li><strong>m2:</strong> Samples in the residual plot form a band
centred at zero. Possibly very negative residuals are less
frequent for fitted values <span class="math inline">\(\hat y_i &lt; 4\)</span>? No outliers are
apparent. The samples in the QQ-plot seem to clearly fall on a
straight line. Overall, model fit seems very good.</li>
<li><strong>m3:</strong> The samples in the residual plot are
centred around <span class="math inline">\(\hat\varepsilon= 0\)</span>, but the width of the spread
increases as the fitted values increase, leasing to a triangular
shape. This indicates that the variance of the residuals is not
constant but increases with <span class="math inline">\(y\)</span>. Possibly, a model with
multiplicative noise would be appropriate for these data. The
QQ-plot shows an approximately straight line, but fit is not as
good as for model <code>m2</code>.</li>
<li><strong>m4:</strong> The samples in the residual plot form a
horizontal band centred at <span class="math inline">\(\hat\varepsilon= 0\)</span>, no outliers are
visible. The QQ-plot shows clearly that the residuals are not
normally distributed: the samples form an “S-shaped” line,
indicating that the errors have lighter tails than we would expect
for a normal distribution.</li>
</ul>
</div>
</div>
<div class="subq">
<ol start="2" style="list-style-type: lower-alpha">
<li>Which of the four models has the best fit?</li>
</ol>
<div class="myanswers">
<p>The data in <code>m1</code> seems to
have a non-linear relationship between <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span>, the data
in <code>m3</code> seems to be better modelled using multiplicative noise,
and the residuals in <code>m4</code> seem not to be normally
distributed. Thus, the model with the best fit is <code>m2</code>,
because it is the only model which does not show any obvious
problems.</p>
</div>
</div>
</div>
<div class="myq">
<p><strong>12.</strong> Using singular value decomposition,
we can write a design matrix <span class="math inline">\(X\)</span> as <span class="math inline">\(X = U D V^\top\)</span>,
where <span class="math inline">\(D\in\mathbb{R}^{(p+1)\times(p+1)}\)</span> is a diagonal matrix
and <span class="math inline">\(U\in\mathbb{R}^{n\times(p+1)}\)</span> and <span class="math inline">\(V\in\mathbb{R}^{(p+1)\times(p+1)}\)</span> are matrices with orthonormal columns.
Denote the diagonal elements of <span class="math inline">\(D\)</span> by <span class="math inline">\(\sigma_0(X), \ldots, \sigma_p(X) \geq 0\)</span>,
and the columns of <span class="math inline">\(V\)</span> by <span class="math inline">\(v_0, \ldots, v_p\)</span>.
Show that <span class="math inline">\(\| X v_k \| = \sigma_k(X)\)</span>.
(We used this fact in example <a href="S15-multicoll.html#exm:multcoll3">15.3</a>.)</p>
<div class="myanswers">
<p>Using the singular value decomposition of <span class="math inline">\(X\)</span>, we find
<span class="math display">\[\begin{equation*}
  \| X v_k \|
  = \| U D V^\top v_k \|.
\end{equation*}\]</span>
For every vector <span class="math inline">\(x\)</span> we
have <span class="math inline">\(\| U x \|^2 = x^\top U^\top U x = x^\top x = \| x \|^2\)</span>.
Thus, multiplying a vector <span class="math inline">\(x\)</span> by <span class="math inline">\(U\)</span> does
not change its length. Using this rule we find
<span class="math display">\[\begin{equation*}
  \| X v_k \|
  = \| D V^\top v_k \|.
\end{equation*}\]</span>
Since the columns of <span class="math inline">\(V\)</span> are orthonormal, we have <span class="math inline">\(V^\top v_k = e_k\)</span>,
where <span class="math inline">\(e_k = (0, \ldots, 1, \ldots, 0)\)</span> is the <span class="math inline">\(k\)</span>th standard basis vector.
Thus we get
<span class="math display">\[\begin{equation*}
  \| X v_k \|
  = \| D e_k \|
  = \| \sigma_k(X) e_k \|
  = \sigma_k(X) \| e_k \|
  = \sigma_k(X)
\end{equation*}\]</span>
as required. This completes the proof.</p>
</div>
</div>

</div>
            </section>

          </div>
        </div>
      </div>
<a href="S11-improving.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="S12-selection.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
  "sharing": null,
  "fontsettings": {
    "theme": "white",
    "family": "sans",
    "size": 2
  },
  "edit": {
    "link": null,
    "text": null
  },
  "history": {
    "link": null,
    "text": null
  },
  "view": {
    "link": null,
    "text": null
  },
  "download": ["MATH3714.pdf"],
  "search": {
    "engine": "fuse",
    "options": null
  },
  "toc": {
    "collapse": "section"
  }
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
